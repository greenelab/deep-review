<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml">
<head>
  <meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
  <meta http-equiv="Content-Style-Type" content="text/css" />
  <meta name="generator" content="pandoc" />
  <title></title>
  <style type="text/css">code{white-space: pre;}</style>
  <link rel="stylesheet" href="github-pandoc.css" type="text/css" />
</head>
<body>
<h1 id="deep-learning-genomics-and-precision-medicine">Deep Learning, Genomics, and Precision Medicine</h1>
<p>For preliminary authorship information, see the <a href="https://github.com/greenelab/deep-review/graphs/contributors">contributors</a> on GitHub.</p>
<h2 id="abstract">Abstract</h2>
<p>Deep learning, a class of machine learning algorithms, has recently showed impressive results across a variety of domains. Biomedicine and genomics, both data- and feature-rich and yet complex and often ill-understood, present an obvious and potentially valuable target for this new approach. We examine applications of deep learning to a variety of biomedical problems -- classification, fundamental research into biology and patient treatment -- to determine if similar progress can be made there or if the biomedical sphere holds unique challenges. While deep learning has yet to revolutionize or definitively resolve any of these problems, promising (sometimes remarkable) advances have been made on the prior state-of-the-art. Even where improvement over the previous baseline has been modest, there is still the promise of greatly speeding or aiding human investigation. More work is needed in technical directions such as interpretability and how to best model a problem. Further, the limited amount of labeled data for training presents problems in some domains, as can the legal and privacy constraints enforced by working with sensitive health records. Nonetheless, we foresee a growing use of deep learning with potential for transforming several fields of biomedicine, coming to routine use at the bench and bedside.</p>
<h2 id="introduction">Introduction</h2>
<p>Biology and medicine are rapidly becoming data-intensive. A recent comparison of genomics with social media, online videos, and other data-intensive scientific disciplines suggested that genomics alone would equal or surpass other fields in data generation and analysis within the next decade <span class="citation">[<a href="#ref-13bxiY1vo">1</a>]</span>. The volume and complexity of these data present not only new opportunities, but also new challenges. Automated algorithms will be crucial in extracting meaningful patterns and actionable knowledge that allow us to better treat, categorize, or study disease, all within data constrained and privacy critical environments.</p>
<p>Over the past five years, a class of machine learning algorithms known as deep learning has revolutionized image classification and speech recognition due to its flexibility and high accuracy <span class="citation">[<a href="#ref-BeijBSRE">2</a>]</span>. More recently, these algorithms have shown equally promising results in fields as diverse as high-energy physics <span class="citation">[<a href="#ref-TDruxF1s">3</a>]</span>, dermatology <span class="citation">[<a href="#ref-XnYNYoYB">4</a>]</span>, and translation among written languages <span class="citation">[<a href="#ref-4TK06zOf">5</a>]</span>. Across fields, &quot;off-the-shelf&quot; implementations of these algorithms have produced comparable or higher accuracy than previous best-in-class methods that required years of extensive customization, and specialized implementations are now being used at industrial scales.</p>
<p>Deep learning algorithms can also be used in an exploratory, &quot;unsupervised&quot; mode, where the goal is to summarize, explain, or identify interesting patterns in a data set (rather than to accurately predict which labels an expert would assign to each data point). In a famous and early example, scientists from Google demonstrated that a neural network &quot;discovered&quot; that cats, faces, and pedestrians were important components of online videos <span class="citation">[<a href="#ref-IiNJE32f">6</a>]</span>, without being told to look for any of them. What if, more generally, deep learning could solve the challenges presented by the growth of data in biomedicine? Could these algorithms identify the &quot;cats&quot; hidden in our data - the patterns unknown to the researcher - and act on them? In this review, we examine whether deep learning's transformation of biomedical science is simply a matter of time or if there are unique challenges posed by biomedical data that render deep learning methods either more challenging or less fruitful to apply.</p>
<h3 id="defining-deep-learning">Defining deep learning</h3>
<p>The term deep learning has come to refer to a collection of new techniques that, together, have demonstrated breakthrough gains over existing best-in-class machine learning algorithms across several fields. It is built on artificial neural networks, an idea that was first proposed in 1943 <span class="citation">[<a href="#ref-1HVDhhwpK">7</a>]</span> as a model for how biological brains process information. Since then, interest in neural networks as computational models has waxed and waned several times. This history is interesting in its own right <span class="citation">[<a href="#ref-1G5eCiq4d">8</a>]</span>. In recent years, attention has shifted back to neural networks as processing power has allowed deep learning techniques to surge ahead of other machine learning algorithms. Our focus is primarily on the downstream applications enabled by these advances.</p>
<p>Several important advances make the current surge of work done in this area possible. Easy-to-use software packages have brought the techniques of the field out of the specialist's toolkit to a broad community of computational scientists. Additionally, new techniques for fast training have enabled their application to larger datasets <span class="citation">[<a href="#ref-3qm8sXnB">9</a>]</span>. Dropout of nodes, edges and layers makes networks more robust, even when the number of parameters is very large. New neural network approaches are also well suited for addressing distinct challenges. For example, neural networks structured as autoencoders or as adversarial networks require no labels and are now regularly used for unsupervised tasks. In this review, we do not exhaustively discuss the different types of deep neural network architectures. A recent book from Goodfellow et al. <span class="citation">[<a href="#ref-yg8NW0K7">10</a>]</span> covers these in detail. Finally, the larger datasets now available are also well suited to fitting the many parameters that exist for deep neural networks. The convergence of these factors currently makes deep learning extremely adaptable and capable of addressing the nuanced differences of each domain to which it is applied.</p>
<h3 id="will-deep-learning-transform-the-study-of-human-disease">Will deep learning transform the study of human disease?</h3>
<p>With this review, we set out to address the question: what would need to be true for deep learning to transform how we categorize, study, and treat individuals to maintain or restore health? We choose a high bar for &quot;transform.&quot; Andrew Grove, the former CEO of Intel, coined the term Strategic Inflection Point to refer to a change in technologies or environment that requires a business to be fundamentally reshaped <span class="citation">[<a href="#ref-mAXsmd43">11</a>]</span>. Here, we seek to identify whether deep learning is an innovation that can induce a strategic inflection point in the practice of biology or medicine. We structure the review with an eye on precision medicine.</p>
<p>There are numerous examples where deep learning has been applied to biological problems and improved results as well as reviews focused on applications of deep learning in biology <span class="citation">[<a href="#ref-yXqhuueV">12</a>–<a href="#ref-MmRGFVUu">16</a>]</span>, healthcare <span class="citation">[<a href="#ref-11I7bLcP3">17</a>]</span>, and drug discovery <span class="citation">[<a href="#ref-gJE0ExFr">18</a>–<a href="#ref-xPkT1z7D">21</a>]</span>. We sought cases where deep learning enables researchers to solve challenges that were previously considered infeasible or makes difficult, tedious analyses routine.</p>
<p>We find that domain-specific considerations have greatly influenced how to best harness the power and flexibility of deep learning. Model interpretability is often critical: understanding the patterns in data may be just as important as fitting the data. In addition, there are important and pressing questions about how to build networks that can efficiently represent the underlying structure and logic of the data. Domain experts can play important roles in designing networks to represent data appropriately, encoding the most salient prior knowledge and assessing success or failure. There is also great potential to create deep learning systems that are not intended to replace biologists and clinicians but rather cooperate with them, working to prioritize experiments or streamline tasks that do not require expert judgment.</p>
<p>Based on our guiding question, we focus on the application of deep learning to topics of biomedical importance. We have divided the large range of topics into three broad classes: Disease and Patient Categorization, Fundamental Biological Study, and Patient Treatment. Below, we briefly introduce the types of questions, approaches and data that are typical for each class in the application of deep learning.</p>
<h4 id="disease-and-patient-categorization">Disease and Patient Categorization</h4>
<p>A key challenge in biomedicine is the accurate classification of diseases and disease subtypes. In oncology, current &quot;gold standard&quot; approaches include histology, which requires interpretation by experts, or assessment of molecular markers such as cell surface receptors or gene expression. One example is the PAM50 approach to classifying breast cancer where the expression of 50 marker genes divides breast cancer patients into four subtypes. Significant heterogeneity still remains within these four subtypes <span class="citation">[<a href="#ref-lnK82Ey6">22</a>,<a href="#ref-pEIw87Mp">23</a>]</span>. Given the increasing wealth of molecular data available, a more comprehensive subtyping seems possible.</p>
<p>Several studies have used deep learning methods in order to better categorize breast cancer patients: denoising autoencoders (DA), an unsupervised approach, can be used to cluster breast cancer patients <span class="citation">[<a href="#ref-PBiRSdXv">24</a>]</span>, and convolutional neural networks (CNN) can help count mitotic divisions, a feature that is highly correlated with disease outcome, in histological images <span class="citation">[<a href="#ref-koEdZRcY">25</a>]</span>. Despite these recent advances, a number of challenges exist in this area of research, most notably the integration of molecular and imaging data with other disparate types of data such as electronic health records (EHR).</p>
<h4 id="fundamental-biological-study">Fundamental Biological Study</h4>
<p>Deep learning can be applied to answer more fundamental biological questions; it is especially suited to leveraging large amounts of data from high-throughput &quot;omics&quot; studies. One classic biological problem where machine learning, and now deep learning, has been extensively applied is molecular target prediction. For example, deep recurrent neural networks (RNN) have been used to predict gene targets of microRNAs <span class="citation">[<a href="#ref-YUms527e">26</a>]</span>, and CNNs have been applied to predict protein residue-residue contacts and secondary structure on a genome-wide scale <span class="citation">[<a href="#ref-BhfjKSY3">27</a>–<a href="#ref-UO8L6nd">29</a>]</span>. Other recent exciting applications of deep learning include recognition of functional genomic elements such as enhancers and promoters <span class="citation">[<a href="#ref-s5sy4AOi">30</a>–<a href="#ref-12aqvAgz6">32</a>]</span> and prediction of the deleterious effects of nucleotide polymorphisms <span class="citation">[<a href="#ref-15E5yG1Ho">33</a>]</span>.</p>
<h4 id="patient-treatment">Patient Treatment</h4>
<p>Although the application of deep learning to patient treatment is just beginning, we expect a dramatic increase in methods aiming to recommend patient treatment, predict treatment outcomes, and guide future development of new therapies. Specifically, effort in this area aims to identify drug targets and interactions or predict drug response. One recent approach uses deep learning on protein structures to predict drug interactions and drug bioactivity <span class="citation">[<a href="#ref-Z7fd0BYf">34</a>]</span>. Drug repositioning using deep learning on transcriptomic data is another exciting area of research <span class="citation">[<a href="#ref-EMDwvRGb">35</a>]</span>. Interestingly, it was shown that restricted Boltzmann machines (RBMs) can be combined into deep belief networks (DBNs) to predict novel drug-target interactions and formulate drug repositioning hypotheses <span class="citation">[<a href="#ref-1AU7wzPqa">36</a>,<a href="#ref-oTF8O79C">37</a>]</span>. Finally, deep learning is also being successfully used to prioritize chemicals in the early stages of drug discovery for new targets <span class="citation">[<a href="#ref-xPkT1z7D">21</a>]</span>.</p>
<h2 id="deep-learning-and-patient-categorization">Deep learning and patient categorization</h2>
<p>In a healthcare setting, individuals are diagnosed with a disease or condition based on symptoms, the results of certain diagnostic tests, or other factors. Once diagnosed with a disease an individual might be assigned a stage based on another set of human-defined rules. While these rules are refined over time, the process is evolutionary rather than revolutionary.</p>
<p>We might imagine that deep learning or artificial intelligence methods could reinvent how individuals are categorized for healthcare. A deep neural network might identify entirely new categories of health or disease that are only present when data from multiple lab tests are integrated. As a potential example, consider the condition Latent Autoimmune Diabetes in Adults (LADA). The history of this disease classification is briefly reviewed in Stenström et al.<span class="citation">[<a href="#ref-WuOqsORY">38</a>]</span>.</p>
<p>Imagine that a deep neural network operating in the early 1980s had access to electronic health records with comprehensive clinical tests. It might have identified a subgroup of individuals with blood glucose levels that indicated diabetes as well as auto-antibodies, even though the individuals had never been diagnosed with type 1 diabetes - the autoimmune form of the disease that arises in young people. Such a neural network would be identifying patients with LADA. As no such computational approach existed, LADA was actually identified by Groop et al. <span class="citation">[<a href="#ref-ws1zvGoZ">39</a>]</span>. However, this represents a potential hope for this area. Perhaps deep neural networks, by reevaluating data without the context of our assumptions, can reveal novel classes of treatable conditions.</p>
<p>Alternatively, imagine that a deep neural network is provided with clinical test results gleaned from electronic health records. Because physicians may order certain tests based on the diagnosis that they suspect a patient has, a deep neural network may learn to &quot;diagnose&quot; patients simply based on the tests that are ordered. For some objective function this may offer good performance (i.e. predicting an ICD code), even though it does not provide insight into the underlying disease beyond physician activity. This challenge is not unique to deep learning approaches; however, it is important for practitioners to be aware of these challenges and the possibility in this domain of constructing highly predictive classifiers of questionable actual utility.</p>
<p>Our goal in this section is to assess the extent to which deep learning is already contributing to the discovery of novel categories. Where it is not, we focus on barriers to achieving these goals. We also highlight approaches that researchers are taking to address challenges within the field, particularly with regards to data availability and labeling.</p>
<h4 id="imaging-applications-in-healthcare">Imaging applications in healthcare</h4>
<p>One area where deep learning methods have had substantial success has been in image analysis. Applications in areas of medicine that use imaging extensively are also emerging. To the date, deep learning has been employed for a wide range of tasks in medical imaging, including classification of exams and lesions/nodules, localization of organs, regions, landmarks, and lesions, segmentation of organs, organ substructures, and lesions, medical image registration, content-based image retrieval, image generation and enhancement, and combining image data with clinical reports <span class="citation">[<a href="#ref-LL5huVs3">40</a>,<a href="#ref-yEstnIOT">41</a>]</span>.</p>
<p>Closest to natural images are applications of deep learning aimed at detection and recognition of melanoma, the deadliest form of skin cancer. Recent works included applications to both dermoscopy <span class="citation">[<a href="#ref-sLPsrfbl">42</a>,<a href="#ref-phRCihNB">43</a>]</span> and non-dermoscopic clinical photography images of skin lesions <span class="citation">[<a href="#ref-XnYNYoYB">4</a>,<a href="#ref-1AJUcl1KV">44</a>,<a href="#ref-O39LDkX">45</a>]</span>. For both modalities pre-training on natural images appears to be common model initialization that allows the use of very deep networks without overfitting. Reported performance is competitive or better compared to a board of certified dermatologists <span class="citation">[<a href="#ref-XnYNYoYB">4</a>,<a href="#ref-sLPsrfbl">42</a>]</span>. This approach is known as transfer learning (see Discussion).</p>
<p>Another fast emerging area of deep learning method applications is the detection of ophthalmological diseases such as diabetic retinopathy and age-related macular degeneration. Diagnosis of diabetic retinopathy through color fundus images became of interest for deep learning researchers and practitioners after the large labeled image set was made publicly available during the corresponding 2015 Kaggle competition <span class="citation">[<a href="#ref-ayTsooEM">46</a>]</span>. Most attempts included training a network from scratch <span class="citation">[<a href="#ref-ayTsooEM">46</a>,<a href="#ref-ayTsooEM">46</a>,<a href="#ref-14Ovc5nPg">47</a>]</span>, while Gulshan et al. <span class="citation">[<a href="#ref-1mJW6umJ">48</a>]</span> employed 48-layer Inception-v3 deep architecture pre-trained on natural images and demonstrated substantial increase over the state-of-the-art in both specificity and sensitivity. Interestingly, Leibig et al. <span class="citation">[<a href="#ref-14Ovc5nPg">47</a>]</span> proposed a method to estimate the uncertainty of deep networks in diabetic retinopathy diagnosis based on a recent theoretical insight on the link between dropout networks and approximate Bayesian inference. Such developments are important for the whole medical image analysis field, because they have a potential to provide information about a level of confidence for every black-box algorithm's classification result and, thus, improve pathologist-computer interaction. Deep networks were also recently applied to age-related macular degeneration detection, similarly demonstrating the power of transfer learning when training set is limited <span class="citation">[<a href="#ref-iBPOt78R">49</a>]</span> as well as the efficient use of a deep 16-layer architecture combined with EMR data for training set enrichment.</p>
<p>Mammography has been one area with numerous contributions <span class="citation">[<a href="#ref-VFw1VXDP">50</a>–<a href="#ref-5kfDbGhA">54</a>]</span>. In most of this work, researchers must work around a challenge typical for the domain - the limited number of well annotated training images. To expand the number and diversity of images, the researchers have employed approaches where they use adversarial examples <span class="citation">[<a href="#ref-Xxb4t3zO">53</a>]</span> or first train towards human-created features before subsequent fine tuning <span class="citation">[<a href="#ref-JK8NuXy3">51</a>]</span>. Adaptation to the medical image domain can be further improved by combining in the latter approach with other machine learning techniques, for example, as a cascade of deep learning and random forest models <span class="citation">[<a href="#ref-5kfDbGhA">54</a>]</span>. Using large dataset, Kooi et al. <span class="citation">[<a href="#ref-18cZbigDD">55</a>]</span> demonstrated that deep neural networks can outperform the traditional computer-aided diagnosis (CAD) system at low sensitivity and perform comparably at high sensitivity. They also compared network performance to certified screening radiologists on a patch level and found no significant difference between the network and the readers. Similarly, Geras et al. <span class="citation">[<a href="#ref-1AWC7HsO0">56</a>]</span> showed that both using large dataset and using multi-view network architecture help to improve classification performance. The presence of a publicly available large bank of well-annotated mammography images would aid in the application of deep neural networks to this area and shift research focus from model generalization to effective processing of large image sets. Deep network pre-trained on large annotated mammogram set can be helpful for related tasks that do not have as much data using transfer learning <span class="citation">[<a href="#ref-1ExJjVKvT">57</a>]</span>. Though this strategy has not yet been employed in this domain, high-quality feature detectors can be constructed from large collections of unlabeled images in an unsupervised context. The small number of labeled examples could be used for subsequent training. Similar strategies have been employed for EHR data where high-quality labeled examples are also difficult to obtain <span class="citation">[<a href="#ref-5x3uMSKi">58</a>]</span>.</p>
<p>In radiological image analysis, deep learning techniques are increasingly used even when dataset size is not big enough to train large capacity models from scratch <span class="citation">[<a href="#ref-1Fy5bcnCI">59</a>–<a href="#ref-Qve94Jra">62</a>]</span>. All these studies demonstrate successful transfer of features learnt from natural image datasets, such as ImageNet <span class="citation">[<a href="#ref-cBVeXnZx">63</a>]</span>. Rajkomar et al. <span class="citation">[<a href="#ref-x6HXFAS4">61</a>]</span> showed that a deep CNN trained on natural images can boost performance in radiology image classification. However, the target task required either re-training the initial model from scratch with special pre-processing or fine-tuning of the whole network on radiographs with heavy data augmentation to avoid overfitting. Shin et al. <span class="citation">[<a href="#ref-1GAyqYBNZ">60</a>]</span> compared various deep network architectures, dataset characteristics, and training procedures for computer tomography-based (CT) abnormality detection. They concluded that in case of three-dimensional data networks as deep as 22 layers can be useful for such problems despite the limited size of training datasets. However, they note, that choice of a specific architecture, parameter setting, and model fine-tuning needed is very problem and dataset-specific. Moreover, this type of tasks often depends on both lesion localization and appearance that pose challenges for CNN-based approaches. Straightforward attempts to capture useful information from full-size images in all three dimensions simultaneously make applications of standard neural network architectures computationally unfeasible due to the curse of dimensionality. Instead, two dimensional models are often used to either process image slices individually (2D), or aggregate information from a number of 2D projections in the native space (2.5D). Roth et al. compared 2D, 2.5D, and 3D CNNs on a number of tasks for computer-aided detection from CT scans and showed that 2.5D CNNs performed comparably well to 3D analogs, while requiring much less training time, especially on augmented training sets <span class="citation">[<a href="#ref-KseoWN2w">64</a>]</span>. Another advantage of 2D and 2.5D networks is a possibility to use widely available models pre-trained on natural images.</p>
<p>Similarly, in magnetic resonance image (MRI) analysis, limited size of training sets and large dimensionality represent challenges to deep learning applications. For example, Amit et al. <span class="citation">[<a href="#ref-SOi9mAC2">65</a>]</span> investigated the tradeoffs between using pre-trained models from a different domain and retraining a small-size CNN on MRI images. They showed that smaller network trained with sufficient data augmentation on few hundred images from a few dozen patients can outperform a pre-trained out-of-domain classifier. Nie et al. <span class="citation">[<a href="#ref-18EpaZ7QB">66</a>]</span> showed that multimodal, multi-channel 3D deep architecture was successful at learning high-level brain tumor appearance features jointly from MRI, functional MRI and diffusion MRI images, outperforming single-modality or 2D models. Overall, the variety of modalities, properties and sizes of training sets, the dimensionality of input, and, finally, the importance of end goals in medical image analysis are provoking a development of specialized deep neural network architectures, training and validation protocols, and input representations that are not characteristic of widely studied natural images.</p>
<p>Chest X-rays are a common radiological examination for screening and diagnosis of lung diseases. Although hospitals have accumulated a large number of raw radiology images and reports in Picture Archiving and Communication Systems and their related reports in Radiology Information System, it is not yet known how to effectively use them to learn the correlation between pathology categories and X-rays. In the last few years, deep learning methods showed remarkable results in chest X-ray image analysis <span class="citation">[<a href="#ref-apBChoyF">67</a>,<a href="#ref-PGi9g7yV">68</a>]</span>. However, it is both costly and time-consuming to annotate a large-scale fully- labeled corpus to facilitate the data-hungry deep learning models. As an alternative, Wang et al. <span class="citation">[<a href="#ref-PGi9g7yV">68</a>]</span> proposed to use weakly labeled images for training deep learning models. To generate weak labels for X-ray images, they applied a series of Natural Language Processing (NLP) techniques to the associated chest X-ray radiological reports. Specifically, they first extracted all diseases mentioned in the reports using a state-of-the-art NLP tool, then applied a newly developed negation and uncertainty detection tool (NegBio) to filter negative and equivocal findings in the reports. Evaluation on three independent datasets demonstrated that NegBio is highly accurate for detecting negative and equivocal findings (~90% in F-measure overall). These highly accurate results meet the need to generate a corpus with weak labels, which serves as a solid foundation for the later process of image classification. The resulting dataset (CXR-XIV <span class="citation">[<a href="#ref-Bi92V99U">69</a>]</span>) consists of 108,948 frontal-view chest X-ray images (from 32,717 patients) and each image is associated with one or more weakly-labeled pathology category (e.g. pneumonia and cardiomegaly) or &quot;normal&quot; otherwise. Further, Wang et al. <span class="citation">[<a href="#ref-PGi9g7yV">68</a>]</span> used this dataset with a unified weakly-supervised multi-label image classification framework, to detect common thoracic diseases. It showed superior performance over a benchmark using fully labeled data.</p>
<p>In addition to medical imaging, histology slides are also being analyzed with deep learning approaches <span class="citation">[<a href="#ref-dQCjqq0Q">70</a>]</span>. Ciresan et al. <span class="citation">[<a href="#ref-koEdZRcY">25</a>]</span> developed one of the earliest examples, winning the 2012 International Conference on Pattern Recognition's Contest on Mitosis Detection while achieving human competitive accuracy. Their approach uses what has become a standard convolutional neural network architecture trained on public data. In more recent work, Wang et al. <span class="citation">[<a href="#ref-mbEp6jNr">71</a>]</span> analyzed stained slides to identify cancers within slides of lymph node slices. The approach provided a probability map for each slide. On this task a pathologist has about a 3% error rate. The pathologist did not produce any false positives, but did have a number of false negatives. While the algorithm had about twice the error rate of a pathologist, the errors were not strongly correlated with those of a pathologist, suggesting that the two could be combined, theoretically, reducing the error rate to under 1%. In this area, these algorithms may be ready to incorporate into existing tools to aid pathologists. The authors' work suggests that this could reduce the false negative rate of such evaluations. This theme of an ensemble between deep learning algorithm and human expert may help overcome some of the challenges presented by data limitations.</p>
<p>One source of training examples with rich clinical annotations is the electronic health records. Recently Lee et al.<span class="citation">[<a href="#ref-SxsZyrVM">72</a>]</span> developed an approach to distinguish individuals with age-related macular degeneration from control individuals. They extracted approximately 100,000 images from structured electronic health records, which they used to train and evaluate a deep neural network. Combining this data resource with standard deep learning techniques, the authors reach greater than 93% accuracy. One item that is important to note with regards to this work is that the authors used their test set for evaluating when training had concluded. In other domains, this has resulted in a minimal change in the estimated accuracy <span class="citation">[<a href="#ref-CCS5KSIM">73</a>]</span>. However, there is not yet a single accepted standard within the field of biomedical research for such evaluations. We recommend the use of an independent test set wherever it is feasible. Despite this minor limitation, the work clearly illustrates the potential that can be unlocked from images stored in electronic health records.</p>
<p>These examples demonstrate that, except for few natural image-like problems (e.g. melanoma detection), biomedical imaging poses a number of challenges for deep learning applications. Dataset sizes are typically limited, annotations can be sparse, and images are often high-dimensional, multimodal, and multi-channel. Techniques like transfer learning, heavy dataset augmentation, multi-view and multi-stream architectures are used more commonly compared to natural image domain. Furthermore, sensitivity and specificity of a model in this case often can translate directly into a clinical value. Thus, results evaluation, uncertainty estimation, and model interpretation methods are also of great importance in this domain (see Discussion). Finally, there is a need for better pathologist-computer interaction techniques that will allow combining the power of deep learning methods with human expertise and lead to better-informed decisions for patient treatment and care.</p>
<h4 id="electronic-health-records">Electronic health records</h4>
<p>EHR data include substantial amounts of free text, which remains challenging to approach <span class="citation">[<a href="#ref-uDaRUyh9">74</a>]</span>. Often, researchers developing algorithms that perform well on specific tasks must design and implement domain- specific features <span class="citation">[<a href="#ref-sG3iVOTS">75</a>]</span>. These features capture unique aspects of the literature being processed. Deep learning methods are natural feature constructors. In recent work, the authors evaluated the extent to which deep learning methods could be applied on top of generic features for domain-specific concept extraction <span class="citation">[<a href="#ref-dO844vZn">76</a>]</span>. They found that performance was in line with, but did not exceed, existing state of the art methods. The deep learning method had performance lower than the best performing domain-specific method in their evaluation <span class="citation">[<a href="#ref-dO844vZn">76</a>]</span>. This highlights the challenge of predicting the eventual impact of deep learning on the field. This provides support that deep learning may impact the field by reducing the researcher time and cost required to develop specific solutions, but it may not lead to performance increases.</p>
<p>In recent work, Yoon et al.<span class="citation">[<a href="#ref-yUgE09ve">77</a>]</span> analyzed simple features using deep neural networks and found that the patterns recognized by the algorithms could be re-used across tasks. Their aim was to analyze the free text portions of pathology reports to identify the primary site and laterality of tumors. The only features the authors supplied to the algorithms that they evaluated were unigrams and bigrams. These are the counts for single words and two-word combinations in a free text document. They subset the full set of words and word combinations to the 400 most commonly used ones. The machine learning algorithms that they employed (naive Bayes, logistic regression, and deep neural networks) all performed relatively similarly on the task of identifying the primary site. However, when the authors evaluated the more challenging task, i.e. evaluating the laterality of each tumor, the deep neural network outperformed the other methods. Of particular interest, when the authors first trained a neural network to predict primary site and then repurposed those features as a component of a secondary neural network trained to predict laterality, the performance was higher than a laterality-trained neural network. This demonstrates how deep learning methods can repurpose features across tasks, improving overall predictions as the field tackles new challenges. For the further review of this type of approaches see Discussion.</p>
<p>Several authors have created reusable feature sets for medical terminologies using natural language processing (NLP) and neural embedding models, as popularized by Word2vec <span class="citation">[<a href="#ref-1GhHIDxuW">78</a>]</span>. A goal of learning terminologies for different entities in the same vector space is to find relationships between different domains (e.g. drugs and the diseases they treat). It is difficult for us to provide a strong statement on the broad utility of these methods. Manuscripts in this area tend to compare algorithms applied to the same data but lack a comparison against overall best-practices for one or more tasks addressed by these methods. Techniques have been developed for free text medical notes <span class="citation">[<a href="#ref-XQtuRkTU">79</a>]</span>, ICD and NDC, and claims data <span class="citation">[<a href="#ref-TwvauiTv">80</a>]</span>. Methods for neural embeddings learned from electronic health records have at least some ability to predict disease-disease associations and implicate genes with a statistical association with a disease <span class="citation">[<a href="#ref-1G2xP5yOM">81</a>]</span>. However, the evaluations performed did not differentiate between simple predictions (i.e. the same disease in different sites of the body) and non-intuitive ones. While promising, a lack of rigorous evaluations of the real-world utility of these kinds of features makes current contributions in this area difficult to evaluate. To examine the true utility, comparisons need to be performed against leading approaches (i.e. algorithms and data) as opposed to simply evaluating multiple algorithms on the same potentially limited dataset.</p>
<p>Identifying consistent subgroups of individuals and individual health trajectories from clinical tests is also an active area of research. Approaches inspired by deep learning have been used for both unsupervised feature construction and supervised prediction. Early work by Lasko et al. <span class="citation">[<a href="#ref-FLX0o7bL">82</a>]</span>, combined sparse autoencoders and Gaussian processes to distinguish gout from leukemia from uric acid sequences. Later work showed that unsupervised feature construction of many features via denoising autoencoder neural networks could dramatically reduce the number of labeled examples required for subsequent supervised analyses <span class="citation">[<a href="#ref-5x3uMSKi">58</a>,<a href="#ref-aM2Uy2ix">83</a>]</span>. In addition, it pointed towards learned features being useful for subtyping within a single disease. In a concurrent large-scale analysis of EHR data from 700,000 patients, Miotto et al. <span class="citation">[<a href="#ref-WrNCJ9sO">84</a>]</span> used a deep denoising autoencoder architecture applied to the number and co-occurrence of clinical events (&quot;DeepPatient&quot;) to learn a representation of patients. The model was able to predict disease trajectories within one year with over 90% accuracy and patient-level predictions were improved by up to 15% when compared to other methods. Razavian et al. <span class="citation">[<a href="#ref-c6MfDdWP">85</a>]</span> used a set of 18 common lab tests to predict disease onset using both CNN and LSTM architectures and demonstrated and improvement over baseline regression models. However, numerous challenges including data integration (patient demographics, family history, laboratory tests, text-based patient records, image analysis, genomic data) and better handling of streaming temporal data with many features, will need to be overcome before we can fully assess the potential of deep learning for this application area.</p>
<p>Still, recent work has also revealed domains in which deep networks have proven superior to traditional methods. Survival analysis models the time leading to an event of interest from a shared starting point, and in the context of EHR data, often associates these events to subject covariates. Exploring this relationship is difficult, however, given that EHR data types are often heterogeneous, covariates are often missing, and conventional approaches require the covariate-event relationship be linear and aligned to a specific starting point <span class="citation">[<a href="#ref-qXdO2aMm">86</a>]</span>. Early approaches, such as the Faraggi-Simon feed-forward network, aimed to relax the linearity assumption, but performance gains were lacking <span class="citation">[<a href="#ref-1921Mctzh">87</a>]</span>. Katzman et al. in turn developed a deep implementation of the Faraggi-Simon network that, in addition to outperforming Cox regression, was capable of comparing the risk between a given pair of treatments, thus potentially acting as recommender system <span class="citation">[<a href="#ref-1FE0F2pQ">88</a>]</span>. To overcome the remaining difficulties, researchers have turned to deep exponential families, a class of latent generative models that are constructed from any type of exponential family distributions <span class="citation">[<a href="#ref-pxdeuhMS">89</a>]</span>. The result was a deep survival analysis model capable of overcoming challenges posed by missing data and heterogeneous data types, while uncovering nonlinear relationships between covariates and failure time. They showed their model more accurately stratified patients as a function of disease risk score compared to the current clinical implementation.</p>
<p>There is a computational cost for these methods, however, when compared to traditional, non-network approaches. For the exponential family models, despite their scalability <span class="citation">[<a href="#ref-8RAYEOPl">90</a>]</span>, an important question for the investigator is whether he or she is interested in estimates of posterior uncertainty. Given that these models are effectively Bayesian neural networks, much of their utility simplifies to whether a Bayesian approach is warranted for a given increase in computational cost. Moreover, as with all variational methods, future work must continue to explore just how well the posterior distributions are approximated, especially as model complexity increases <span class="citation">[<a href="#ref-15lbUf0as">91</a>]</span>.</p>
<h5 id="challenges-and-opportunities-in-patient-categorization">Challenges and opportunities in patient categorization</h5>
<h6 id="generating-ground-truth-labels-can-be-expensive-or-impossible">Generating ground-truth labels can be expensive or impossible</h6>
<p>A dearth of true labels is perhaps among the biggest obstacles for EHR-based analyses that employ machine learning. Popular deep learning (and machine learning) methods are often used to tackle classification tasks and thus require ground-truth labels for training. For EHRs this can mean that researchers must hire multiple clinicians to manually read and annotate individual patients' records through a process called chart review. This allows researchers to assign &quot;true&quot; labels, i.e. those that match our best available knowledge. Depending on the application, sometimes the features constructed by algorithms also need to be manually validated and interpreted by clinicians. This can be time consuming and expensive <span class="citation">[<a href="#ref-1Ar4f4vfR">92</a>]</span>. Because of these costs, much of this research, including the work cited in this review, skips the process of expert review. Clinicians' skepticism for research without expert review may greatly dampen their enthusiasm for the work and consequently reduce its impact. To date, even well-resourced large national consortia have been challenged by the task of acquiring enough expert-validated labeled data. For instance, in the eMERGE consortia and PheKB database <span class="citation">[<a href="#ref-ziudr6hx">93</a>]</span>, most samples with expert validation contain only 100 to 300 patients. These datasets are quite small, even for simple machine learning algorithms. The challenge is greater for deep learning models with many parameters. While unsupervised and semi-supervised approaches can help with small sample sizes, the field would benefit greatly from large collections of anonymized records in which a substantial number of records have undergone expert review. This challenge is not unique to EHR-based studies. Work on medical images, omics data in applications for which detailed metadata are required, and other applications for which labels are costly to obtain will be hampered as long as abundant curated data are unavailable.</p>
<p>Successful approaches to date in this domain have sidestepped this challenge by making methodological choices that either reduce the need for labeled examples or that use transformations to training data to increase the number of times it can be used before overfitting occurs. For example, the unsupervised and semi-supervised methods that we have discussed reduce the need for labeled examples <span class="citation">[<a href="#ref-5x3uMSKi">58</a>]</span>. The anchor and learn framework <span class="citation">[<a href="#ref-A9JeoGV8">94</a>]</span> uses expert knowledge to identify high confidence observations from which labels can be inferred. The adversarial training example strategies that we have mentioned can reduce overfitting, if transformations are available that preserve the meaningful content of the data while transforming irrelevant features <span class="citation">[<a href="#ref-Xxb4t3zO">53</a>]</span>. While adversarial training examples can be easily imagined for certain methods that operate on images, it is more challenging to figure out what an equivalent transformation would be for a patient's clinical test results. Consequently, it may be hard to employ adversarial training examples, not to be confused with generative adversarial neural networks, with other applications. Finally, approaches that transfer features can also help use valuable training data most efficiently. Rajkomar et al. trained a deep neural network using generic images before tuning using only radiology images <span class="citation">[<a href="#ref-x6HXFAS4">61</a>]</span>. Datasets that require many of the same types of features might be used for initial training, before fine tuning takes place with the more sparse biomedical examples. Though the analysis has not yet been attempted, it is possible that analogous strategies may be possible with electronic health records. For example, features learned from the electronic health record for one type of clinical test (e.g. a decrease over time in a lab value) may transfer across phenotypes.</p>
<p>Methods to accomplish more with little high-quality labeled data are also being applied in other domains and may also be adapted to this challenge, e.g. data programming <span class="citation">[<a href="#ref-5Il3kN32">95</a>]</span>. In data programming, noisy automated labeling functions are integrated. Numerous writers have described data as the new oil <span class="citation">[<a href="#ref-daemz8Fm">96</a>,<a href="#ref-o8mib4CN">97</a>]</span>. The idea behind this metaphor is that data are available in large quantities, valuable once refined, and the underlying resource that will enable a data-driven revolution in how work is done. Contrasting with this perspective, Ratner, Bach, and Ré described labeled training data as &quot;The <em>New</em> New Oil&quot; <span class="citation">[<a href="#ref-hfcf5Hmi">98</a>]</span>. In this framing, data are abundant and not a scarce resource. Instead, new approaches to solving problems arise when labeled training data become sufficient to enable them. Based on our review of research on deep learning methods to categorize disease, the latter framing rings true.</p>
<p>We expect improved methods for domains with limited data to play an important role if deep learning is going to transform how we categorize states of human health. We don't expect that deep learning methods will replace expert review. We expect them to complement expert review by allowing more efficient use of the costly practice of manual annotation.</p>
<h6 id="data-sharing-is-hampered-by-standardization-and-privacy-considerations">Data sharing is hampered by standardization and privacy considerations</h6>
<p>To construct the types of very large datasets that deep learning methods thrive on, we need robust sharing of large collections of data. This is in part a cultural challenge. We touch on this challenge in the Discussion section. Beyond the cultural hurdles around data sharing, there are also technological hurdles related to sharing individual health records or deep models built from such records. This subsection deals primarily with these challenges.</p>
<p>EHRs are designed chiefly for clinical, administrative and financial purposes, such as patient care, insurance and billing <span class="citation">[<a href="#ref-FkSZ1qmz">99</a>]</span>. Science is at best a tertiary priority, presenting challenges to EHR-based research in general, and to deep learning research particularly. These difficulties can be grouped into three areas: local bias, wider standards and legal issues. Note these problems are not restricted to EHR but can also apply to any large biomedical dataset, e.g. clinical trial data.</p>
<p>Even within the same healthcare system, EHRs can be used differently <span class="citation">[<a href="#ref-11sli93ov">100</a>,<a href="#ref-y9ONtSZ9">101</a>]</span>. Individual users have unique usage patterns, with different departments and different hospitals having different priorities which code patients and introduce missing data in a non-random fashion <span class="citation">[<a href="#ref-7BctyA7f">102</a>]</span>. Patient data may be kept across several &quot;silos&quot; within a single health system. Even the most basic task of matching patients across systems can be challenging due to data entry issues <span class="citation">[<a href="#ref-4rTluXLs">103</a>]</span>. The situation is further exacerbated by the ongoing introduction, evolution and migration of EHR systems, especially where reorganized and acquired healthcare facilities have to merge. As a result, EHR can be less complete and less objective than expected.</p>
<p>In the wider picture, standards for EHRs are many and evolving. Proprietary systems, indifferent and scattered use of health information standards and controlled terminologies makes combining and comparison of data across systems challenging <span class="citation">[<a href="#ref-DPsQumQ2">104</a>,<a href="#ref-13filvWwr">105</a>]</span>. Further diversity arises from variation in languages, healthcare practices and demographics. Merging EHR gathered in different systems (and even under different assumptions) is challenging <span class="citation">[<a href="#ref-1CWhXZxos">106</a>]</span>.</p>
<p>Combining or replicating studies across systems thus requires controlling for both the above biases and dealing with mismatching standards. This has the practical effect of reducing cohort size, limiting statistical significance, preventing the detection of weak effects <span class="citation">[<a href="#ref-Fx5qVQlk">107</a>]</span> and restricting the number of parameters that can be trained in a model. Further, rules-based algorithms have been popular in EHR-based research but because these are developed at a single institution and trained with a specific patient population they do not transfer easily to other populations <span class="citation">[<a href="#ref-11OyzMl87">108</a>]</span>. For example, Wiley et al. <span class="citation">[<a href="#ref-qe90c1CL">109</a>]</span> showed that warfarin dosing algorithms often under-perform in African Americans, illustrating that some of these issues are unresolved even at a treatment best practices level. Lack of standardization also makes it challenging for investigators skilled in deep learning to enter the field, as numerous data processing steps must be performed before algorithms are applied.</p>
<p>Finally, even if data were perfectly consistent and compatible across systems, attempts to share and combine EHR data face considerable legal and ethical barriers. Patient privacy can severely restrict the sharing and use of EHR <span class="citation">[<a href="#ref-CVnO5njl">110</a>]</span>. Here again, standards are heterogeneous and evolving but often EHR data can often not be exported or even accessed directly for research purposes without appropriate consent. Once again, this has the effect of making data gathering more laborious, expansive and reducing sample size and study power.</p>
<p>Several technological solutions have been proposed in this direction, allowing access to sensitive data satisfying privacy and legal concerns. Software like DataShield <span class="citation">[<a href="#ref-SfxIiPJ1">111</a>]</span> and ViPAR <span class="citation">[<a href="#ref-1D6b3tMu9">112</a>]</span>, although not EHR specific, allows querying and combining of datasets and calculation of summary statistics across remote sites by &quot;taking the analysis to the data&quot;. The computation is carried out at the remote site. Conversely, the EH4CR project <span class="citation">[<a href="#ref-13filvWwr">105</a>]</span> allows analysis of private data by use of an inter-mediation layer that intreprets remote queries across internal formats and datastores and returns the results in a de-identified standard form, thus giving real-time consistent but secure access. Continuous Analysis <span class="citation">[<a href="#ref-Qh7xTLwz">113</a>]</span> can allow reproducible computing on private data. Using such techniques intermediate results can be automatically tracked and shared without sharing the original data. While none of these have been used in deep learning, the potential is there.</p>
<p>Even without sharing data, algorithms trained on confidential patient data may present security risks or accidentally allow for the exposure of individual level patient data. Tramer et al. <span class="citation">[<a href="#ref-ULSPV0rh">114</a>]</span> showed the ability to steal trained models via public APIs and Dwork and Roth <span class="citation">[<a href="#ref-v8Lp4ibI">115</a>]</span> demonstrate the ability to expose individual level information from accurate answers in a machine learning model. Attackers can use similar attacks to find out if particular data instance was present in the original training set for the machine learning model <span class="citation">[<a href="#ref-1HbRTExaU">116</a>]</span> - in this case, whether a person's record was present. This presents a potential hazard for approaches that aim to generate data. Choi et al. propose generative adversarial neural networks as a tool to make sharable EHR data <span class="citation">[<a href="#ref-xl1ijigK">117</a>]</span>; however, the authors did not take steps to protect the model from such attacks.</p>
<p>There are approaches to protect models, but they pose their own challenges. Training in a differentially private manner provides a limited guarantee that an algorithm's output will be equally likely to occur regardless of the participation of any one individual. The limit is determined by a single parameter which provides a quantification of privacy. Simmons et al. <span class="citation">[<a href="#ref-6XtEfQMC">118</a>]</span> present the ability to perform GWASs in a differentially private manner and Abadi et al. <span class="citation">[<a href="#ref-ucHUOABT">119</a>]</span> show the ability to train deep learning classifiers under the differential privacy framework. Federated learning <span class="citation">[<a href="#ref-TaPZBxYS">120</a>]</span> and secure aggregations <span class="citation">[<a href="#ref-U0ySdznJ">121</a>–<a href="#ref-b8DJ1u6W">123</a>]</span> are complementary approaches that reinforce differential privacy. Both aim to maintain privacy by training deep learning models from decentralized data sources such as personal mobile devices without transferring actual training instances. This is becoming of increasing importance with the rapid growth of mobile health applications. However, the training process in these approaches places constraints on the algorithms used and can make fitting a model substantially more challenging. In our own experience it can be trivial to train a model without differential privacy, but quite difficult to train one within the differential privacy framework. The problem can be particularly pronounced with small sample sizes.</p>
<p>While none of these problems are insurmountable or restricted to deep learning, they present challenges that cannot be ignored. Technical evolution in EHRs and data standards will doubtless ease - although not solve - the problems of data sharing and merging. More problematic are the privacy issues. Those applying deep learning to the domain should consider the potential of inadvertently disclosing the participants identity. Techniques that enable training on data without sharing the raw data may have a part to play. Training within a differential privacy framework may often be warranted.</p>
<h6 id="discrimination-and-right-to-an-explanation-laws">Discrimination and &quot;right to an explanation&quot; laws</h6>
<p>In April 2016, the European Union adopted new rules regarding the use of personal information, the General Data Protection Regulation (GDPR) <span class="citation">[<a href="#ref-7yE9K08a">124</a>]</span>. A component of these rules can be summed up by the phrase &quot;right to an explanation&quot;. Those who use machine learning algorithms must be able to explain how a decision was reached. For example, a clinician treating a patient who is aided by a machine learning algorithm may be expected to explain decisions that use the patient's data. The new rules were designed to target categorization or recommendation systems, which inherently profile individuals. Such systems can do so in ways that are discriminatory and unlawful <code>TODO: @traversc citation needed</code>.</p>
<p>As datasets become larger and more complex, we may begin to identify relationships in data that are important for human health but difficult to understand. The algorithms described in this review and others like them may become highly accurate and useful for various purposes, including within medical practice. However, to discover and avoid discriminatory applications it will be important to consider interpretability alongside accuracy. A number of properties of genomic and health care data will make this difficult.</p>
<p>First, research samples are frequently non-representative of the general population of interest; they tend to be disproportionately sick <span class="citation">[<a href="#ref-10shRODux">125</a>]</span>, male <span class="citation">[<a href="#ref-sOBzMC57">126</a>]</span>, and European in ancestry <span class="citation">[<a href="#ref-dKwyEWWF">127</a>]</span>. One well-known consequence of these biases in genomics is that penetrance is consistently lower in the general population than would be implied by case-control data, as reviewed in <span class="citation">[<a href="#ref-10shRODux">125</a>]</span>. Moreover, real genetic associations found in one population may not hold in other populations with different patterns of linkage disequilibrium (even when population stratification is explicitly controlled for; <span class="citation">[<a href="#ref-T3GG8iJN">128</a>]</span>). As a result, many genomic findings are of limited value for people of non-European ancestry<span class="citation">[<a href="#ref-dKwyEWWF">127</a>]</span> and may even lead to worse treatment outcomes for them. Methods have been developed for mitigating some of these problems in genomic studies <span class="citation">[<a href="#ref-10shRODux">125</a>,<a href="#ref-T3GG8iJN">128</a>]</span>, but it is not clear how easily they can be adapted for deep models that are designed specifically to extract subtle effects from high-dimensional data. For example, differences in the equipment that tended to be used for cases versus controls have led to spurious genetic findings (e.g. <span class="citation">[<a href="#ref-DmQPI43R">129</a>]</span>); in some contexts, it may not be possible to correct for all of these differences to the degree that a deep network is unable to use them. Moreover, the complexity of deep networks makes it difficult to determine when their predictions are likely to be based on such nominally-irrelevant features of the data (called &quot;leakage&quot; in other fields; <span class="citation">[<a href="#ref-889LsjDi">130</a>]</span>). When we are not careful with our data and models, we may inadvertently say more about the way the data was collected (which may involve a history of unequal access and discrimination) than about anything of scientific or predictive value. This fact can undermine the privacy of patient data <span class="citation">[<a href="#ref-889LsjDi">130</a>]</span> or lead to severe discriminatory consequences <span class="citation">[<a href="#ref-6co0adq">131</a>]</span>.</p>
<p>There is a small but growing literature on the prevention and mitigation of data leakage <span class="citation">[<a href="#ref-889LsjDi">130</a>]</span>, as well as a closely-related literature on discriminatory model behavior <span class="citation">[<a href="#ref-1ENxzq6pT">132</a>]</span>, but it remains difficult to predict when these problems will arise, how to diagnose them, and how to resolve them in practice. There is even disagreement about which kinds of algorithmic outcomes should be considered discriminatory <span class="citation">[<a href="#ref-11aqfNfQx">133</a>]</span>. Despite the difficulties and uncertainties, machine learning practitioners (and particularly those who use deep neural networks, which are challenging to interpret) must remain cognizant of these dangers and make every effort to prevent harm from discriminatory predictions. To reach their potential in this domain, deep learning methods will need to be interpretable. Researchers need to consider the extent to which biases may be learned by the model and whether or not a model is sufficiently interpretable to identify bias. We discuss the challenge of model interpretability more completely in the discussion section.</p>
<h6 id="applications-of-deep-learning-to-longitudinal-analysis">Applications of Deep Learning to Longitudinal Analysis</h6>
<p>Longitudinal analysis follows a population across time, for example, prospectively from birth or from the onset of particular conditions. In large patient populations, longitudinal analyses such as the Farmingham Heart Study <span class="citation">[<a href="#ref-N96QKgly">134</a>]</span> and the Avon Longitudinal Study of Parents and Children <span class="citation">[<a href="#ref-1FjSxrV1k">135</a>]</span> have yielded important insights into the development of disease and the factors contributing to health status. Yet, a common practice in EHR-based research is to take a point in time snapshot and convert patient data to a traditional vector for machine learning and statistical analysis. This results in loss of information as timing and order of events can provide insight into a patient's disease and treatment <span class="citation">[<a href="#ref-6RHepB1T">136</a>]</span>. Efforts to model sequences of events have shown promise <span class="citation">[<a href="#ref-ogs3PPp7">137</a>]</span> but require exceedingly large patient sizes due to discrete combinatorial bucketing. Lasko et al. <span class="citation">[<a href="#ref-FLX0o7bL">82</a>]</span> used autoencoders on longitudinal sequences of serum urine acid measurements to identify population subtypes. More recently, deep learning has shown promise working with both sequences (Convolutional Neural Networks) <span class="citation">[<a href="#ref-Ohd1Q9Xw">138</a>]</span> and the incorporation of past and current state (Recurrent Neural Networks, Long Short Term Memory Networks)<span class="citation">[<a href="#ref-HRXii6Ni">139</a>]</span>. This may be a particular area of opportunity for deep neural networks. The ability to discover relevant sequences of events from a large number of trajectories requires powerful and flexible feature construction methods - an area at which deep neural networks excel.</p>
<h2 id="deep-learning-to-study-the-fundamental-biological-processes-underlying-human-disease">Deep learning to study the fundamental biological processes underlying human disease</h2>
<p>The study of cellular structure and core biological processes -- transcription, translation, signaling, metabolism, etc. -- in humans and model organisms will greatly impact our understanding of human disease over the long horizon <span class="citation">[<a href="#ref-ru0hjGeQ">140</a>]</span>. Predicting how cellular systems are altered by genetic variation and respond to environmental perturbations remain daunting tasks. Deep learning offers new approaches for modeling biological processes and integrating multiple types of omic data <span class="citation">[<a href="#ref-8SMDF816">141</a>]</span>, which could eventually help predict how these processes are disrupted in disease. Recent work has already advanced our ability to identify and interpret genetic variants, study microbial communities, and predict protein structures (which relates to the problems discussed in the drug development section). In addition, unsupervised deep learning has enormous potential for discovering novel cellular states from gene expression, fluorescence microscopy, and other types of data that ultimately prove to be clinically relevant.</p>
<p>Progress has been rapid in genomics and imaging, fields where important tasks are readily adapted to well-established deep learning paradigms. One dimensional convolutional and recurrent neural networks are well-suited for important problems in protein binding of DNA and RNA, epigenomics, and RNA splicing. Two dimensional CNNs are ideal for segmentation, feature extraction, and classification in fluorescence microscopy images <span class="citation">[<a href="#ref-MmRGFVUu">16</a>]</span>. Other areas, such as cellular signaling, are biologically important but studied less-frequently to date <span class="citation">[<a href="#ref-rmjDc5rm">142</a>]</span>. This may be a consequence of data limitations or greater challenges in adapting neural network architectures to the available data. Here, we highlight several areas of investigation and assess how deep learning can move these fields forward.</p>
<h3 id="gene-expression">Gene expression</h3>
<p>Gene expression technologies characterize the abundance of many thousands of RNA transcripts within a given organism, tissue, or cell. This characterization can represent the underlying state of the given system and can be used to study heterogeneity across samples as well as how the system reacts to perturbation. While gene expression measurements have been traditionally made by quantitative polymerase chain reaction (qPCR), low-throughput fluorescence-based methods, and microarray technologies, the field has shifted in recent years to primarily performing RNA sequencing (RNA-seq) to catalog whole transcriptomes. As RNA-seq continues to fall in price and rise in throughput, applying deep learning to study gene expression data is likely to make training deep models more feasible. With increased modeling ability, deep learning approaches are likely to grow in popularity and lead to novel biological insights.</p>
<p>Already several deep learning approaches have been applied to gene expression data with varying aims. For instance, many researchers have applied unsupervised deep learning models to extract meaningful representations of gene modules or sample clusters. Denoising autoencoders have been used to cluster yeast expression microarrays into known modules representing cell cycle processes <span class="citation">[<a href="#ref-AnenJOuU">143</a>]</span> and also to stratify yeast strains based on chemical and mutational perturbations <span class="citation">[<a href="#ref-yVBx9Qx4">144</a>]</span>. Shallow (one hidden layer) denoising autoencoders have also been fruitful in extracting biological insight from thousands of <em>Pseudomonas aeruginosa</em> experiments <span class="citation">[<a href="#ref-1CFhfCyWN">145</a>,<a href="#ref-zuLdSQx3">146</a>]</span> and in aggregating features relevant to specific breast cancer subtypes <span class="citation">[<a href="#ref-PBiRSdXv">24</a>]</span>. These unsupervised approaches applied to gene expression data are powerful methods for aggregating features and identifying gene signatures that may otherwise be overlooked by alternative methods. An additional benefit of unsupervised approaches is that ground truth labels, which are often difficult to acquire or are incorrect, are nonessential. However, careful interpretation must be performed regarding how the genes are aggregated into features. Precisely attributing node activations to specific biological functions risks over-interpreting models and can lead to incorrect conclusions.</p>
<p>Deep learning approaches are also being applied to gene expression prediction tasks. For example, a deep neural network with three hidden layers outperformed linear regression in inferring the expression of over 20,000 target genes based on a representative, well-connected set of about 1,000 landmark genes <span class="citation">[<a href="#ref-12QQw9p7v">147</a>]</span>. However, while the deep learning model outperformed existing algorithms in nearly every scenario, the model still displayed poor performance. The paper was also limited by computational bottlenecks that required data to be split randomly into two distinct models and trained separately. It is unclear how much performance would have increased if not for computational restrictions. Alternatively, epigenetic data may have sufficient explanatory power for inference of gene expression. For instance, a convolutional neural network applied to histone modifications, termed DeepChrome, <span class="citation">[<a href="#ref-G10wkFHt">148</a>]</span> was shown to improve prediction accuracy of high or low expression over existing methods. Deep learning can also be useful for integrating different data types. For example, Liang et al. combined RBMs to integrate gene expression, DNA methylation, and miRNA data to define ovarian cancer subtypes <span class="citation">[<a href="#ref-1EtavGKI4">149</a>]</span>. While the aforementioned approaches are promising, many convert gene expression measurements to categorical or binary variables, thus ablating many complex gene expression signatures present in intermediate and relative numbers.</p>
<p>Deep learning applied to gene expression data is still in its infancy, but the future is bright. Many previously untestable hypotheses can now be interrogated as deep learning enables analysis of increasing amounts of data generated by new technologies. For example, the effects of cellular heterogeneity on basic biology and disease etiology can now be explored by single-cell RNA-seq and high-throughput fluorescence-based imaging, techniques that will benefit immensely from deep learning approaches.</p>
<h3 id="splicing">Splicing</h3>
<p>Pre-mRNA transcripts can be spliced into different isoforms by retaining or skipping subsets of exons, or including parts of introns, creating enormous spatiotemporal flexibility to generate multiple distinct proteins from a single gene. Unfortunately, this remarkable complexity can lend itself to defects that underlie many diseases <span class="citation">[<a href="#ref-QFK6GapR">150</a>]</span>. For instance, in Becker muscular dystrophy, a point mutation in dystrophin creates an exon splice silencer that induces skipping of exon 31. A recent study found that quantitative trait loci (QTLs) that affect splicing in lymphoblastoid cell lines are enriched within risk loci for schizophrenia, multiple sclerosis, and other immune diseases, implicating mis-splicing as a much more widespread feature of human pathologies than previously thought <span class="citation">[<a href="#ref-b6p6wxpC">151</a>]</span>.</p>
<p>Sequencing studies routinely return thousands of unannotated variants, but which cause functional changes in splicing, and if so, how? Prediction of a “splicing code” has been a holy grail over the past decade. Initial machine learning approaches used a naive Bayes model and a 2-layer Bayesian neural network with thousands of hand-derived sequence-based features to predict the probability of exon skipping <span class="citation">[<a href="#ref-11ETDdRKr">152</a>,<a href="#ref-8VPGUHcf">153</a>]</span>. With the advent of deep learning, more complex models were built that provided better predictive accuracy <span class="citation">[<a href="#ref-17sgPdcMT">154</a>,<a href="#ref-N0HBi8MH">155</a>]</span>. Importantly, these new approaches can take in multiple kinds of epigenomic measurements, as well as tissue identity and RNA binding partners of splicing factors. Deep learning is critical in furthering these kinds of integrative studies where different data types and inputs interact in unpredictable (often nonlinear) ways to create higher-order “features”, compared to earlier approaches that often assumed independence of features or required extensive human fine-tuning. Moreover, as in gene expression network analysis, interrogating the hidden nodes within neural networks will likely yield new biological insights into splicing. For instance, tissue-specific splicing mechanisms can be inferred by training networks on splicing data from different tissues, then searching for common versus distinctive nodes, a technique employed by Qin et al. for tissue-specific TF binding predictions <span class="citation">[<a href="#ref-Qbtqlmhf">156</a>]</span>.</p>
<p>A parallel effort has been to use more data with simpler models. An exhaustive study using readouts of splicing for millions of synthetic intronic sequences uncovered motifs that influence the strength of alternative splice sites <span class="citation">[<a href="#ref-mlqKTlZY">157</a>]</span>. Interestingly, they built a simple linear model using hexamer motif frequencies that successfully generalized to exon skipping: in a limited analysis using SNPs from three genes, it predicted exon skipping with three times the accuracy of Xiong et al.’s deep learning-based framework. This case is instructive in that clever sources of data, not just more descriptive models, are still critical in yielding novel insights.</p>
<p>We already understand how mis-splicing of a single gene can cause diseases such as Duchenne muscular dystrophy. The challenge now is to uncover how genome-wide alternative splicing underlies complex, non-Mendelian diseases such as autism, schizophrenia, Type 1 diabetes, and multiple sclerosis <span class="citation">[<a href="#ref-CNz9HwZ3">158</a>]</span>. As a proof of concept, Xiong et al. <span class="citation">[<a href="#ref-17sgPdcMT">154</a>]</span> sequenced five ASD and 12 control samples, each with an average of 42,000 rare variants, and identified mis-splicing in 19 genes with neural functions. Deep learning will allow scientists and clinicians to rapidly profile thousands of unannotated variants for functional effects on splicing and nominate candidates for further investigation. Moreover, these nonlinear algorithms can deconvolve the effects of multiple variants on a single splice event without the need to perform combinatorial in vitro experiments.</p>
<p>Our end goal is to predict an individual’s tissue-specific, exon-specific splicing patterns from their genome sequence and other measurements. Knowing exactly which genes are mis-spliced in each tissue could enable a new branch of precision diagnostics that also stratifies patients and suggests targeted therapies to correct splicing defects. A continued focus on interpreting the “black box” of deep neural networks, along with integrating diverse data sources, will help us better understand the basic determinants of splicing and its links to complex disease, which will lead to novel diagnostics and therapeutics.</p>
<h3 id="transcription-factors-and-rna-binding-proteins">Transcription factors and RNA-binding proteins</h3>
<p>Transcription factors (TFs) and RNA-binding proteins are key components in gene regulation and higher-level biological processes. While high-throughput sequencing techniques such as chromatin immunoprecipitation and massively parallel DNA sequencing (ChIP-seq) have been able to accurately identify targets for TFs, these experiments are both time consuming and expensive. Thus, there is a need to computationally predict binding sites and understand binding specifities de novo from sequence data. In this section we focus on TFs, with the understanding that deep learning methods applied to TFs will also be broadly applicable to RNA-binding proteins, though RNA-specific models do exist <span class="citation">[<a href="#ref-qnKdqG0P">159</a>]</span>.</p>
<p>TFs are regulatory proteins that bind to certain genomic loci and control the rate of mRNA production. ChIP-seq and related technologies are able to identify highly likely binding sites for a certain TF, and databases such as ENCODE <span class="citation">[<a href="#ref-1Bs5k1MVg">160</a>]</span> have made freely available ChIP-seq data for hundreds of different TFs across many laboratories. In order to computationally predict transcription factor binding sites (TFBSs) on a DNA sequence, researchers initially used consensus sequences and position weight matrices to match against a test sequence <span class="citation">[<a href="#ref-ywDQIvZJ">161</a>]</span>. Simple neural network classifiers were then proposed to differentiate positive and negative binding sites but did not show significant improvements over the weight matrix matching methods <span class="citation">[<a href="#ref-uZvDdFZo">162</a>]</span>. Later, SVM techniques outperformed the generative methods by using k-mer features <span class="citation">[<a href="#ref-JxuQvvyk">163</a>,<a href="#ref-138dgb9Ca">164</a>]</span>, but string kernel-based SVM systems are limited by their expensive computational cost, which is proportional to the number of training and testing sequences.</p>
<p>With the advent of deep learning, Alipanahi et al. <span class="citation">[<a href="#ref-2UI1BZuD">165</a>]</span> showed that convolutional neural network models could achieve state of the art results on the TFBS task and are scalable to a large number of genomic sequences. Lanchantin et al. <span class="citation">[<a href="#ref-Dwi2eAvT">166</a>]</span> introduced several new convolutional and recurrent neural network models that further improved TFBS predictive accuracy. Due to the motif-driven nature of the TFBS task, most architectures have been convolution-based <span class="citation">[<a href="#ref-182UhQqzp">167</a>]</span>. While many models for TFBS prediction resemble computer vision and natural language processing (NLP) tasks, it is important to note that DNA sequence tasks are fundamentally different than NLP tasks, and thus the models should be adapted from traditional deep learning models in order to account for such differences. For example, motifs may appear in either strand of a DNA sequence, resulting in two different forms of the motif (forward and reverse complement) due to complementary base pairing. To handle this issue, Shrikumar et al. <span class="citation">[<a href="#ref-iEmvzeT8">168</a>]</span> created a convolutional model that can find motifs in both directions. Since deep learning for protein binding prediction is still in early stages, we expect to see an increase in domain-specific architectures for this task.</p>
<p>Despite these advances, several challenges remain. First, because the inputs (ChIP-seq measurements) are continuous and most current algorithms are designed to produce binary outputs (whether or not there is TF binding at a particular site), false positives or false negatives can result depending on the threshold chosen by the algorithm. Second, most methods predict binding of TFs at sites in isolation, whereas in reality multiple TFs may compete for binding at a single site or act synergistically to co-occupy it. Fortunately, multi-task models are rapidly improving at simultaneous prediction of many TFs' binding at any given site <span class="citation">[<a href="#ref-2UI1BZuD">165</a>]</span>. Third, it is unclear exactly how to define a non-binding or &quot;negative&quot; site in the training data, since the number of positive binding sites of a particular TF is relatively small with respect to the total number of base-pairs in DNA (see Discussion).</p>
<p>While deep learning-based models can automatically extract features for TFBS prediction at the sequence level, they often cannot predict binding patterns for cell types or conditions that have not been previously studied. One solution could be to introduce a multimodal model that, in addition to sequence data, incorporates cell-line specific features such as chromatin accessibility, DNA methylation, or gene expression. Without cell-specific features, another solution could be to use domain adaptation methods where we train our model on a source cell type and use unsupervised feature extraction methods to predict on a target cell type. <span class="citation">[<a href="#ref-Qbtqlmhf">156</a>]</span> predicts binding in new cell type-TF pairs, but the cell types must be in the training set for other TFs besides the target TF. A more general domain transfer model across cell types would be more useful.</p>
<p>Critically, deep learning can also provide useful biological insights into TF binding. Lanchantin et al. <span class="citation">[<a href="#ref-Dwi2eAvT">166</a>]</span> and Shrikumar et al. <span class="citation">[<a href="#ref-xAbGxia4">169</a>]</span> developed tools to visualize TF motifs learned from TFBS classification tasks. Alipanahi et al. <span class="citation">[<a href="#ref-2UI1BZuD">165</a>]</span> also introduced mutation maps, where they could easily mutate, add, or delete base pairs in a sequence and see how the model changed its prediction. This would be very time consuming in a lab setting, but was easy to simulate using their model. As we learn to better visualize and analyze the hidden nodes within deep learning models, our understanding of TF binding motifs and dynamics will likely improve.</p>
<h3 id="promoters-enhancers-and-related-epigenomic-tasks">Promoters, enhancers, and related epigenomic tasks</h3>
<p>Identification of promoters and other cis-regulatory elements (CREs) presents an obvious use case for deep learning. Transcriptional control is undoubtedly a vital -- and early -- part of the regulation of gene expression. An abundance of sequence and associated functional data (e.g. ENCODE <span class="citation">[<a href="#ref-1Bs5k1MVg">160</a>]</span> and ExAC <span class="citation">[<a href="#ref-fSpvdh5l">170</a>]</span>) exists across species. At the same time, studies of gene regulation have often focused on the protein (binding) rather than promoter level <span class="citation">[<a href="#ref-19jjiGHWc">171</a>]</span>, perhaps due to the ill-defined nature of CREs. A promoter itself can be seen as an assemblage of &quot;active&quot; binding sites for transcription factors interspersed by less-characterized and perhaps functionally silent spacer regions. However, the sequence signals that control the start and stop of transcription and translation are still not well understood, compounded by incomplete understanding of alternative transcripts and the context for these alternatives. Sequence similarity is poor even between functionally correlated genes. While homologs might be studied for insight, they may not exist or may be just as poorly characterized.</p>
<p>Recognizing enhancers presents additional challenges. Enhancers may be up to one million base pairs upstream or downstream from the target promoter, on either strand, even within the introns of other genes <span class="citation">[<a href="#ref-8yA3foA6">172</a>]</span>. They do not necessarily operate on the nearest gene and may in fact effect multiple genes. Their activity is frequently tissue- or context-specific. A substantial fraction of enhancers displays modest or no conservation across species. There is no universal enhancer sequence signal or marker for enhancers, and some literature suggests that enhancers and promoters may be just categories along a spectrum <span class="citation">[<a href="#ref-J0PJHcHK">173</a>]</span>. One study <span class="citation">[<a href="#ref-5zmE7Qkb">174</a>]</span> even showed that only 33% of predicted regulatory regions could be validated, while a class of &quot;weak&quot; predicted enhancers were strong drivers of expression. Yet there is growing evidence for their vast ubiquity, making them possibly the predominant functional non-coding element. Thus, identifying enhancers is critical yet the search space is large.</p>
<p>While prior (non-deep learning) approaches have made steady improvements on promoter prediction, there is little consensus on the best approach and performance is poor. Typically algorithms will recognize only half of all promoters, with an accompanying high false positive rate <span class="citation">[<a href="#ref-huFxo9OA">175</a>]</span>. Methods with better sensitivity generally do so at the cost of poorer specificity. Conventional identification of enhancers has leaned heavily on simple conservation or laborious experimental techniques, with only moderate sensitivity and specificity. For example, while chromatin accessibility has often been used for identifying enhancers, this also &quot;recognizes&quot; a wide variety of other functional elements, like promoters, silencers, and repressors.</p>
<p>The complex nature of CREs (and our ignorance at to what are the important features of them) is therefore a good subject for deep learning approaches. Indeed, neural networks were used for promoter recognition as early as 1996, albeit with mixed results <span class="citation">[<a href="#ref-3Ew5V1iC">176</a>]</span>. Since then, there has been much work in applying deep learning to this area, although little in the way of comparative studies or formal benchmarks. We will therefore focus on a few recent characteristic studies to outline the state of the art and extant problems.</p>
<p>Most broadly, Kelley et al. <span class="citation">[<a href="#ref-2CbHXoFn">177</a>]</span> trained CNNs on DNA accessibility datasets, getting a marked improvement on previous methods, albeit still with a high false positive rate. (Note as above, using DNA accessibility conflates enhancers with other functional sites.) This study also featured a useful interpretability approach, introducing known protein binding motifs into sequences and measuring the change in predicted accessibility.</p>
<p>Umarov et al. <span class="citation">[<a href="#ref-as2HfoSh">178</a>]</span> demonstrated the use of CNNs in recognizing promoter sequences, achieving markedly better performance than conventional methods (sensitivity and specificity exceeding 90%). While some results were achieved over bacterial promoters (which are considerably simpler in structure), surprisingly roughly similar performance was found for human promoters. This work also included a promising and simple method for interpretability (randomly substituting bases in a recognized promoter region, then checking for a change in recognition) that would be useful to exploit more widely.</p>
<p>Xu et al. <span class="citation">[<a href="#ref-jV2YerUS">179</a>]</span> applied CNNs to the detection of enhancers, achieving incremental improvements in specificity and sensitivity over previous SVM-based approach, and markedly better performance for cell-specific enhancers. A massive improvement in speed was also achieved. Additionally, they compared the performance of different CNN architectures, finding that while layers for batch normalization improved performance, surprisingly deeper architectures decreased performance.</p>
<p>Singh et al. <span class="citation">[<a href="#ref-14TqLB9iZ">180</a>]</span> also used batch normalization, approaching the problem of predicting enhancer-promoter interactions from solely the sequence and location of putative enhancers and promoters in a particular cell type. Performance was comparative to state-of-the-art conventional techniques that used the whole gamut of full functional genomic and non-sequence data.</p>
<p>Given the conflation between different CREs, the study of Li et al. <span class="citation">[<a href="#ref-1HbQQcY2q">181</a>]</span> is particularly interesting. They used a feed-forward neural network to distinguish classes of CRES and activity states. Active enhancers and promoters could be easily be distinguished, as could active and inactive elements. Perhaps unsurprisingly, it was difficult to distinguish between inactive enhancers and promoters. They also investigated the power of sequence features to drive classification, finding that beyond CpG islands, few were useful.</p>
<p>In summary, deep learning is a promising approach for identifying CREs, able to interrogate sequence features that are complex and ill-understood, already offering marked improvements on the prior state of the art. However, the exact methodology is up for debate and needs examination and more comparative study. Work needs to be done in understanding the best architecture to be used. The challenges in predicting TF binding -- lack of large gold standard datasets, model interpretation, and definition negative examples -- are pertinent to CRE identification as well. Furthermore, the quality and meaning of training data needs to be closely considered, given that a &quot;promoter&quot; or &quot;enhancer&quot; may only be putative or dependent on the experimental method or context of identification. Else we risk building detectors not for CREs but putative CREs. Although most deep learning studies in this area currently focus on predicting the 1D location of enhancers, modeling 3D chromatin conformations, enhancer-promoter interactions <span class="citation">[<a href="#ref-14TqLB9iZ">180</a>]</span>, and enhancer-target gene interactions will be critical for understanding transcriptional regulation.</p>
<h3 id="micro-rna-binding">Micro-RNA binding</h3>
<p>Prediction of microRNAs (miRNAs) in the genome as well as miRNA targets is of great interest, as they are critical components of gene regulatory networks and are often conserved across great evolutionary distance <span class="citation">[<a href="#ref-yVKIhIAf">182</a>,<a href="#ref-8lpCCppx">183</a>]</span>. While many machine learning algorithms have been applied to solve these prediction tasks, they currently require extensive feature selection and optimization. For instance, one of the most widely adopted tools for miRNA target prediction, TargetScan, trained multiple linear regression models on 14 hand-curated features including structural accessibility of the target site on the mRNA, the degree of site conservation, and predicted thermodynamic stability of the miRNA:mRNA complex <span class="citation">[<a href="#ref-12vPQi3gp">184</a>]</span>. Some of these features, including structural accessibility, are imperfect or empirically derived. In addition, current algorithms suffer from low specificity <span class="citation">[<a href="#ref-1GwC1ll6h">185</a>]</span>.</p>
<p>As in other applications, deep learning promises to achieve equal or better performance in predictive tasks by automatically engineering complex features to minimize an objective function. Two recently published tools use different recurrent neural network-based architectures to perform miRNA and target prediction with solely sequence data as input <span class="citation">[<a href="#ref-1GwC1ll6h">185</a>,<a href="#ref-1TeyWffV">186</a>]</span>. Though the results are preliminary and still based on a validation set rather than a completely independent test set, they were able to predict microRNA target sites with 15-25% higher specificity and sensitivity than TargetScan. Excitingly, these tools seem to show that RNNs can accurately align sequences and predict bulges, mismatches, and wobble base pairing without requiring the user to input secondary structure predictions or thermodynamic calculations.</p>
<p>Further incremental advances in neural-network approaches for miRNA and target prediction will likely be sufficient to meet the current needs of systems biologists and other researchers, who use prediction tools mainly to nominate candidates that are then tested experimentally. Similar to other applications, the major contribution of deep learning will be to deliver deep insights into the biology of miRNA targeting as we learn to interrogate the hidden nodes within neural networks.</p>
<h3 id="protein-secondary-and-tertiary-structure">Protein secondary and tertiary structure</h3>
<p>Proteins play fundamental roles in almost all biological processes, and understanding their structure is critical for basic biology and drug development. UniProt currently has about 94 million protein sequences, yet fewer than 100,000 proteins across all species have experimentally-solved structures in Protein Data Bank (PDB). As a result, computational structure prediction is essential for a majority of proteins. However, this is very challenging, especially when similar solved structures (called templates) are not available in PDB. Over the past several decades, various computational methods have been developed to predict aspects of protein structure such as secondary structure, torsion angles, solvent accessibility, inter-residue contact maps, disorder regions, and side-chain packing. In recent years, various deep learning architectures have been utilized, including deep belief networks, LSTM (long short-term memory), deep convolutional neural networks, and deep convolutional neural fields (DeepCNF) <span class="citation">[<a href="#ref-UO8L6nd">29</a>,<a href="#ref-pNoAbBEu">187</a>]</span>.</p>
<p>Here we focus on deep learning methods for two representative sub-problems: secondary structure prediction and contact map prediction. Secondary structure refers to local conformation of a sequence segment, while a contact map contains information on all residue-residue contacts. Secondary structure prediction is a basic problem and an almost essential module of any protein structure prediction package. Contact prediction is much more challenging than secondary structure prediction, but it has a much larger impact on tertiary structure prediction. In recent years, the accuracy of contact prediction has significantly improved <span class="citation">[<a href="#ref-BhfjKSY3">27</a>,<a href="#ref-7atXz0r">188</a>–<a href="#ref-10dNuD89l">190</a>]</span>.</p>
<p>Protein secondary structure can exhibit three different states (alpha helix, beta strand, and loop regions) or eight finer-grained states. Q3 and Q8 accuracy pertain to 3-state or 8-state predictions, respectively. Several groups <span class="citation">[<a href="#ref-ZzaRyGuJ">28</a>,<a href="#ref-1AlhRKQbe">191</a>,<a href="#ref-UpFrhdJf">192</a>]</span> initiated the application of deep learning to protein secondary structure prediction, but were unable to achieve significant improvement over the de facto standard method PSIPRED <span class="citation">[<a href="#ref-Aic7UyXM">193</a>]</span>, which uses two shallow feedforward neural networks. In 2014, Zhou and Troyanskaya demonstrated that they could improve Q8 accuracy by using a deep supervised and convolutional generative stochastic network <span class="citation">[<a href="#ref-8t43CQ9m">194</a>]</span>. In 2016 Wang et al. developed a DeepCNF model that significantly improved Q3 and Q8 accuracy as well as prediction of solvent accessibility and disorder regions <span class="citation">[<a href="#ref-UO8L6nd">29</a>,<a href="#ref-pNoAbBEu">187</a>]</span>. DeepCNF was the first tool to achieve Q3 accuracy of 84-85%, much higher than the 80% accuracy standard maintained by PSIPRED for more than 10 years. This improvement may be mainly due to the ability of convolutional neural fields to capture long-range sequential information, which is important for beta strand prediction. Nevertheless, improving secondary structure prediction from 80% to 84-85% is unlikely to result in a commensurate improvement in tertiary structure prediction since secondary structure mainly reflects coarse-grained local conformation of a protein structure.</p>
<p>Protein contact prediction and contact-assisted folding (i.e. folding proteins using predicted contacts as restraints) represents a promising new direction for <em>ab initio</em> folding of proteins without good templates in PDB. Co-evolution analysis is effective for proteins with a very large number (&gt;1000) of sequence homologs <span class="citation">[<a href="#ref-10dNuD89l">190</a>]</span>, but otherwise fares poorly for proteins without many sequence homologs. By combining co-evolution information with a few other protein features, shallow neural network methods such as MetaPSICOV <span class="citation">[<a href="#ref-7atXz0r">188</a>]</span> and CoinDCA-NN <span class="citation">[<a href="#ref-kqjqFesT">195</a>]</span> have shown some advantage over pure co-evolution analysis for proteins with few sequence homologs, but their accuracy is still far from satisfactory. In recent years, deeper architectures have been explored for contact prediction, such as CMAPpro <span class="citation">[<a href="#ref-xdoT1yUx">196</a>]</span>, DNCON <span class="citation">[<a href="#ref-18bNbDNlc">197</a>]</span> and PConsC <span class="citation">[<a href="#ref-F13xtRbV">198</a>]</span>. However, blindly tested in the well-known CASP competitions, these methods did not show any advantage over MetaPSICOV <span class="citation">[<a href="#ref-7atXz0r">188</a>]</span>.</p>
<p>Recently, Wang et al. proposed the deep learning method RaptorX-Contact <span class="citation">[<a href="#ref-BhfjKSY3">27</a>]</span>, which significantly improves contact prediction over MetaPSICOV and pure co-evolution methods, especially for proteins without many sequence homologs. It employs a network architecture formed by one 1D residual neural network and one 2D residual neural network. Blindly tested in the latest CASP competition (i.e. CASP12 <span class="citation">[<a href="#ref-zScWGveU">199</a>]</span>), RaptorX-Contact ranked first in F1 score (a widely-used performance metric combining sensitivity and specificity) on free-modeling targets as well as the whole set of targets. In CAMEO (which can be interpreted as a fully-automated CASP) <span class="citation">[<a href="#ref-u9uApoaB">200</a>]</span>, its predicted contacts were also able to fold proteins with a novel fold and only 65-330 sequence homologs. This technique also worked well on membrane proteins even when trained on non-membrane proteins <span class="citation">[<a href="#ref-39RPiE10">201</a>]</span>. RaptorX-Contact performed better mainly due to introduction of residual neural networks and exploitation of contact occurrence patterns by simultaneously predicting all the contacts in a single protein.</p>
<p>Taken together, <em>ab initio</em> folding is becoming much easier with the advent of direct evolutionary coupling analysis and deep learning techniques. We believe it is still possible to further improve contact prediction for proteins with fewer than 1000 homologs by studying new deep network architectures. However, it is unclear whether there is an effective way to use deep learning to improve prediction for proteins with almost no sequence homologs. Finally, the deep learning methods summarized above also apply to interfacial contact prediction for protein complexes, but may be less effective since on average protein complexes have fewer sequence homologs.</p>
<h3 id="morphological-phenotypes">Morphological phenotypes</h3>
<p>A field poised for dramatic revolution by deep learning is bioimage analysis. Thus far, the primary use of deep learning for biological images has been for segmentation - that is, for the identification of biologically relevant structures in images such as nuclei, infected cells, or vasculature, in fluorescence or even brightfield channels <span class="citation">[<a href="#ref-40EG4ZEU">202</a>]</span>. Once so-called regions of interest have been identified, it is often straightforward to measure biological properties of interest, such as fluorescence intensities, textures, and sizes. Given the dramatic successes of deep learning in biological imaging, we simply refer to articles that review recent advancements <span class="citation">[<a href="#ref-MmRGFVUu">16</a>,<a href="#ref-40EG4ZEU">202</a>,<a href="#ref-TutLhFSz">203</a>]</span>. We believe deep learning will become a commonplace tool for biological image segmentation once user-friendly tools exist.</p>
<p>We anticipate an additional kind of paradigm shift in bioimaging that will be brought about by deep learning: what if images of biological samples, from simple cell cultures to three-dimensional organoids and tissue samples, could be mined for much more extensive biologically meaningful information than is currently standard? For example, a recent study demonstrated the ability to predict lineage fate in hematopoietic cells up to three generations in advance of differentiation <span class="citation">[<a href="#ref-On4vW5aU">204</a>]</span>. In biomedical research, by far the most common paradigm is for biologists to decide in advance what feature to measure in images from their assay system. Although classical methods of segmentation and feature extraction can produce hundreds of metrics per cell in an image, deep learning is unconstrained by human intuition and can in theory extract more subtle features through its hidden nodes. Already, there is evidence deep learning can surpass the efficacy of classical methods <span class="citation">[<a href="#ref-gllSeTW">205</a>]</span>, even using generic deep convolutional networks trained on natural images <span class="citation">[<a href="#ref-BMg062hc">206</a>]</span>, known as transfer learning.</p>
<p>The impact of further improvements on biomedicine could be enormous. Comparing cell population morphologies using conventional methods of segmentation and feature extraction has already proven useful for functionally annotating genes and alleles, identifying the cellular target of small molecules, and identifying disease-specific phenotypes suitable for drug screening <span class="citation">[<a href="#ref-hkKO4QYl">207</a>–<a href="#ref-McjXFLLq">209</a>]</span>. Deep learning would bring to these new kinds of experiments - known as image-based profiling or morphological profiling - a higher degree of accuracy, stemming from the freedom from human-tuned feature extraction strategies. Perhaps most excitingly, focused characterization of these higher-level features will likely lead to new and valuable biological insights.</p>
<h3 id="single-cell">Single-cell</h3>
<p>Single-cell methods are generating extreme excitement as biologists recognize the vast heterogeneity within unicellular species and between cells of the same tissue type in the same organism <span class="citation">[<a href="#ref-1AWC7HsO0">56</a>]</span>. For instance, tumor cells and neurons can both harbor extensive somatic variation <span class="citation">[<a href="#ref-1GvfSy48x">210</a>]</span>. Understanding single-cell diversity in all its dimensions — genetic, epigenetic, transcriptomic, proteomic, morphologic, and metabolic — is key if precision medicine is to be targeted not only to a specific individual, but also to specific pathological subsets of cells. Single-cell methods also promise to uncover a wealth of new biological knowledge. A sufficiently large population of single cells will have enough representative “snapshots” to recreate timelines of rapid biological processes. If tracking processes over time is not the limiting factor, single cell techniques can provide maximal resolution compared to averaging across all cells in bulk tissue, enabling the study of transcriptional bursting with single-cell FISH or the heterogeneity of epigenetic patterns with single-cell Hi-C or ATAC-seq <span class="citation">[<a href="#ref-QafUwNKn">211</a>,<a href="#ref-v97iPXDw">212</a>]</span>.</p>
<p>However, large challenges exist in studying single cells. Relatively few cells can be assayed at once using current droplet, imaging, or microwell technologies, and low-abundance molecules or modifications may not be detected by chance in a phenomenon known as dropout. To solve this problem, Angermueller et al. <span class="citation">[<a href="#ref-19EJTHByG">213</a>]</span> trained a neural network to predict the presence or absence of methylation of a specific CpG site in single cells based on surrounding methylation signal and underlying DNA sequence, achieving several percentage points of improvement compared to random forests or deep networks trained only on CpG or sequence information. Similar deep learning methods have been applied to impute low-resolution ChIP-seq signal from bulk tissue with great success, and they could easily be adapted to single cell data <span class="citation">[<a href="#ref-Qbtqlmhf">156</a>,<a href="#ref-XimuXZlz">214</a>]</span>. Deep learning has also been useful for dealing with batch effects <span class="citation">[<a href="#ref-T2Md9xLY">215</a>]</span>.</p>
<p>Examining populations of single cells can reveal biologically meaningful subsets of cells as well as their underlying gene regulatory networks <span class="citation">[<a href="#ref-1HPu3R2B4">216</a>]</span>. Unfortunately, machine learning generally struggles with unbalanced data — when there are many more inputs of class 1 than class 2 — because prediction accuracy is usually evaluated over the entire dataset. To tackle this challenge, Arvaniti et al. <span class="citation">[<a href="#ref-r3Gbjksq">217</a>]</span> classified healthy and cancer cells expressing 25 markers by using the most discriminative filters from a CNN trained on the data as a linear classifier. They achieved an impressive precision of 50% to 90% with 80% recall on cells where the subset percentage ranged from 0.1 to 1%, which significantly outperformed logistic regression and distance-based outlier detection methods. However, they did not benchmark against random forests, which tend to be better with unbalanced data, or against the neural network itself, and their data was fairly low dimensional. Future work will be needed to establish the utility of deep learning in cell subset identification, but the stunning improvements in image classification over the past 5 years <span class="citation">[<a href="#ref-j7KrVyi8">218</a>]</span> suggest that this goal will be achievable.</p>
<p>The sheer quantity of “omic” information that can be obtained from each cell, as well as the number of cells in each dataset, uniquely position single-cell data to benefit from deep learning. In the future, lineage tracing could be revolutionized by using autoencoders to reduce the feature space of transcriptomic or variant data followed by algorithms to learn optimal cell differentiation trajectories <span class="citation">[<a href="#ref-Oljj2W96">219</a>]</span>, or by feeding cell morphology and movement into neural networks <span class="citation">[<a href="#ref-On4vW5aU">204</a>]</span>. Reinforcement learning algorithms <span class="citation">[<a href="#ref-2gn6PKkv">220</a>]</span> could be trained on the evolutionary dynamics of cancer cells or bacterial cells undergoing selection pressure and reveal whether patterns of adaptation are random or deterministic, allowing us to develop therapeutic strategies that forestall resistance. It will be exciting to see the creative applications of deep learning to single-cell biology that emerge over the next few years.</p>
<h3 id="metagenomics">Metagenomics</h3>
<p>Metagenomics, which refers to the study of genetic material -- 16S rRNA and/or whole-genome shotgun DNA -- from microbial communities, has revolutionized the study of micro-scale ecosystems within us and around us. In recent years, machine learning has proved to be a powerful tool for metagenomic analysis. 16S rRNA has long been used to deconvolve mixtures of microbial genomes, yet this ignores &gt;99% of the genomic content. Subsequent tools aimed to classify 300-3000bp reads from complex mixtures of microbial genomes based on tetranucleotide frequencies (which are characteristic for different organisms <span class="citation">[<a href="#ref-N9NzkOjA">221</a>]</span>) using supervised <span class="citation">[<a href="#ref-QV551Nlx">222</a>,<a href="#ref-1HtJuEkb2">223</a>]</span> or unsupervised methods <span class="citation">[<a href="#ref-1HhqhBwrM">224</a>]</span>. Then, researchers began to use techniques that could estimate relative abundances from an entire sample, which is much faster than classifying individual reads <span class="citation">[<a href="#ref-56wEWVIl">225</a>–<a href="#ref-8DLzxOEt">228</a>]</span>. There is also great interest in identifying and annotating sequence reads <span class="citation">[<a href="#ref-qUGH5CX8">229</a>,<a href="#ref-yFOAeemA">230</a>]</span>. However, the focus on taxonomic/functional annotation is just the first step. Several groups have proposed methods to determine host or environment phenotypes from the organisms that are identified <span class="citation">[<a href="#ref-W0cYSf89">231</a>–<a href="#ref-y9s5irW">234</a>]</span> or overall sequence composition <span class="citation">[<a href="#ref-5W4KMSdT">235</a>]</span>. Also, researchers have looked into how feature selection can improve classification <span class="citation">[<a href="#ref-y9s5irW">234</a>,<a href="#ref-Kt9NojjR">236</a>]</span>, and techniques have been proposed that are classifier-independent <span class="citation">[<a href="#ref-1AN5UPfb1">237</a>,<a href="#ref-O9D66oYa">238</a>]</span>.</p>
<p>How have neural networks (NNs) been of use? Most neural networks are being used for phylogenetic classification or functional annotation from sequence data, where there is a lot of data for training (and thus suitable for NNs). Neural networks have been applied successfully to gene annotation (e.g. Orphelia <span class="citation">[<a href="#ref-q1A2AEtO">239</a>]</span> and FragGeneScan <span class="citation">[<a href="#ref-QlbXLqH">240</a>]</span>), which usually has plenty of training examples. Representations (similar to Word2Vec <span class="citation">[<a href="#ref-1GhHIDxuW">78</a>]</span> in natural language processing) for protein family classification have been introduced and classified with a skip-gram neural network <span class="citation">[<a href="#ref-1E1PWjqTm">241</a>]</span>. Recurrent neural networks show good performance for homology and protein family identification <span class="citation">[<a href="#ref-G8RKF6sz">242</a>,<a href="#ref-81Cl5QSM">243</a>]</span>. Interestingly, Hochreiter, who invented Long Short Term Memory (LSTM), delved into homology/protein family classification in 2007, and therefore, deep learning is deeply rooted in functional classification methods.</p>
<p>One of the first techniques of <em>de novo</em> genome binning used self-organizing maps, a type of NN <span class="citation">[<a href="#ref-1HhqhBwrM">224</a>]</span>. Essinger et al. used Adaptive Resonance Theory (ART) to cluster similar genomic fragments and showed that it had better performance than K-means <span class="citation">[<a href="#ref-11wVLI2Hn">244</a>]</span>. However, other methods based on interpolated Markov models <span class="citation">[<a href="#ref-c4rnN1wo">245</a>]</span> have performed better than these early genome binners. Neural networks can be slow, and therefore, have had limited use for reference-based taxonomic classification, with TAC-ELM <span class="citation">[<a href="#ref-Wz7VUS03">246</a>]</span> being the only NN-based algorithm to taxonomically classify massive amounts of metagenomic data. Also, neural networks can fail to perform if there are not enough training examples, which is the case with taxonomic classification (since only ~10% of estimated species have been sequenced). An initial study successfully applied neural networks to taxonomic classification of 16S rRNA genes, with convolutional networks providing about 10% accuracy genus-level improvement over RNNs and even random forests <span class="citation">[<a href="#ref-iPIJrVVs">247</a>]</span>. However, this study performed 10-fold cross-validation on only 3000 sequences.</p>
<p>Neural network uses for classifying phenotype from microbial composition are just beginning. A standard multi-layer perceptron (MLP) was able to classify wound severity from microbial species present in the wound <span class="citation">[<a href="#ref-oas5tbC7">248</a>]</span>. Recently, Ditzler et al. associated soil samples with pH level using MLPs, deep-belief networks, and recursive neural networks <span class="citation">[<a href="#ref-i38A0beL">249</a>]</span>. Besides classifying the samples appropriately, they showed that internal phylogenetic tree nodes inferred by the networks were appropriate features representing low/high pH. Thus, hidden nodes might provide biological insight as well as new features for future metagenomic sample comparison. Also, an initial study has shown promise of these networks for diagnosing disease <span class="citation">[<a href="#ref-NQ5jiN7B">250</a>]</span>.</p>
<p>Challenges remain in applying deep neural networks to metagenomics problems. They are not yet ideal for phenotype classification because most studies contain tens of samples and hundreds or thousands of features (aka species). Such underdetermined, or ill-conditioned, problems are still a challenge for deep neural networks that require many more training examples than features to sufficiently converge the weights on the hidden layers. Also, due to convergence issues (slowness and instability due to large neural networks modeling very large datasets <span class="citation">[<a href="#ref-g2vvbB91">251</a>]</span>), taxonomic classification of reads from whole genome sequencing seems out of reach at the moment for deep neural networks -- due to only thousands of full-sequenced genomes as compared to hundreds of thousands of 16S rRNA sequences available for training.</p>
<p>However, because recurrent neural networks are showing success for denoising base calls for the relatively new Oxford Nanopore long-read sequencer <span class="citation">[<a href="#ref-1BTJ1KqRa">252</a>]</span> (discussed further in the next section), there is hope that the entire pipeline, from denoising of through functional classification, can be combined into one step by using powerful LSTM's, which have been quite successful in raw speech signal-to-meaning translation <span class="citation">[<a href="#ref-2cMhMv5A">253</a>]</span>. For example, metagenomic assembly usually requires binning then assembly, but could deep neural nets accomplish both tasks in one network? We believe the largest potential in deep learning is to learn &quot;everything&quot; in one complex network, with a plethora of labeled (reference) data and unlabeled (microbiome experiments) examples.</p>
<h3 id="sequencing-and-variant-calling">Sequencing and variant calling</h3>
<p>While we have so far discussed the role of deep learning in analyzing genomic data, deep learning approaches can also substantially improve our ability to obtain the genomic data itself. We will discuss two specific challenges: calling SNPs (single nucleotide polymorphisms) and indels (insertions and deletions) with high specificity and sensitivity, and improving the accuracy of new types of data such as nanopore sequencing. These two tasks are critical for studying rare variation, allele-specific transcription and translation, and splice site mutations, among others. In the clinical realm, sequencing of rare tumor clones and other genetic diseases will require accurate calling of SNP and indels.</p>
<p>Current methods achieve relatively high (&gt;99%) precision at 90% recall for SNPs and indel calls from Illumina short-read data <span class="citation">[<a href="#ref-FVfZESYP">254</a>]</span>, yet this leaves a large number of potentially clinically important remaining false positives and false negatives. These methods have so far relied on experts to build probabilistic models that reliably separate signal from noise. However, this process is time consuming and, more importantly, fundamentally limited by how well we understand and can model the factors that contribute to noise. Recently, two groups have applied deep learning to construct data-driven and, therefore, unbiased noise models. One of these models, DeepVariant, leverages Inception, a neural network trained for image classification by Google Brain, by encoding reads around a candidate SNP as a 221x100 bitmap image, where each column is a nucleotide and each row is a read from the sample library <span class="citation">[<a href="#ref-FVfZESYP">254</a>]</span>. The top 5 rows represent the reference, and the bottom 95 rows represent randomly sampled reads that overlap the candidate variant. Each RGBA (red/green/blue/alpha) image pixel encodes the base (A, C, T, G) as a different R value, quality score as a G value, strand as a B value, and variation from the reference as the alpha value. The neural network outputs genotype probabilities for each candidate variant. They were able to achieve better performance than GATK, a leading genotype caller, even when GATK was given information about population variation for each candidate variant. Another method, still in its infancy, hand-developed 642 features for each candidate variant and fed these vectors into a fully connected deep neural network <span class="citation">[<a href="#ref-GSLRw2L5">255</a>]</span>. Unfortunately, this feature set required at least 15 iterations of software development to fine-tune, which will likely not be generalizable.</p>
<p>Going forward, we believe that variant calling will benefit more from optimizing neural network architectures than from developing features by hand. An interesting and informative next step would be to rigorously test whether encoding raw sequence and quality data as an image, tensor, or some other mixed format produces the best variant calls. Because many of the latest neural network architectures (ResNet, Inception, Xception, and others) are already optimized for and pre-trained on generic, large-scale image datasets <span class="citation">[<a href="#ref-VMkPJjVk">256</a>]</span>, encoding genomic data as images could prove to be a generally effective, and efficient, strategy.</p>
<p>In limited experiments, DeepVariant was robust to sequencing depth, read length, and even species <span class="citation">[<a href="#ref-FVfZESYP">254</a>]</span>. However, a model built on Illumina data, for instance, may not be applicable to PacBio long-read data or MinION nanopore data, which have vastly different specificity and sensitivity profiles and signal-to-noise characteristics. Recently, Boza et al. used bidirectional recurrent neural networks to infer the <em>E. coli</em> sequence from MinION nanopore electric current data with 2% higher per-base accuracy than the proprietary hidden Markov model-based algorithm Metrichor (86% to 88%) <span class="citation">[<a href="#ref-1BTJ1KqRa">252</a>]</span>. Unfortunately, training any neural network requires a large amount of data, which is often not available for new sequencing technologies. To circumvent this, one very preliminary study simulated mutations and spiked them into somatic and germline RNA-seq data, then trained and tested a neural network on simulated paired RNA-seq and exome sequencing data <span class="citation">[<a href="#ref-ECTm1SuA">257</a>]</span>. However, because this model was not subsequently tested on ground-truth datasets, it is unclear whether simulation can produce sufficiently realistic data to produce reliable models.</p>
<p>Method development for interpreting new types of sequencing data has historically taken two steps: first, easily implemented hard cutoffs that prioritize specificity over sensitivity, then expert development of probabilistic models with hand-developed inputs <span class="citation">[<a href="#ref-ECTm1SuA">257</a>]</span>. We anticipate that these steps will be replaced by deep learning, which will infer features simply by its ability to optimize a complex model against data.</p>
<h2 id="the-impact-of-deep-learning-in-treating-disease-and-developing-new-treatments">The impact of deep learning in treating disease and developing new treatments</h2>
<p>Given the ever-present need to make better interventions faster at the point of care -- incorporating the complex calculus of a patients symptoms, diagnostics and life history -- there is a long history of attempts to apply deep learning to patient treatment. Success in this area would also be very useful for directions like personalized healthcare or precision medicine <span class="citation">[<a href="#ref-VOQtVhWs">258</a>,<a href="#ref-3JyJ3DTh">259</a>]</span>. Earlier, we have written of the possibilities for patient categorization. Here, we examine the potential for better treatment, which broadly, may divided into methods for improved choices of interventions for patients and those for development of new interventions.</p>
<h3 id="categorizing-patients-for-clinical-decision-making">Categorizing patients for clinical decision making</h3>
<p>As long ago as 1996, Tu <span class="citation">[<a href="#ref-kL0B4m9d">260</a>]</span> compared the effectiveness of artificial neural networks and logistic regression, questioning whether deep learning would replace traditional statistical methods for predicting medical outcomes such as myocardial infarction <span class="citation">[<a href="#ref-jdg2u7bX">261</a>]</span> or mortality <span class="citation">[<a href="#ref-xX68eyvs">262</a>]</span>. He posited that while neural networks have several advantages in representational power, the difficulties in interpretation may limit clinical applications. Similarly, in 2006 Lisboa and Taktak <span class="citation">[<a href="#ref-qxxwkSAT">263</a>]</span> examined the use of artificial neural networks in medical journals, concluding that they improved healthcare relative to traditional screening methods in 21 of 27 studies.</p>
<p><code>TODO: could really use some references for following paragraph</code></p>
<p>While further progress has been made in using deep learning for clinical decision making, it is hindered by a challenge common to many deep learning applications: it is much easier to predict an outcome than to suggest an action to change the outcome. Several attempts at recasting the clinical decision making problem into a prediction problem (i.e., prediction of which treatment will most improve the patient's health) have accurately predicted prescription habits, but technical and medical challenges remain for clinical adoption (similar to those for categorization). In particular, remaining challenges include actionable interpretability of deep learning models, fitting deep models to limited and heterogeneous data, and integrating complex predictive models into a dynamic clinical environment.</p>
<p>A critical challenge in moving from prediction to treatment recommendations is the necessity to establish a causal relationship for a recommendation. Causal inference is often framed in terms of counterfactual question <span class="citation">[<a href="#ref-cpNVdlL7">264</a>]</span>. Johansson et al. <span class="citation">[<a href="#ref-173ftiSzF">265</a>]</span> use deep neural networks to create representation models for covariates that capture nonlinear effects and show significant performance improvements over existing models. In a less formal approach, Kale et al. <span class="citation">[<a href="#ref-FUIfIdE">266</a>]</span> first create a deep neural network to model clinical time series and then analyze the relationship of the hidden features to the output using a causal approach.</p>
<h4 id="applications">Applications</h4>
<h5 id="trajectory-prediction-for-treatment">Trajectory prediction for treatment</h5>
<p>A common application for deep learning techniques in this domain is to leverage the temporal structure of healthcare records. As previously discussed, many studies <span class="citation">[<a href="#ref-4zpZxjHR">267</a>–<a href="#ref-glyI7H6F">270</a>]</span> have used deep recurrent networks to categorize patients but most stop short of suggesting clinical decisions. Nemati et al. <span class="citation">[<a href="#ref-16OQvsRqJ">271</a>]</span> used deep reinforcement learning to optimize a heparin dosing policy for intensive care patients. However, because the ideal dosing policy is unknown, the model's predictions must be evaluated on counter-factual data. This represents a common challenge when bridging the gap between research and clinical practice: because the ground-truth is unknown, researchers struggle to evaluate model predictions in the absence of interventional data, but clinical application is unlikely until the model has been shown to be effective. The impressive applications of deep reinforcement learning to other domains <span class="citation">[<a href="#ref-2gn6PKkv">220</a>]</span> have relied on knowledge of the underlying processes (e.g. the rules of the game). Some models have been developed for targeted medical problems <span class="citation">[<a href="#ref-eCrLGgiX">272</a>]</span>, but a generalized engine is beyond current capabilities. Further development of the rules underlying biological processes could unleash deep learning methods that are currently hampered by the difficulties of counter-factual inference.</p>
<h5 id="efficient-clinical-trials">Efficient clinical trials</h5>
<p>A clinical task to deep learning which has been more successfully applied is the assignment of patients to clinical trials. Ithapu et al <span class="citation">[<a href="#ref-eehGXQlY">273</a>]</span> used a randomized denoising autoencoder to learn a multimodal imaging marker that predicts future cognitive and neural decline from positron emission tomography (PET), amyloid florbetapir PET, and structural magnetic resonance imaging. By accurately predicting which cases will progress to dementia, they were able to efficiently assign patients to a clinical trial and reduced the required sample sizes by a factor of five. Similarly, Artemov et al <span class="citation">[<a href="#ref-mo3GQwJj">274</a>]</span> applied deep learning to predict which clinical trials were likely to fail and which were likely to succeed. By predicting the side effects and pathway activations of each drug, and then translating these activations to a success probability, their deep learning-based approach was able to significantly outperform a random forest classifier trained on gene expression changes. These approaches suggest promising directions to improve the efficiency of clinical trials and accelerate drug development.</p>
<h4 id="challenges">Challenges</h4>
<h5 id="actionable-interpretability">Actionable interpretability</h5>
<p>A common challenge in many applied deep learning problems is the consideration of deep learning models as uninterpretable &quot;black boxes&quot;. Without human- intelligible reasoning for the model's predictions, it is difficult to trust the model. This presents a major challenge for the risk-averse task of clinical decision making. As described above, there has been some work to directly assign treatment plans without interpretability; however, the removal of human experts from the decision-making loop make the models difficult to integrate with clinical practice. To alleviate this challenge, several studies have attempted to create more interpretable deep models, either specifically for healthcare or as a general procedure for deep learning. Further work in interpreting predictions and understanding the knowledge learned by deep neural networks seem necessary for transformative impact in clinical practice. Interpretability in deep learning is reviewed more extensively in the Discussion.</p>
<h5 id="integrating-deep-learning-with-clinical-practice">Integrating deep learning with clinical practice</h5>
<p>As deep learning models are difficult to interpret, many current models have been designed to replace aspects of clinical practice rather than to assist trained clinicians. This makes it difficult to integrate deep learning with clinical decision making. In addition, the challenges that physicians face are largely similar to those faced by machine learning models. For a given patient, the number of possible diseases is very large, with a long tail of rare diseases. Furthermore, patients are highly heterogeneous and may present with very different signs and symptoms for the same disease. Physicians are experienced in treating patients with common diseases, but rare diseases are extremely challenging. Unfortunately, machine learning methods also struggle for rare diseases. Directly applying current deep learning models to diagnose patients with rare diseases would require prohibitively large datasets to provide sufficient training data to capture the rare instances. Focused effort in reducing the data requirements of deep learning by integrating pre-existing knowledge or compiling large datasets of patient records may unlock the power of deep learning for clinical practice.</p>
<h3 id="drug-repositioning">Drug repositioning</h3>
<p>Drug repositioning (or repurposing) is an attractive option for delivering new drugs to the market because of the high costs and failure rates associated with more traditional drug discovery approaches <span class="citation">[<a href="#ref-13c9OPizf">275</a>,<a href="#ref-79Ktl2">276</a>]</span>. A decade ago, the concept of the Connectivity Map <span class="citation">[<a href="#ref-Ot5bUkmI">277</a>]</span> had a sizeable impact on the field: reverse matching disease gene expression signatures with a large set of reference compound profiles allowed to formulate repurposing hypotheses at scale using a simple non-parametric test. Since then, several advanced computational methods have been applied to formulate and validate drug repositioning hypotheses <span class="citation">[<a href="#ref-gTwjIQqB">278</a>–<a href="#ref-ir7ElHha">280</a>]</span>. Using supervised learning and collaborative filtering to tackle this type of problems is proving successful in different scenarios, especially when coupling disease or compound omic data with topological information from protein-protein or protein-compound interaction networks <span class="citation">[<a href="#ref-M1EW8Rfl">281</a>–<a href="#ref-18lqFDKRR">283</a>]</span>.</p>
<p>For example, Menden et al. <span class="citation">[<a href="#ref-QcwZC8wG">284</a>]</span> used a shallow neural network to predict sensitivity of cancer cell lines to drug treatment using both cell line and drug features, opening the door to precision medicine and drug repositioning opportunities in cancer. More recently, Aliper et al <span class="citation">[<a href="#ref-EMDwvRGb">35</a>]</span> used gene- and pathway-level drug perturbation transcriptional profiles from the Library of Network-Based Cellular Signatures (LINCS) <span class="citation">[<a href="#ref-ppGS5h4v">285</a>]</span> to train a fully connected deep neural network able to predict drug therapeutic uses and indications. By using confusion matrices and leveraging misclassification, the authors formulate a number of interesting hypotheses, including repurposing cardiovascular drugs such as otenzepad and pinacidil for neurological disorders.</p>
<p>Drug repositioning can also be approached by attempting to predict novel drug-target interactions and then repurposing the drug for the associated indication <span class="citation">[<a href="#ref-tOpadZQw">286</a>,<a href="#ref-1SIuofeg">287</a>]</span>. Wang et al. <span class="citation">[<a href="#ref-TeIxEjqm">288</a>]</span> devised a pairwise input neural network with two hidden layers that takes two inputs, a drug and a target binding site, and predicts whether they interact. Wang et al <span class="citation">[<a href="#ref-1AU7wzPqa">36</a>]</span> trained individual RBMs for each target in a drug-target interaction network and used these models to predict novel interactions pointing to new indications for existing drugs. Wen et al. <span class="citation">[<a href="#ref-oTF8O79C">37</a>]</span> extended this concept to deep learning by creating a DBN of stacked RBMs called DeepDTIs, which is able to predict interactions on the basis of chemical structure and protein sequence features.</p>
<p>Drug repositioning appears to be an obvious candidate for the development of deep learning applications both because of the large amount of high-dimensional data available and the complexity of the question being asked. However, what is perhaps the most promising piece of work in this space <span class="citation">[<a href="#ref-EMDwvRGb">35</a>]</span> is more a proof of concept than a real-world hypothesis-generation tool; notably, deep learning was used to predict drug indications but not for the actual repositioning. At present, some of the most popular state-of-the-art methods for signature-based drug repurposing <span class="citation">[<a href="#ref-cQAldRdg">289</a>]</span> do not use predictive modelling. While this might change in the future, we believe that a mature and production-ready framework where deep learning is directly applied to the problem of drug repositioning is currently missing.</p>
<h3 id="drug-development">Drug development</h3>
<h4 id="ligand-based-prediction-of-bioactivity">Ligand-based prediction of bioactivity</h4>
<p>In the biomedical domain, high-throughput chemical screening aims to improve therapeutic options over a long term horizon <span class="citation">[<a href="#ref-1DTUK3YyI">20</a>]</span>. The objective is to discover which small molecules (also referred to as chemical compounds or ligands) effectively and specifically affect the activity of a target, such as a kinase, protein-protein interaction, or broader cellular phenotype. This screening process can serve as one of the first steps in the long drug discovery pipeline, where novel chemicals are pursued for their ability to inhibit or enhance disease-relevant biological mechanisms <span class="citation">[<a href="#ref-RAadmvJN">290</a>]</span>. Initial hits are confirmed to eliminate false positives and proceed to the lead generation stage <span class="citation">[<a href="#ref-1D6emOV6q">291</a>]</span>, where they are evaluated for absorption, distribution, metabolism, excretion, and toxicity (ADMET) and other properties. It is desirable to advance multiple lead series, clusters of structurally-similar active chemicals, for further optimization by medicinal chemists to protect against unexpected failures in the later stages of drug discovery <span class="citation">[<a href="#ref-RAadmvJN">290</a>]</span>.</p>
<p>The appeal of machine learning in this domain is the need to improve the efficiency of the initial high-throughput screens such that sufficient candidate active compounds can be identified without exhaustively screening libraries of hundreds of thousands or millions of chemicals. Predicting chemical activity computationally is known as virtual screening. This task has been treated variously as a classification, regression, or ranking problem. In reality, it does not fit neatly into any of those categories. An ideal algorithm will rank a sufficient number of active compounds before the inactives, but the rankings of actives relative to other actives and inactives are less important <span class="citation">[<a href="#ref-cjj5vT3H">292</a>]</span>. Computational modeling also has the potential to predict ADMET traits for lead generation <span class="citation">[<a href="#ref-uP7SgBVd">293</a>]</span> and how drugs are metabolized <span class="citation">[<a href="#ref-7QsMcDYy">294</a>]</span>.</p>
<p>Here we primarily focus on ligand-based approaches that train on chemicals' features without requiring prior knowledge of the target. Chemical features may be represented as a list of molecular descriptors such as molecular weight, atom counts, functional groups, charge representations, summaries of atom-atom relationships in the molecular graph, and more sophisticated derived properties <span class="citation">[<a href="#ref-17eGl2pn9">295</a>]</span>. Alternatively, chemicals can be characterized with the fingerprint bit vectors, textual strings, or novel learned representations described below. Neural networks have a long history in this domain <span class="citation">[<a href="#ref-gJE0ExFr">18</a>,<a href="#ref-xPkT1z7D">21</a>]</span>, and the 2012 Merck Molecular Activity Challenge on Kaggle generated substantial excitement about the potential for high-parameter deep learning approaches. The winning submission was an ensemble that included a multitask multilayer perceptron network <span class="citation">[<a href="#ref-1Dzz0P0qr">296</a>]</span>, and the sponsors noted drastic improvements over a random forest (RF) baseline, remarking &quot;we have seldom seen any method in the past 10 years that could consistently outperform RF by such a margin&quot; <span class="citation">[<a href="#ref-xOaTIeBY">297</a>]</span>. Subsequent work (reviewed in more detail by Goh et al. <span class="citation">[<a href="#ref-zCt6PUXj">19</a>]</span>) explored the effects of jointly modeling far more targets than the Merck challenge <span class="citation">[<a href="#ref-F8fP2vAg">298</a>,<a href="#ref-yAoN5gTU">299</a>]</span>, with <span class="citation">[<a href="#ref-yAoN5gTU">299</a>]</span> showing that the benefits of multi-task networks had not yet saturated even with 259 targets. Although a deep learning approach, DeepTox <span class="citation">[<a href="#ref-Y1D0SZrO">300</a>]</span>, was also the overall winner of another competition, the Toxicology in the 21st Century (Tox21) Data Challenge, it did not dominate alternative methods as thoroughly as in other domains. DeepTox was the top performer on 9 of 15 targets and highly competitive with the top performer on the others. However, for many targets there was little separation between the top two or three methods.</p>
<p>The nuanced Tox21 performance may be more reflective of the practical challenges encountered in ligand-based chemical screening than the extreme enthusiasm generated by the Merck competition. A study of 22 ADMET tasks demonstrated that there are limitations to multi-task transfer learning that are in part a consequence of the degree to which tasks are related <span class="citation">[<a href="#ref-uP7SgBVd">293</a>]</span>. Some of the ADMET datasets showed superior performance in multi-task models with only 22 ADMET tasks compared to multi-task models with over 500 less-similar tasks. In addition, training datasets encountered in practical applications may be tiny relative to what is available in public datasets and organized competitions. A study of BACE-1 inhibitors included only 1547 compounds <span class="citation">[<a href="#ref-B4cL1o2P">301</a>]</span>. Machine learning models were able to train on this limited dataset, but overfitting was a challenge and the differences between random forests and a deep neural were negligible, especially in the classification setting. Overfitting is still a problem in larger chemical screening datasets with tens or hundreds of thousands of compounds because the number of active compounds can be very small, on the order of 0.1% of all tested chemicals for a typical target <span class="citation">[<a href="#ref-WeiyYhfy">302</a>]</span>. This is consistent with the strong performance of low-parameter neural networks that emphasize compound-compound similarity, such as influence-relevance voter, <span class="citation">[<a href="#ref-cjj5vT3H">292</a>,<a href="#ref-1E0x7QgLP">303</a>]</span> instead of predicting compound activity directly from chemical features.</p>
<p>Much of the recent excitement in this domain has come from what could be considered a creative experimentation phase, in which deep learning has offered novel possibilities for feature representation and modeling of chemical compounds. A molecular graph, where atoms are labeled nodes and bonds are labeled edges, is a natural way to represent a chemical structure. Traditional machine learning approaches relied on preprocessing the graph into a feature vector, such as a fixed-width bit vector fingerprint <span class="citation">[<a href="#ref-QnZ7V9Rd">304</a>]</span>. The same fingerprints have been used by some drug-target interaction methods discussed above <span class="citation">[<a href="#ref-oTF8O79C">37</a>]</span>. An overly simplistic but approximately correct view of chemical fingerprints is that each bit represents the presence of absence of a particular chemical substructure in the molecular graph. Modern neural networks can operate directly on the molecular graph as input. Duvenaud et al. <span class="citation">[<a href="#ref-Oe573FaL">305</a>]</span> generalized standard circular fingerprints by substituting discrete operations in the fingerprinting algorithm with operations in a neural network, producing a real-valued feature vector instead of a bit vector. Other approaches offer trainable networks that can in theory learn chemical feature representations that are optimized for a particular prediction task. Lusci et al. <span class="citation">[<a href="#ref-17Wih4Hd5">306</a>]</span> adapted recursive neural networks for directed acyclic graphs for undirected molecular graphs by creating an ensemble of directed graphs in which one atom is selected as the root node. A single feature vector is obtained by summing over all feature vectors for all directed graphs in the ensemble. Graph convolutions on undirected molecular graphs have eliminated the need to enumerate artificial directed graphs, learning feature vectors for atoms that are a function of the properties of neighboring atoms and local regions on the molecular graph <span class="citation">[<a href="#ref-145os4Y6t">307</a>,<a href="#ref-P4ixsM8i">308</a>]</span>.</p>
<p>Advances in chemical representation learning have also enabled new strategies for learning chemical-chemical similarity functions. Altae-Tran et al. developed a one-shot learning network <span class="citation">[<a href="#ref-P4ixsM8i">308</a>]</span> to address the reality that most practical chemical screening studies are unable to provide the thousands or millions of training compounds that are needed to train larger multitask networks. Using graph convolutions to featurize chemicals, the network learns an embedding from compounds into a continuous feature space such that compounds with similar activities in a set of training tasks have similar embeddings. The approach is evaluated in an extremely challenging setting where the embedding is learned from a subset of prediction tasks (e.g. activity assays for individual proteins) and only one to ten labeled examples are provided as training data on a new task. On Tox21 targets, even when trained with <em>one</em> task-specific active compound and <em>one</em> inactive compound, the model is able to generalize reasonably well because it has learned an informative embedding function from the related tasks. Random forests, which cannot take advantage of the related training tasks, trained in the same setting are only slightly better than a random classifier. Despite the success on Tox21, performance on MUV datasets, which contains assays designed to be challenging for chemical informatics algorithms, is considerably worse. The authors also demonstrate the limitations of transfer learning as embeddings learned from the Tox21 assays have little utility for a drug adverse reaction dataset.</p>
<p>These novel, learned chemical feature representations may prove to be essential for accurately predicting why some compounds with similar structures yield similar target effects and others produce drastically different results. Currently, these methods are enticing but do not necessarily outperform classic approaches by a large margin. The neural fingerprints <span class="citation">[<a href="#ref-Oe573FaL">305</a>]</span> were narrowly beaten by regression using traditional circular fingerprints on a drug efficacy prediction task (but were superior for predicting solubility or photovoltaic efficiency). In the original study, graph convolutions <span class="citation">[<a href="#ref-145os4Y6t">307</a>]</span> performed comparably to a multitask network using standard fingerprints and slightly better than the neural fingerprints <span class="citation">[<a href="#ref-Oe573FaL">305</a>]</span> on the drug efficacy task but were slightly worse than the influence-relevance voter method on an HIV dataset. <span class="citation">[<a href="#ref-cjj5vT3H">292</a>]</span>. Broader recent benchmarking has shown that relative merits of these methods depends on the dataset and cross validation strategy <span class="citation">[<a href="#ref-16OPHvAij">309</a>]</span>, though we caution against over-interpreting AUC ROC-based results, a popular metric in this domain despite the active/inactive class imbalance (see Discussion).</p>
<p>We remain optimistic for the potential of deep learning and specifically representation learning in this domain and propose that rigorous benchmarking on broad and diverse prediction tasks will be as important as novel neural network architectures to advance the state of the art and convincingly demonstrate superiority over traditional cheminformatics techniques. Fortunately, there has recently been much progress in this direction. The DeepChem software <span class="citation">[<a href="#ref-P4ixsM8i">308</a>,<a href="#ref-Ytvk62dX">310</a>]</span> and MoleculeNet benchmarking suite <span class="citation">[<a href="#ref-16OPHvAij">309</a>]</span> built upon it contain chemical bioactivity and toxicity prediction datasets, multiple compound featurization approaches including graph convolutions, and various machine learning algorithms ranging from standard baselines like logistic regression and random forests to recent neural network architectures. Independent research groups have already contributed additional datasets and prediction algorithms to DeepChem, and adoption of common benchmarking evaluation metrics, datasets, and baseline algorithms has the potential to establish the practical utility of deep learning in chemical bioactivity prediction and lower the barrier to entry for machine learning researchers without biochemistry expertise.</p>
<p>One open question in ligand-based screening pertains to the benefits and limitations of transfer learning. Multitask neural networks have shown the advantages of jointly modeling many targets <span class="citation">[<a href="#ref-F8fP2vAg">298</a>,<a href="#ref-yAoN5gTU">299</a>]</span>. Other studies have shown the limitations of transfer learning when the prediction tasks are insufficiently related <span class="citation">[<a href="#ref-uP7SgBVd">293</a>,<a href="#ref-P4ixsM8i">308</a>]</span>. This has important implications for representation learning. The typical approach to improve deep learning models by expanding the dataset size may not be applicable if only &quot;related&quot; tasks are beneficial, especially because task-task relatedness is ill-defined. The massive chemical state space will also influence the development of unsupervised representation learning methods <span class="citation">[<a href="#ref-2dU8f4XJ">311</a>]</span>. Future work will establish whether it is better to train on massive collections of diverse compounds, drug-like small molecules, or specialized subsets.</p>
<h4 id="structure-based-prediction-of-bioactivity">Structure-based prediction of bioactivity</h4>
<p>When protein structure is available, virtual screening has traditionally relied on docking programs to predict how a compound best fits in the target's binding site and score the predicted ligand-target complex <span class="citation">[<a href="#ref-13iyYvEcB">312</a>]</span>. Recently, deep learning approaches have been developed to model protein structure, which is expected to improve upon the simpler drug-target interaction algorithms described above that represent proteins with feature vectors derived from amino acid sequences <span class="citation">[<a href="#ref-oTF8O79C">37</a>,<a href="#ref-TeIxEjqm">288</a>]</span>.</p>
<p>Structure-based deep learning methods differ in whether they use experimentally-derived or predicted ligand-target complexes and how they represent the 3D structure. The Atomic Convolutional Neural Network <span class="citation">[<a href="#ref-17YaKNLKk">313</a>]</span> takes 3D crystal structures from PDBBind <span class="citation">[<a href="#ref-YO41GAOP">314</a>]</span> as input, ensuring it uses the correct ligand-target complex. Alternatively, AtomNet <span class="citation">[<a href="#ref-Z7fd0BYf">34</a>]</span> samples multiple ligand poses within the target binding site, and DeepVS <span class="citation">[<a href="#ref-Gue0c5Gb">315</a>]</span> and Ragoza et al. <span class="citation">[<a href="#ref-bNBiIiTt">316</a>]</span> use a docking program to generate protein-compound complexes. If they are sufficiently accurate, these latter approaches would have wider applicability to a much larger set of compounds and proteins. However, incorrect ligand poses will be misleading during training, and the predictive performance is sensitive to the docking quality <span class="citation">[<a href="#ref-Gue0c5Gb">315</a>]</span>. A 3D grid can be used to represent a protein-compound complex <span class="citation">[<a href="#ref-Z7fd0BYf">34</a>,<a href="#ref-bNBiIiTt">316</a>]</span>. Each entry in the grid tracks the types of protein and ligand atoms in that region of the 3D space or descriptors derived from those atoms. Both DeepVS <span class="citation">[<a href="#ref-Gue0c5Gb">315</a>]</span> and atomic convolutions <span class="citation">[<a href="#ref-17YaKNLKk">313</a>]</span> offer greater flexibility in their convolutions by eschewing the 3D grid. Instead, they each implement techniques for executing convolutions over atoms' neighboring atoms in the 3D space. Gomes et al. demonstrate that currently random forest on a 1D feature vector that describes the 3D ligand-target structure generally outperforms neural networks on the same feature vector, atomic convolutions, and ligand-based neural networks when predicting the continuous-valued inhibition constant on the PDBBind refined dataset. However, in the long term atomic convolutions may ultimately overtake grid-based methods, as they provide greater freedom to model atom-atom interactions and the forces that govern binding affinity.</p>
<h4 id="de-novo-drug-design"><em>De novo</em> drug design</h4>
<p>Whereas the goal of virtual screening is to find active molecules by predicting the biochemical activity of hundreds of thousands to millions of chemicals using existing (virtual) collections of molecules, analogous to robot based high-throughput &quot;wet lab&quot; screening, <em>de novo</em> drug design aims to directly <em>generate</em> active compounds <span class="citation">[<a href="#ref-kJ4hy7E">317</a>,<a href="#ref-omzv9ryI">318</a>]</span>.</p>
<p>Drug design attempts to model the typical design-synthesize-test cycle of drug discovery <span class="citation">[<a href="#ref-kJ4hy7E">317</a>]</span>. Thus <em>de novo</em> design explores in principle without explicit enumeration the much larger space of an estimated 10<sup>60</sup> synthesizable organic molecules with drug-like properties <span class="citation">[<a href="#ref-WeiyYhfy">302</a>]</span>. To test or score structures, machine learning algorithms like those discussed earlier are used. To &quot;design&quot; and &quot;synthesize&quot;, traditional <em>de novo</em> design software relied on classical optimizers such as genetic algorithms. Unfortunately, this often leads to overfitted, &quot;weird&quot; molecules, which are difficult to synthesize in the lab. To generate molecules, current programs have therefore settled on rule-based virtual chemical reactions to generate molecular structures <span class="citation">[<a href="#ref-omzv9ryI">318</a>]</span>.</p>
<p>Neural network models that learn to generate realistic, synthesizable molecules have been proposed as an alternative to provide the large molecule sets needed for virtual screening or even create and refine focussed molecules for <em>de novo</em> design. In contrast to the classical, symbolic approaches, generative models learned from data do not depend on laboriously encoded expert knowledge. The problem is related to the generation of syntactically and semantically correct text <span class="citation">[<a href="#ref-15y7iq6HF">319</a>]</span>.</p>
<p>As deep learning models that directly output (molecular) graphs remain under-explored, generative neural networks for drug design typically represent chemicals with the simplified molecular-input line-entry system (SMILES), a standard way string-based representation with characters that represent atoms, bonds, and rings <span class="citation">[<a href="#ref-8LWFFeYg">320</a>]</span>. This allows treating molecules as sequences and leveraging recent progress in recurrent neural networks. Gómez-Bombarelli et al. designed a SMILES-to-SMILES autoencoder to learn a continuous latent feature space for chemicals <span class="citation">[<a href="#ref-2dU8f4XJ">311</a>]</span>. In this learned continuous space it was possible to interpolate between continuous representations of chemicals in a manner that is not possible with discrete (e.g. bit vector or string) features or in symbolic, molecular graph space. Even more interesting is the prospect of performing gradient-based or Bayesian optimization of molecules within this latent space. The strategy of constructing simple, continuous features before applying supervised learning techniques is reminiscent of autoencoders trained on high-dimensional EHR data <span class="citation">[<a href="#ref-5x3uMSKi">58</a>]</span>. A drawback of the SMILES-to-SMILES autoencoder is that not all SMILES strings produced by the autoencoder's decoder correspond to valid chemical structures. Recently, the Grammar Variational Autoencoder, which takes the SMILES grammar into account and is guaranteed to produce syntactically valid SMILES, has been proposed to alleviate this issue <span class="citation">[<a href="#ref-AQ3N6Ayw">321</a>]</span>.</p>
<p>Another approach to drug design is to train character-based RNNs on large collections of molecules, for example, ChEMBL, <span class="citation">[<a href="#ref-x1nE5icc">322</a>]</span> to first obtain a generic generative model for drug-like compounds <span class="citation">[<a href="#ref-8LWFFeYg">320</a>]</span>. These generative models successfully learn the grammar of compound representations, with 94% <span class="citation">[<a href="#ref-1EayJRsI">323</a>]</span> or nearly 98% <span class="citation">[<a href="#ref-8LWFFeYg">320</a>]</span> of generated SMILES corresponding to valid molecular structures. The initial RNN is then fine-tuned to generate molecules that are likely to be active against a specific target by either continuing training on a small set of positive examples <span class="citation">[<a href="#ref-8LWFFeYg">320</a>]</span> or adopting reinforcement learning strategies <span class="citation">[<a href="#ref-1EayJRsI">323</a>,<a href="#ref-lERqKdZJ">324</a>]</span>. Both fine-tuning and reinforcement learning strategies could rediscover known, held-out active molecules. The great flexibility of neural networks, and progress in generative models offers many opportunites for deep architectures in <em>de novo</em> design, for example, the adaptation of Generative Adversarial Networks (GANs) for molecules.</p>
<h2 id="discussion">Discussion</h2>
<p>Despite the disparate types of data and scientific goals in the learning tasks covered above, several challenges can be seen to be broadly important for deep learning in the biomedical domain. Here we examine these factors that may impede further progress, ask what steps have already been taken to overcome them, and suggest future research directions.</p>
<h3 id="evaluation">Evaluation</h3>
<p><em>What are the challenges in evaluating deep learning models that are specific to this domain? This can include a discussion of ROC versus precision-recall curves for the imbalanced classes often encountered in biomedical datasets. It could also mention alternative metrics that are used in specific sub-areas such as enrichment factors in virtual screening. A lack of true gold standard data for some problems complicates both training and evaluation. Confidence- weighted labels are valuable when available.</em></p>
<p><em>Is progress in some biomedical areas slowed when new predictions (e.g. from generative models) cannot be assessed by any human expert and require experimental testing? For example, contrast a painting or song generated by a GAN versus a novel chemical compound. Related is the idea that on some tasks (e.g. the recent wave of deep learning versus MD image classification papers) it is easy to tell when deep learning has produced a breakthrough because human-level performance is an impressive baseline. In many tasks we reviewed, human-level performance is irrelevant.</em></p>
<p><code>TODO: draft coming May 4 or 5</code></p>
<h3 id="interpretation">Interpretation</h3>
<p>As deep learning models achieve state-of-the-art performance in a variety of domains, there is a growing need to make the models more interpretable. Interpretability matters for two main reasons. First, a model that achieves breakthrough performance may have identified patterns in the data that practitioners in the field would like to understand. However, this would not be possible if the model is a black box. Second, interpretability is important for trust. If a model is making medical diagnoses, it is important to ensure the model is making decisions for reliable reasons and is not focusing on an artifact of the data. A motivating example of this can be found in Caruana et al. <span class="citation">[<a href="#ref-1AhGoHZP9">325</a>]</span>, where a model trained to predict the likelihood of death from pneumonia assigned lower risk to patients with asthma, but only because such patients were treated as higher priority by the hospital. In the context of deep learning, understanding the basis of a model's output is particularly important as deep learning models are unusually susceptible to adversarial examples <span class="citation">[<a href="#ref-1AkF8Wsv7">326</a>]</span> and can output confidence scores over 99.99% for samples that resemble pure noise.</p>
<p>As the concept of interpretability is quite broad, many methods described as improving the interpretability of deep learning models take disparate and often complementary approaches. Some key themes are discussed below.</p>
<h4 id="assigning-example-specific-importance-scores">Assigning example-specific importance scores</h4>
<p>Several approaches ascribe importance on an example-specific basis to the parts of the input that are responsible for a particular output. These can be broadly divided into perturbation-based approaches and backpropagation-based approaches.</p>
<h5 id="perturbation-based-approaches">Perturbation-based approaches</h5>
<p>These approaches make perturbations to individual inputs and observes the impact on the output of the network. Zhou and Troyanskaya <span class="citation">[<a href="#ref-2UI1BZuD">165</a>]</span> scored genomic sequences by introducing virtual mutations at each position and quantifying the change in the output. Ribeiro et al. <span class="citation">[<a href="#ref-QwXSJhr0">327</a>]</span> introduced LIME which constructs a linear model to locally approximate the output of the network on perturbed versions of the input and assigned importance scores accordingly. For analyzing images, Zeiler and Fergus <span class="citation">[<a href="#ref-voh0OiT2">328</a>]</span> applied constant-value masks to different input patches and studied the changes in the activations of later layers. As an alternative to using masks, which can produce misleading results, Zintgraf et al. <span class="citation">[<a href="#ref-Kk20paR7">329</a>]</span> proposed a novel strategy based on marginalizing over plausible values of an input patch to more accurately estimate its contribution. <code>TODO: do we need an example of what is misleading?</code></p>
<p>A common drawback to perturbation-based approaches is computational efficiency: each perturbed version of an input requires a separate forward propagation through the network to compute the output. As noted by Shrikumar et al. <span class="citation">[<a href="#ref-zhmq9ktJ">330</a>]</span>, such methods may also underestimate the impact of features that have saturated their contribution to the output, as can happen when multiple redundant features are present.</p>
<p>To reduce the computational overhead of perturbation-based approaches, Fong and Vedaldi <span class="citation">[<a href="#ref-y4t9EzPn">331</a>]</span> solve an optimization problem using gradient descent to discover a minimal subset of inputs to perturb in order to decrease the predicted probability of a selected class. When tested on image data, their method took about 300 iterations to converge, compared to the ~5000 iterations used by LIME. One drawback of this approach is that the use of gradient descent requires the perturbation to have a differentiable form.</p>
<p><code>TODO: tag:Alipanahi2015_predicting (DeepBind) was in the original draft. Does that still fit somewhere?  It is okay to leave out, it is already cited in the TF binding section.</code></p>
<h5 id="backpropagation-based-approaches">Backpropagation-based approaches</h5>
<p>A second strategy for addressing the computational inefficiency of perturbation-based approaches is to propagate an important signal from a target output neuron backwards through the layers to the input layer in a single backpropagation-like pass. A classic example of this calculating the gradients of the output w.r.t. the input <span class="citation">[<a href="#ref-1YcKYTvO">332</a>]</span> to compute a &quot;saliency map&quot;. Bach et al. <span class="citation">[<a href="#ref-au5CLIOH">333</a>]</span> proposed a strategy called Layerwise Relevance Propagation, which was shown to be equivalent to the elementwise product of the gradient and input <span class="citation">[<a href="#ref-xAbGxia4">169</a>,<a href="#ref-b1sc0cgP">334</a>]</span>. Several variants of gradients exist which differ in their handling of the ReLU nonlinearity. While gradients zero-out the importance signal at ReLUs if the input to the ReLU is negative, deconvolutional networks <span class="citation">[<a href="#ref-voh0OiT2">328</a>]</span> zero-out the importance signal if the signal itself is negative. Guided backpropagation <span class="citation">[<a href="#ref-f2L6isRj">335</a>]</span> combines the two strategies to zero-out the importance signal if either the input to ReLU is negative or the importance signal is negative, in effect discarding negative gradients. However, Mahendran and Vedaldi <span class="citation">[<a href="#ref-3CM9XLyL">336</a>]</span> showed that while guided backpropagation excelled at identifying salient features in the input image, these features showed little class-specificity, producing very similar saliency maps regardless of the class under consideration. Selvaraju et al. <span class="citation">[<a href="#ref-RZsNSRDS">337</a>]</span> attempted to alleviate this by combining gradients and guided backpropagation in Guided Grad-CAM (Class Activation Mapping). Feature maps in the last convolutional layer were associated with classes using gradients, and the weighted activation of these feature maps was multiplied with the result of guided backpropagation to introduce more class specificity. Note that these approaches still would not highlight features that have saturated their contribution to the output, as the gradients with respect to such features would be zero at the input.</p>
<p>To address the saturation failure mode, strategies have been developed to consider how the output changes between some reference input and the actual input, where the reference input represents a &quot;null&quot; input that it is informative to measure differences against. Sundararajan et al. <span class="citation">[<a href="#ref-WzFOJBiA">338</a>]</span> integrated the gradients as the input was linearly increased from the reference to its actual value (in their examples, which were on image-like data, they used a reference of all zeros). While the numerical integration adds computational overhead, the method is still more efficient on average than perturbation approaches. Further, by relying only on the gradients, the method is a fully black-box approach that is guaranteed to give the same answer for functionally equivalent networks. Shrikumar et al. <span class="citation">[<a href="#ref-zhmq9ktJ">330</a>]</span> developed DeepLIFT, a strategy that used the difference between a neuron's activation on the reference input compared to its activation on the actual input to improve the backpropagation of importance scores. DeepLIFT is a white box method that requires knowledge of the network architecture, but it is more computationally efficient than integrated gradients. Lundberg and Lee <span class="citation">[<a href="#ref-DeOI1oGf">339</a>]</span> noted that several importance scoring methods, including DeepLIFT, integrated gradients and LIME, could all be considered approximations to the Shapely values, which have a long history in game theory for assigning contributions to players in cooperative games. <code>TODO: Add reference for Shapely values and/or explain that term</code> DeepLIFT introduced a modification which treated positive and negative contributions separately to address some failure cases of integrated gradients; the modification can be understood as an improved approximation of the Shapely values.</p>
<h4 id="matching-or-exaggerating-the-hidden-representation">Matching or exaggerating the hidden representation</h4>
<p>Another approach to understanding the network's predictions is to find artificial inputs that produce similar hidden representations to a chosen example. This can elucidate the features that the network uses for prediction and drop the features that the network is insensitive to. In the context of natural images, Mahendran and Vedaldi <span class="citation">[<a href="#ref-19mGl6pfy">340</a>]</span> introduced the &quot;inversion&quot; visualization which uses gradient descent and backpropagation to reconstruct the input from its hidden representation. The method required placing a prior on the input to favor results which resemble natural images. For genomic sequence, Finnegan and Song <span class="citation">[<a href="#ref-VjsZbMSz">341</a>]</span> used a Markov chain Monte Carlo algorithm to find the maximum-entropy distribution of inputs that produced a similar hidden representation to the chosen input.</p>
<p>A related idea is &quot;caricaturization&quot;, where an initial image is altered to exaggerate patterns that the net searches for <span class="citation">[<a href="#ref-1FkT6C6oa">342</a>]</span>. This is done by maximizing the response of neurons that are active in the network, subject to some regularizing constraints. Mordvintsev et al. <span class="citation">[<a href="#ref-XLHInhc1">343</a>]</span> leveraged caricaturization to generate aesthetically pleasing images using neural networks.</p>
<h4 id="activation-maximization">Activation maximization</h4>
<p>Activation maximization can reveal patterns detected by an individual neuron in the network by generating images which maximally activate that neuron, subject to some regularizing constraints. This technique was first introduced in Ehran et al. <span class="citation">[<a href="#ref-UAAd9Uez">344</a>]</span> and applied in Simonyan et al. <span class="citation">[<a href="#ref-1YcKYTvO">332</a>]</span>, Mordvintsev et al. <span class="citation">[<a href="#ref-XLHInhc1">343</a>]</span>, Yosinksi et al. <span class="citation">[<a href="#ref-17i18PMkR">345</a>]</span> and Mahendran and Vedaldi <span class="citation">[<a href="#ref-1FkT6C6oa">342</a>]</span>. Lanchantin et al. <span class="citation">[<a href="#ref-Dwi2eAvT">166</a>]</span> applied activation maximization to genomic sequence. One drawback of this approach is that neural networks often learn highly distributed representations where several neurons cooperatively describe a pattern of interest - thus, visualizing patterns learned by individual neurons may not always be informative.</p>
<h4 id="rnn-specific-approaches">RNN-specific approaches</h4>
<p>Several interpretation methods are specifically tailored to recurrent neural network architectures. A few key approaches are summarized below.</p>
<p>The most common form of interpretability provided by RNNs is through attention mechanisms, which have been used in diverse problems such as image captioning and machine translation to select portions of the input to focus on for generating a particular output <span class="citation">[<a href="#ref-haHzVaaz">346</a>,<a href="#ref-yHn4SDRI">347</a>]</span>. Deming et al. <span class="citation">[<a href="#ref-SAvEOARL">348</a>]</span> applied the attention mechanism to models trained on genomic sequence. Attention mechanisms provide insight into the model's decision-making process by revealing which portions of the input are used by different outputs. In the clinical domain, Choi et al. <span class="citation">[<a href="#ref-UcRbawKo">349</a>]</span> leveraged attention mechanisms to highlight which aspects of a patient's medical history were most relevant for making diagnoses. Choi et al. <span class="citation">[<a href="#ref-10nDTiETi">350</a>]</span> later extended this work to take into account the structure of disease ontologies and found that the concepts represented by the model were aligned with medical knowledge. Note that interpretation strategies that rely on an attention mechanism do not provide insight into the internal logic used by the attention layer to decide which inputs to attend to.</p>
<p>Visualizing the activation patterns of the hidden state of a recurrent neural network can also be instructive. Early work by Ghosh and Karamcheti <span class="citation">[<a href="#ref-oc44yBj0">351</a>]</span> used cluster analysis to study hidden states of comparatively small networks trained to recognize strings from a finite state machine. More recently, Karpathy et al. <span class="citation">[<a href="#ref-2cpYveR4">352</a>]</span> showed the existence of individual cells in LSTMs that kept track of quotes and brackets in character-level language models. To facilitate such analyses, LSTM vis <span class="citation">[<a href="#ref-1Ad3UOefc">353</a>]</span> allows interactive exploration of the hidden state of LSTMs on different inputs.</p>
<p>Another strategy, adopted by Lanchatin et al. <span class="citation">[<a href="#ref-Dwi2eAvT">166</a>]</span> looks at how the output of a recurrent neural network changes as longer and longer subsequences are supplied as input to the network, where the subsequences begin with just the first position and end with the entire sequence. In a binary classification task, this can identify those positions which are responsible for flipping the output of the network from negative to positive. If the RNN is bidirectional, the same process can be repeated on the reverse sequence. As noted by the authors, this approach was less effective at identifying motifs compared to the gradient-based backpropagation approach of Simonyan et al. <span class="citation">[<a href="#ref-1YcKYTvO">332</a>]</span> illustrating the need for more sophisticated strategies to assign importance scores in recurrent neural networks.</p>
<p>Murdoch and Szlam <span class="citation">[<a href="#ref-10ViHstXn">354</a>]</span> showed that the output of an LSTM can be decomposed into a product of factors where each factor can be interpreted as the contribution at a particular timestep. The contribution scores were then used to identify key phrases from a model trained to do sentiment analysis and obtained superior results compared to scores derived via a gradient-based approach.</p>
<h4 id="miscellaneous-approaches">Miscellaneous approaches</h4>
<p>Toward quantifying the uncertainty of predictions, there has been a renewed interest in confidence intervals for deep neural networks. Early work from Chryssolouris et al. <span class="citation">[<a href="#ref-9SnNyc8Y">355</a>]</span> provided confidence intervals under the assumption of normally distributed error. A more recent technique known as test-time dropout <span class="citation">[<a href="#ref-1FDihfnM">356</a>]</span> can also be used to obtain a probabilistic interpretation of a network's outputs.</p>
<p>It can often be informative to understand how the training data affects the learning of a model. Toward this end, Koh and Liang <span class="citation">[<a href="#ref-69wxD9y">357</a>]</span> used influence functions, a technique from robust statistics, to trace a model's predictions back through the learning algorithm to identify the datapoints in the training set that had the most impact on a given prediction.</p>
<p>A more free-form approach to interpretability is to visualize the activation patterns of the network on individual inputs and on subsets of the data. ActiVis and CNNvis <span class="citation">[<a href="#ref-QphVo2P2">358</a>,<a href="#ref-AEc66xxR">359</a>]</span> are two frameworks that enable interactive visualization and exploration of large-scale deep learning models.</p>
<p>An orthogonal strategy is to use a knowledge distillation approach to replace a deep learning model with a more interpretable model that achieves comparable performance. Towards this end, Che et al. <span class="citation">[<a href="#ref-14DAmZTDg">360</a>]</span> used gradient boosted trees to learn interpretable healthcare features from trained deep models.</p>
<p>Finally, it is sometimes possible to train the model to provide justifications for its predictions. Lei et al. <span class="citation">[<a href="#ref-ZUCVI5eU">361</a>]</span> used a generator to identify &quot;rationales&quot;, which are short and coherent pieces of the input text that produce similar results to the whole input when passed through an encoder. The authors applied their approach to a sentiment analysis task and obtained substantially superior results compared to an attention-based method.</p>
<p><code>TODO: Are there any brief final thoughts you would like to add? This paper is part review, part perspective piece so we have the opportunity to speculate about the future or push certain for certain research directions. For example: Is the criticism of deep learning as a black box, uninterpretable approach exaggerated given all of these methods? Are there certain types of features or domains (in genomics, healthcare, etc.) where these methods still fall short? Are there practical steps that would improve adoption of appropriate model interpretation? Maybe closer integration into the most popular deep learning frameworks, as applicable?</code></p>
<h3 id="data-limitations">Data limitations</h3>
<p>A lack of large-scale, high-quality, correctly labeled training data has impacted deep learning in nearly all applications we have discussed, from healthcare to genomics to drug discovery. The challenges of training complex, high-parameter neural networks from few examples are obvious, but uncertainty in the labels of those examples can be just as problematic. For example, in genomics labeled data may be derived from an experimental assay with known and unknown technical artifacts, biases, and error profiles. It is possible to weight training examples or construct Bayesian models to account for uncertainty or non-independence in the data. To this end, Park et al. <span class="citation">[<a href="#ref-5tvnB4uW">362</a>]</span> estimated shared non-biological signal between datasets to correct for non-independence related to assay platform or other factors in a Bayesian integration of many datasets. However, such techniques are rarely placed front and center in any description of methods, and so may be easily overlooked.</p>
<p>For some types of data, especially images, it is straightforward to augment training datasets by splitting a single labeled example into multiple examples. For example, an image can easily be rotated, flipped, or translated and retain its label <span class="citation">[<a href="#ref-9G9Hv1Pp">52</a>]</span>. 3D MRI and 4D fMRI (with time as a dimension) data can be decomposed into sets of 2D images <span class="citation">[<a href="#ref-11NHbWB1V">363</a>]</span>. This can greatly expand the number of training examples but artificially treats such derived images as independent instances and sacrifices the structure inherent in the data. CellCnn trains a model to recognize rare cell populations in single-cell data by creating training instances that consist of random subsets of cells that are randomly sampled with replacement from the full dataset <span class="citation">[<a href="#ref-r3Gbjksq">217</a>]</span>.</p>
<p>Simulated or semi-synthetic training data has also been employed in multiple biomedical domains. <code>TODO:  simulated data: #5 #99 #293, maybe #117 and #197. There is a counter-example from drug discovery to include as well that is related to #55</code></p>
<p>Multimodal, multi-task, and transfer learning, discussed in detail below, can also combat data limitations to some degree. There are also emerging network architectures, such as Diet Networks for high-dimensional SNP data <span class="citation">[<a href="#ref-15JUKBg9y">364</a>]</span>. These use multiple networks to drastically reduce the number of free parameters by first flipping the problem and training a network to predict parameters (weights) for each input (SNP) to learn a feature embedding. This embedding (i.e. PCA, per class histograms, or a Word2vec <span class="citation">[<a href="#ref-1GhHIDxuW">78</a>]</span> generalization) can be learned directly from input data or take advantage of other datasets or domain knowledge. Additionally, in this task the features are the examples, an important advantage when it is typical to have 500 thousand or more SNPs and only a few thousand patients. Finally, this embedding is of a much lower dimension, allowing for a large reduction in the number of free parameters. In the example given, the number of free parameters from was reduced from 30 million to 50 thousand, a factor of 600.</p>
<h3 id="hardware-limitations-and-scaling">Hardware limitations and scaling</h3>
<p>Efficiently scaling deep learning is challenging, and there is a high computational cost (e.g. time, memory, energy) associated with training neural networks and using them for classification. This is one of the reasons why neural networks have only recently found widespread use <span class="citation">[<a href="#ref-BQS8ClV0">365</a>]</span>.</p>
<p>Many have sought to curb these costs, with methods ranging from the very applied (e.g. reduced numerical precision <span class="citation">[<a href="#ref-CKcJuj03">366</a>–<a href="#ref-1GUizyE8e">369</a>]</span>) to the exotic and theoretic (e.g. training small networks to mimic large networks and ensembles <span class="citation">[<a href="#ref-1AhGoHZP9">325</a>,<a href="#ref-1CRF3gAV">370</a>]</span>). The largest gains in efficiency have come from computation with graphics processing units (GPUs) <span class="citation">[<a href="#ref-BQS8ClV0">365</a>,<a href="#ref-F3e4wfzQ">371</a>–<a href="#ref-1FocAi7N0">375</a>]</span>, which excel at the matrix and vector operations so central to deep learning. The massively parallel nature of GPUs allows additional optimizations, such as accelerated mini-batch gradient descent <span class="citation">[<a href="#ref-NSgduYNT">372</a>,<a href="#ref-IULiPa6L">373</a>,<a href="#ref-aClNvbyM">376</a>,<a href="#ref-fNkl8HFz">377</a>]</span>. However, GPUs also have a limited quantity of memory, making it difficult to implement networks of useful size and complexity on a single GPU or machine <span class="citation">[<a href="#ref-CCS5KSIM">73</a>,<a href="#ref-F3e4wfzQ">371</a>]</span>. This restriction has sometimes forced computational biologists to use workarounds or limit the size of an analysis. For example, Chen et al. <span class="citation">[<a href="#ref-12QQw9p7v">147</a>]</span> aimed to infer the expression level of all genes with a single neural network, but due to memory restrictions they randomly partitioned genes into two halves and analyzed each separately. In other cases, researchers limited the size of their neural network <span class="citation">[<a href="#ref-BhfjKSY3">27</a>,<a href="#ref-2dU8f4XJ">311</a>]</span>. Some have also chosen to use slower CPU implementations rather than sacrifice network size or performance <span class="citation">[<a href="#ref-x0M6vals">378</a>]</span>.</p>
<p>While steady improvements in GPU hardware may alleviate this issue, it is unclear whether advances can occur quickly enough to keep up with the growing amount of available biological data or increasing network sizes. Much has been done to minimize the memory requirements of neural networks <span class="citation">[<a href="#ref-1AhGoHZP9">325</a>,<a href="#ref-CKcJuj03">366</a>–<a href="#ref-1GUizyE8e">369</a>,<a href="#ref-YwdqeYZi">379</a>,<a href="#ref-15lYGmZpY">380</a>]</span>, but there is also growing interest in specialized hardware, such as field-programmable gate arrays (FPGAs) <span class="citation">[<a href="#ref-1FocAi7N0">375</a>,<a href="#ref-9NKsJjSw">381</a>]</span> and application-specific integrated circuits (ASICs). Specialized hardware promises improvements in deep learning at reduced time, energy, and memory <span class="citation">[<a href="#ref-1FocAi7N0">375</a>]</span>. Obviously, there is as yet less software available for such highly specialized hardware <span class="citation">[<a href="#ref-9NKsJjSw">381</a>]</span>, and it could be a difficult investment for those not solely interested in deep learning. However, it is likely that such options will find increased support as they become a more popular platform for deep learning and general computation.</p>
<p>Distributed computing is a general solution to intense computational requirements, and has enabled many large-scale deep learning efforts. Early approaches to distributed computation <span class="citation">[<a href="#ref-xE3EYmck">382</a>,<a href="#ref-1XcexUAV">383</a>]</span> were not suitable for deep learning <span class="citation">[<a href="#ref-17cBimWgp">384</a>]</span>, but much progress has been made. There now exist a number of algorithms <span class="citation">[<a href="#ref-w6CoVmFK">368</a>,<a href="#ref-17cBimWgp">384</a>,<a href="#ref-HIiQN4bd">385</a>]</span>, tools <span class="citation">[<a href="#ref-rmJZ2Aui">386</a>–<a href="#ref-Gp4OR9Lf">388</a>]</span>, and high-level libraries <span class="citation">[<a href="#ref-FwEK0msb">389</a>,<a href="#ref-y9IoEy4r">390</a>]</span> for deep learning in a distributed environment, and it is possible to train very complex networks with limited infrastructure <span class="citation">[<a href="#ref-4MZ2tmZ8">391</a>]</span>. Besides handling very large networks, distributed or parallelized approaches offer other advantages, such as improved ensembling <span class="citation">[<a href="#ref-JUF9VoRD">392</a>]</span> or accelerated hyperparameter optimization <span class="citation">[<a href="#ref-wz83yfHF">393</a>,<a href="#ref-Wsa952Ax">394</a>]</span>.</p>
<p>Cloud computing, which has already seen wide adoption in genomics <span class="citation">[<a href="#ref-B6g0qKf4">395</a>]</span>, could facilitate easier sharing of the large datasets common to biology <span class="citation">[<a href="#ref-1E7bFCRV4">396</a>,<a href="#ref-q0SsFrZd">397</a>]</span>, and may be key to scaling deep learning. Cloud computing affords researchers flexibility, and enables the use of specialized hardware (e.g., FPGAs, ASICs, GPUs) without major investment. As such, it could be easier to address the different challenges associated with the multitudinous layers and architectures available <span class="citation">[<a href="#ref-ZSVsnPVO">398</a>]</span>. Though many are reluctant to store sensitive data (e.g. patient electronic health records) in the cloud, secure/regulation-compliant cloud services do exist <span class="citation">[<a href="#ref-ObFN78yp">399</a>]</span>.</p>
<h3 id="data-code-and-model-sharing">Data, code, and model sharing</h3>
<p>A robust culture of data, code, and model sharing would do much to speed advances in this domain. The cultural barriers of data sharing in particular are perhaps best captured by the implications of using the term &quot;research parasite&quot; to describe scientists who use data from other researchers <span class="citation">[<a href="#ref-o0F1MXBC">400</a>]</span>. In short, a field that honors only discoveries and not the hard work of generating useful data will have difficulty encouraging scientists to share their hard-won data. Unfortunately, it's precisely those data that would help to power deep learning in the domain. Efforts are underway to recognize those who promote an ecosystem of rigorous sharing and analysis <span class="citation">[<a href="#ref-194IoYUs3">401</a>]</span>.</p>
<p>The sharing of high-quality, labeled datasets will be especially valuable. In addition, researchers who invest time to preprocess datasets to be suitable for deep learning can make the preprocessing code (e.g. Basset <span class="citation">[<a href="#ref-2CbHXoFn">177</a>]</span> and variationanalysis <span class="citation">[<a href="#ref-GSLRw2L5">255</a>]</span>) and cleaned data (e.g. MoleculeNet <span class="citation">[<a href="#ref-16OPHvAij">309</a>]</span>) publicly available to catalyze further research. However, there are complex privacy and legal issues involved in sharing patient data that cannot be ignored. Furthermore, in some domains, some of the best training data has been generated privately, for example, high-throughput chemical screening data at pharmaceutical companies. One perspective is that there is little expectation or incentive for this private data to be shared. However, data are not inherently valuable. Instead, the insights that we glean from them are where the value lies. Private companies may establish a competitive advantage by releasing sufficient data for improved methods to be developed.</p>
<p>Code sharing and open source licensing is essential for continued progress in this domain. We strongly advocate following established best practices for sharing source code, archiving code in repositories that generate digital object identifiers, and open licensing <span class="citation">[<a href="#ref-gvyja7v1">402</a>]</span> regardless of the minimal requirements, or lack thereof, set by journals, conferences, or preprint servers. In addition, it is important for authors to share not only code for their core models but also scripts and code used for data cleaning (see above) and hyperparameter optimization. These improve reproducibility and serve as documentation of the detailed decisions that impact model performance but may not be exhaustively captured in a manuscript's methods text.</p>
<p>Because many deep learning models are often built using one of several popular software frameworks, it is also possible to directly share trained predictive models. The availability of pre-trained models can accelerate research, with image classifiers as an apt example. A pre-trained neural network can be quickly fine-tuned on new data and used in transfer learning, as discussed below. Taking this idea to the extreme, genomic data has been artificially encoded as images in order to benefit from pre-trained image classifiers <span class="citation">[<a href="#ref-FVfZESYP">254</a>]</span>. &quot;Model zoos&quot; -- collections of pre-trained models -- are not yet common in biomedical domains but have started to appear in genomics applications <span class="citation">[<a href="#ref-19EJTHByG">213</a>,<a href="#ref-117PEpTMe">403</a>]</span>. Sharing models for patient data requires great care because deep learning models can be attacked to identify examples used in training. We discuss this issue as well as recent techniques to mitigate these concerns in the patient categorization section.</p>
<p>DeepChem <span class="citation">[<a href="#ref-P4ixsM8i">308</a>–<a href="#ref-Ytvk62dX">310</a>]</span> and DragoNN <span class="citation">[<a href="#ref-117PEpTMe">403</a>]</span> exemplify the benefits of sharing pre-trained models and code under an open source license. DeepChem, which targets drug discovery and quantum chemistry, has actively encouraged and received community contributions of learning algorithms and benchmarking datasets. As a consequence, it now supports of a large suite of machine learning approaches, both deep learning and competing strategies that can be run on diverse test cases. This realistic, continual evaluation will play a critical role in assessing which techniques are most promising for chemical screening and drug discovery. Like formal, organized challenges such as the ENCODE-DREAM <em>in vivo</em> Transcription Factor Binding Site Prediction Challenge <span class="citation">[<a href="#ref-wW6QbBXz">404</a>]</span>, <code>TODO: placeholder URL until the preprint is available</code> DeepChem provides a forum for the fair, critical evaluations that are not always conducted in individual methodological papers, which can be biased toward favoring a new proposed algorithm. Likewise DragoNN (Deep RegulAtory GenOmic Neural Networks), offers not only code and a model zoo but also a detailed tutorial and partner package for simulating training data. These resources, especially the ability to simulate datasets that are sufficiently complex to demonstrate the challenges of training neural networks but small enough to train quickly on a CPU, are important for (human) training and attracting machine learning researchers to problems in genomics and healthcare. We have even included DragoNN and hands-on model training into the curriculum of a graduate student course.</p>
<h3 id="multimodal-multi-task-and-transfer-learning">Multimodal, multi-task, and transfer learning</h3>
<p>As discussed above, the fact that biomedical datasets often contain a limited number of instances or labels can be a cause of poor performance of machine learning algorithms. When trained on such datasets, deep learning models are particularly prone to overfitting due to their high representational power. However, transfer learning techniques also known as domain adaptation enable transfer of extracted patterns between different datasets and even domains. This approach consists of training a model for the base task, and subsequently reusing the trained model for the target problem in hand. The first step allows a model to take advantage of a larger amount of data and/or labels to extract better feature representations. Transferring learnt features in deep neural networks improves performance compared to randomly initialized features even when pre-training and target sets are dissimilar. However, transferability of features decreases as the distance between the base task and target task increases <span class="citation">[<a href="#ref-enhj7VT6">405</a>]</span>.</p>
<p>In image analysis, previous examples of deep transfer learning applications proved large scale natural image sets <span class="citation">[<a href="#ref-cBVeXnZx">63</a>]</span> to be useful for pre-training models that can then serve as generic feature extractors applied to various types of biological images <span class="citation">[<a href="#ref-irSe12Sm">14</a>,<a href="#ref-BMg062hc">206</a>,<a href="#ref-HlDY7trA">406</a>,<a href="#ref-z3I2IudI">407</a>]</span>. More recently, deep learning models trained to predict protein sub-cellular localization successfully performed predictions for proteins not originally present in the training set <span class="citation">[<a href="#ref-2a7MHtAx">408</a>]</span>. Moreover, in this type of task, learnt features performed reasonably well even when applied to images obtained using different fluorescent labels, imaging techniques, and different cell types <span class="citation">[<a href="#ref-DcnNfASG">409</a>]</span>. However, there are no established theoretical guarantees for feature transferability between distant domains such as natural images and various modalities of biological imaging. Because learnt patterns are represented in deep neural networks in a layer-wise hierarchical fashion, this issue is usually addressed by fixing an empirically chosen number of layers that preserve generic characteristics of both training and target datasets. The model is then fine-tuned by re-training multiple networks' top layers on the specific dataset in order to re-learn domain-specific high level concepts (e.g. fine-tuning for radiology image classification <span class="citation">[<a href="#ref-x6HXFAS4">61</a>]</span>). Fine-tuning on specific biological datasets enables more focused predictions. The Basset package <span class="citation">[<a href="#ref-2CbHXoFn">177</a>]</span> for prediction of functional activities from DNA sequences was shown to rapidly learn and accurately predict on new data by leveraging a model pre-trained on available public data. To simulate this scenario, authors put aside 15 of 164 cell type datasets and trained the Basset model on the remaining 149 datasets. Then, they fine-tuned the model with one training pass of each of the remaining datasets and achieved results close to the model trained on all 164 datasets together. In another example, Min et al. <span class="citation">[<a href="#ref-jV2YerUS">179</a>]</span> demonstrated how training on the experimentally validated FANTOM5 permissive enhancer dataset followed by fine-tuning on ENCODE enhancer datasets improved cell type-specific predictions, outperforming state-of-the-art results. In drug design, general RNN models trained to generate molecules from the ChEMBL database have been fine-tuned to produce drug-like compounds for specific targets <span class="citation">[<a href="#ref-8LWFFeYg">320</a>,<a href="#ref-1EayJRsI">323</a>]</span>.</p>
<p>Related to transfer learning, multimodal learning assumes simultaneous learning from various types of inputs, such as images and text. It allows capture of features that describe common concepts across input modalities. Generative graphical models like restricted Boltzmann machines (RBM) and their stacked versions, deep Boltzmann machines (DBM), and deep belief networks (DBN), demonstrate successful extraction of more informative features for one modality (images or video) when jointly learnt with other modalities (audio or text) <span class="citation">[<a href="#ref-1eN66lwn">410</a>]</span>. Deep graphical models such as DBNs are considered to be well suited for multimodal learning tasks since they learn a joint probability distribution from inputs. They can be pre-trained in an unsupervised fashion on large unlabeled data and then fine-tuned on a smaller number of labeled examples. When labels are available, convolutional neural networks (CNN) are ubiquitously used since they can be trained end-to-end with backpropagation and demonstrate state-of-the-art performance in many discriminative tasks <span class="citation">[<a href="#ref-irSe12Sm">14</a>]</span>.</p>
<p>Jha et al. <span class="citation">[<a href="#ref-N0HBi8MH">155</a>]</span> showed that an integrated training approach delivers better performance compared to individual networks. They compared a number of feed-forward architectures trained on RNA-seq data with and without an additional set of CLIP-seq, knockdown, and over-expression based input features. Results showed that the integrative deep model generalized well for combined data, offering large performance improvement for alternative splicing event estimation. Chaudhary et al. <span class="citation">[<a href="#ref-obeRVckH">411</a>]</span> trained a deep autoencoder model jointly on RNA-seq, miRNA-seq, and methylation data from TCGA to predict survival subgroups of hepatocellular carcinoma patients. This multimodal approach that treated different omics as different modalities outperformed both traditional methods (PCA) and single-omic models. Interestingly, multi-omic model performance did not improve when combined with clinical information, suggesting that the model was able to capture redundant contributions of clinical features through their correlated genomic features. Chen et al. <span class="citation">[<a href="#ref-rmjDc5rm">142</a>]</span> used deep belief networks to learn phosphorylation states of a common set of signaling proteins in primary cultured bronchial cells collected from rats and humans treated with distinct stimuli. By interpreting species as different modalities representing similar high-level concepts, they showed that DBNs were able to capture cross-species representation of signaling mechanisms in response to a common stimuli. Another application used DBNs for joint unsupervised feature learning from cancer datasets containing gene expression, DNA methylation, and miRNA expression data <span class="citation">[<a href="#ref-1EtavGKI4">149</a>]</span>. This approach allowed for the capture of intrinsic relationships in different modalities and for better clustering performance over conventional k-means based methods.</p>
<p>Multimodal learning with CNNs is usually implemented as a collection of individual networks in which each learns representations from single data type. These individual representations are further concatenated before or within fully-connected layers. FIDDLE <span class="citation">[<a href="#ref-yOz8Ybj2">412</a>]</span> is an example of multimodal CNNs that represents an ensemble of individual networks that take as inputs a number of genomic datasets, including NET-seq, MNase-seq, ChIP-seq, RNA-seq, and raw DNA sequence to predict Transcription Start Site-seq (TSS-seq) outputs. The combined model radically improves performance over separately trained datatype-specific networks, suggesting that it learns the synergistic relationship between datasets.</p>
<p>Multi-task learning (MTL) is an approach related to transfer learning. In an MTL framework a model co-learns a number of tasks simultaneously such that features are shared across them. DeepSEA framework <span class="citation">[<a href="#ref-2UI1BZuD">165</a>]</span> implemented a multi-task joint learning of diverse chromatin factors sharing predictive features from raw DNA sequence. This allowed, for example, a sequence feature that is effective in recognizing binding of a specific TF to be simultaneously used by another predictor for a physically interacting TF. Similarly, TFImpute <span class="citation">[<a href="#ref-Qbtqlmhf">156</a>]</span>, a CNN-RNN architecture learned information shared across transcription factors and cell lines to predict cell-specific TF binding for TF-cell line combinations based on only a small fraction (4%) of the combinations using available ChIP-seq data. On multiple test sets that excluded specific TFs and cell lines, TFImpute showed comparable or superior performance compared to the state-of-the-art. Yoon et al.<span class="citation">[<a href="#ref-yUgE09ve">77</a>]</span>, previously discussed in the section on Electronic Health Records, demonstrated that predicting the primary cancer site from the cancer pathology reports together with its laterality substantially improved the performance for the latter task, suggesting that MTL can effectively leverage the commonality between two tasks using a shared representation. A number of studies previously mentioned in the section on developing new treatments employed multi-task learning approach to predict a large number of compound and target interactions for drug discovery <span class="citation">[<a href="#ref-1Dzz0P0qr">296</a>,<a href="#ref-yAoN5gTU">299</a>]</span> and drug toxicity prediction <span class="citation">[<a href="#ref-Y1D0SZrO">300</a>,<a href="#ref-1BARarxfz">413</a>]</span>. Kearnes et al. <span class="citation">[<a href="#ref-uP7SgBVd">293</a>]</span> did a systematic comparison of single-task and multi-task deep models on a set of industrial ADMET datasets. They confirmed that multi-task learning can improve performance over single-task models. They further showed that smaller datasets tend to benefit more from multitask learning than larger datasets. Results emphasized that multi-task effects are highly dataset-dependent, suggesting the use of dataset-specific models to maximize overall performance.</p>
<p>MTL approach is complementary to multimodal and transfer learning. All three techniques can be used together in the same model. For example, Zhang et al. <span class="citation">[<a href="#ref-HlDY7trA">406</a>]</span> combined deep model-based transfer and multi-task learning for cross-domain image annotation. One could imagine extending that approach to multimodal inputs as well. Common characteristic of these methods lies in better generalization of extracted features by leveraging relationships between information in provided in inputs and task objectives, represented at various hierarchical levels of abstraction in a deep learning model structure.</p>
<p>Despite demonstrated improvements, transfer learning approaches also pose a number of challenges. As mentioned above, there are no theoretically sound principles for pre-training and fine-tuning. Most best practice recommendations are heuristic and have to take into account additional hyper-parameters that depend on specific deep architectures, sizes of pre-training and target datasets, and similarity of domains. However, similarity of datasets and domains in transfer learning and relatedness of tasks in MTL are difficult to access. Most current studies address these limitations by empirical evaluation of the model using established best practices or heuristics and cross-validation. Unfortunately, negative results are typically left out and not presented in the final study publications. Results by Rajkomar et al. <span class="citation">[<a href="#ref-x6HXFAS4">61</a>]</span> showed that a deep CNN trained on natural images can boost radiology image classification performance. However, due to differences in imaging domains, target task required either re-training the initial model from scratch with special pre-processing or fine-tuning of the whole network on radiographs with heavy data augmentation to avoid overfitting. Exclusively fine-tuning top layers led to much lower validation accuracy (81.4 vs 99.5). Fine-tuning procedure for the discussed Basset model pre-trained on data from different cell types required no more than one training pass. Otherwise, the model started overfitting new data <span class="citation">[<a href="#ref-2CbHXoFn">177</a>]</span>. DeepChem successfully improved results for low-data drug discovery with one-shot learning for related tasks. However, it demonstrated clear limitations to cross-task generalization across unrelated tasks in one-shot models, specifically nuclear receptor assays and patient adverse reactions <span class="citation">[<a href="#ref-P4ixsM8i">308</a>]</span>.</p>
<p>Overall, multimodal, multi-task and transfer learning strategies demonstrate high potential for many biomedical applications that are otherwise limited by data volume and presence of labels. However, these methods not only inherit most methodological issues from natural image, text, and audio domains, but also pose new challenges, specific to biological data. Making negative results, source code, and pre-trained models publicly available helps to accelerate progress in this direction. However, there are privacy considerations for models trained on sensitive data, such as patient-related information (see Data sharing section). Thus, there is a compelling need for the development of privacy-preserving transfer learning algorithms, such as Private Aggregation of Teacher Ensembles (PATE-G) <span class="citation">[<a href="#ref-b8DJ1u6W">123</a>]</span>, that can leverage publicly available data. We suggest that these types of models deserve deeper investigation to establish sound theoretical guarantees and best practices and determine limits for the transferability of features between various closely related and distant learning tasks.</p>
<h2 id="conclusions">Conclusions</h2>
<p>Deep learning-based methods now match or surpass the previous state of the art in a diverse array of tasks in patient and disease categorization, fundamental biological study, genomics, and treatment development. Returning to our central question: given this rapid progress, has deep learning transformed the study of human disease? Though the answer is highly dependent on the specific domain and problem being addressed, we conclude that deep learning has not <em>yet</em> realized its transformative potential or induced a strategic inflection point. Despite its dominance over competing machine learning approaches in many of the areas reviewed here and quantitative improvements in predictive performance, deep learning has not yet definitively &quot;solved&quot; those problems.</p>
<p>As an analogy, consider recent progress in conversational speech recognition. Since 2009 there have been drastic performance improvements, with error rates dropping from more than 20% to less than 6% <span class="citation">[<a href="#ref-nyjAIan4">414</a>]</span> and finally approaching or exceeding human performance in the past year <span class="citation">[<a href="#ref-M2OLWojE">415</a>,<a href="#ref-wKioubsT">416</a>]</span> <code>TODO: need better source for this error trajectory</code>. The phenomenal improvements on benchmark datasets are undeniable, but halving the error rate on these benchmarks did not fundamentally transform the domain. Widespread adoption of conversational speech technologies will require not only improvements over baseline methods but truly solving the problem, in this case exceeding human-level performance, as well as convincing users to embrace the technology <span class="citation">[<a href="#ref-nyjAIan4">414</a>]</span>. We see parallels to the healthcare domain, where achieving the full potential of deep learning will require outstanding predictive performance as well as acceptance and adoption by biologists and clinicians.</p>
<p>Some of the areas we have discussed are closer to surpassing this lofty bar than others, generally those that are more similar to the non-biomedical tasks that are now monopolized by deep learning. In medical imaging, diabetic retinopathy <span class="citation">[<a href="#ref-1mJW6umJ">48</a>]</span>, diabetic macular edema <span class="citation">[<a href="#ref-1mJW6umJ">48</a>]</span>, tuberculosis <span class="citation">[<a href="#ref-Qve94Jra">62</a>]</span>, and skin lesion <span class="citation">[<a href="#ref-XnYNYoYB">4</a>]</span> classifiers are highly accurate and comparable to clinician performance in the latter case.</p>
<p>In other domains, perfect accuracy will not be required because deep learning will be used primarily to prioritize experiments and assist discovery. For example, in chemical screening for drug discovery, a deep learning system that successfully identifies dozens or hundreds of target-specific, active small molecules from a massive search space would have immense practical value even if its overall precision is modest. In medical imaging, deep learning can point an expert to the most challenging cases that require manual review <span class="citation">[<a href="#ref-Qve94Jra">62</a>]</span>, though the risk of false negatives must be addressed. In protein structure prediction, errors in individual residue-residue contacts can be tolerated when using the contacts jointly for 3D structure modeling. Improved contact map predictions <span class="citation">[<a href="#ref-BhfjKSY3">27</a>]</span> have led to notable improvements in fold and 3D structure prediction for some of the most challenging proteins, such as membrane proteins <span class="citation">[<a href="#ref-39RPiE10">201</a>]</span>.</p>
<p>Conversely, the most challenging tasks may be those in which predictions are used directly for downstream modeling or decision-making, especially in the clinic. As an example, errors in sequence variant calling will be amplified if they are used directly for GWAS. In addition, the stochasticity and complexity of biological systems implies that for some problems, for instance, predicting gene regulation in disease, perfect accuracy will be unattainable.</p>
<p>We are witnessing deep learning models achieving human-level performance across a number of biomedical domains, and yet do not believe that biologists and clinicians will be out of a job anytime soon. While deep learning methods will soon be (or already are) better than scientists at specific tasks, they may not fully grasp the bigger picture. Machine learning algorithms, including deep neural networks, are also prone to mistakes that humans are much less likely to make, such as misclassification of adversarial examples <span class="citation">[<a href="#ref-1Fel6Bdb8">417</a>,<a href="#ref-UtcyntjF">418</a>]</span>, a reminder that these algorithms do not understand the semantics of the objects presented. Despite progress in addressing some of these limitations <span class="citation">[<a href="#ref-AsLAb71x">419</a>,<a href="#ref-18lZK7fxH">420</a>]</span>, until true and reliable artificial intelligence becomes standard in the laboratory and in the clinic, the human factor still has a critical role to play. In some cases, cooperation between human experts and deep learning algorithms can achieve better performance than either individually <span class="citation">[<a href="#ref-mbEp6jNr">71</a>]</span>. Especially for sample and patient classification tasks, we expect deep learning methods to complement and assist biomedical researchers rather than compete with or even replace them.</p>
<p>Even if deep learning in biology and healthcare is not yet transformative today, we are extremely optimistic about its future. Given how rapidly deep learning is evolving, its full potential in biomedicine has not been explored. We have highlighted numerous challenges beyond improving training and predictive accuracy, such as preserving patient privacy and interpreting models. Ongoing research has begun to address these problems and shown they are not insurmountable. Deep learning offers the flexibility to model data in its most natural form, for example, longer DNA sequences instead of k-mers for transcription factor binding prediction and molecular graphs instead of pre-computed bit vectors for drug discovery. These flexible input feature representations have spurred creative modeling approaches that would be infeasible with other machine learning techniques. Unsupervised methods are currently less developed than their supervised counterparts, but they may have the most potential because of how expensive and time-consuming it is to label large amounts of biomedical data. When deep learning algorithms can summarize very large collections of input data into interpretable models that spur scientists to ask questions that they didn't know how to ask, it will be clear that deep learning has transformed biology and medicine.</p>
<h3 id="author-contributions">Author contributions</h3>
<p><code>TODO: not sure if it should go here, but somewhere we should talk about how we wrote this thing, since it is still somewhat unconventional to have a review written in this manner.</code> We recognized that writing a review on a rapidly developing area in a manner that allowed us to provide a forward-looking perspective on diverse approaches and biological problems would require expertise from across computational biology and medicine. We created an open repository on the GitHub version control system and engaged with numerous authors from papers within and outside of the area. Paper review was conducted in the open by <code>#</code> individuals, and the manuscript was drafted in a series of commits from <code>#</code> authors. Individuals who met the ICJME standards of authorship are included as authors. These were individuals who contributed to the review of the literature; drafted the manuscript or provided substantial critical revisions; approved the final manuscript draft; and agreed to be accountable in all aspects of the work. Individuals who did not contribute in one or more of these ways, but who did participate, are acknowledged at the end of the manuscript.</p>
<p><code>TODO: update after finalizing discussion in #369</code></p>
<div id="refs" class="references">
<div id="ref-13bxiY1vo">
<p>1. Stephens ZD <em>et al.</em> 2015 Big Data: Astronomical or Genomical? <em>PLOS Biology</em> <strong>13</strong>, e1002195. (doi:<a href="https://doi.org/10.1371/journal.pbio.1002195">10.1371/journal.pbio.1002195</a>)</p>
</div>
<div id="ref-BeijBSRE">
<p>2. LeCun Y, Bengio Y, Hinton G. 2015 Deep learning. <em>Nature</em> <strong>521</strong>, 436–444. (doi:<a href="https://doi.org/10.1038/nature14539">10.1038/nature14539</a>)</p>
</div>
<div id="ref-TDruxF1s">
<p>3. Baldi P, Sadowski P, Whiteson D. 2014 Searching for exotic particles in high-energy physics with deep learning. <em>Nature Communications</em> <strong>5</strong>. (doi:<a href="https://doi.org/10.1038/ncomms5308">10.1038/ncomms5308</a>)</p>
</div>
<div id="ref-XnYNYoYB">
<p>4. Esteva A, Kuprel B, Novoa RA, Ko J, Swetter SM, Blau HM, Thrun S. 2017 Dermatologist-level classification of skin cancer with deep neural networks. <em>Nature</em> <strong>542</strong>, 115–118. (doi:<a href="https://doi.org/10.1038/nature21056">10.1038/nature21056</a>)</p>
</div>
<div id="ref-4TK06zOf">
<p>5. Wu Y <em>et al.</em> 2016 Google’s neural machine translation system: Bridging the gap between human and machine translation. </p>
</div>
<div id="ref-IiNJE32f">
<p>6. In press. See <a href="http://research.google.com/archive/unsupervised_icml2012.html" class="uri">http://research.google.com/archive/unsupervised_icml2012.html</a>.</p>
</div>
<div id="ref-1HVDhhwpK">
<p>7. McCulloch WS, Pitts W. 1943 A logical calculus of the ideas immanent in nervous activity. <em>The Bulletin of Mathematical Biophysics</em> <strong>5</strong>, 115–133. (doi:<a href="https://doi.org/10.1007/bf02478259">10.1007/bf02478259</a>)</p>
</div>
<div id="ref-1G5eCiq4d">
<p>8. Block HD, Knight BW, Rosenblatt F. 1962 Analysis of a Four-Layer Series-Coupled Perceptron. II. <em>Reviews of Modern Physics</em> <strong>34</strong>, 135–142. (doi:<a href="https://doi.org/10.1103/revmodphys.34.135">10.1103/revmodphys.34.135</a>)</p>
</div>
<div id="ref-3qm8sXnB">
<p>9. Niu F, Recht B, Re C, Wright SJ. 2011 HOGWILD!: A lock-free approach to parallelizing stochastic gradient descent. </p>
</div>
<div id="ref-yg8NW0K7">
<p>10. In press. See <a href="http://www.deeplearningbook.org/" class="uri">http://www.deeplearningbook.org/</a>.</p>
</div>
<div id="ref-mAXsmd43">
<p>11. In press. See <a href="http://www.intel.com/pressroom/archive/speeches/ag080998.htm" class="uri">http://www.intel.com/pressroom/archive/speeches/ag080998.htm</a>.</p>
</div>
<div id="ref-yXqhuueV">
<p>12. Park Y, Kellis M. 2015 Deep learning for regulatory genomics. <em>Nature Biotechnology</em> <strong>33</strong>, 825–826. (doi:<a href="https://doi.org/10.1038/nbt.3313">10.1038/nbt.3313</a>)</p>
</div>
<div id="ref-1VZjheOA">
<p>13. Mamoshina P, Vieira A, Putin E, Zhavoronkov A. 2016 Applications of Deep Learning in Biomedicine. <em>Molecular Pharmaceutics</em> <strong>13</strong>, 1445–1454. (doi:<a href="https://doi.org/10.1021/acs.molpharmaceut.5b00982">10.1021/acs.molpharmaceut.5b00982</a>)</p>
</div>
<div id="ref-irSe12Sm">
<p>14. Angermueller C, Pärnamaa T, Parts L, Stegle O. 2016 Deep learning for computational biology. <em>Molecular Systems Biology</em> <strong>12</strong>, 878. (doi:<a href="https://doi.org/10.15252/msb.20156651">10.15252/msb.20156651</a>)</p>
</div>
<div id="ref-G00xvi94">
<p>15. Min S, Lee B, Yoon S. 2016 Deep learning in bioinformatics. <em>Briefings in Bioinformatics</em>, bbw068. (doi:<a href="https://doi.org/10.1093/bib/bbw068">10.1093/bib/bbw068</a>)</p>
</div>
<div id="ref-MmRGFVUu">
<p>16. Kraus OZ, Frey BJ. 2016 Computer vision for high content screening. <em>Critical Reviews in Biochemistry and Molecular Biology</em> <strong>51</strong>, 102–109. (doi:<a href="https://doi.org/10.3109/10409238.2015.1135868">10.3109/10409238.2015.1135868</a>)</p>
</div>
<div id="ref-11I7bLcP3">
<p>17. Miotto R, Wang F, Wang S, Jiang X, Dudley JT. 2017 Deep learning for healthcare: review, opportunities and challenges. <em>Briefings in Bioinformatics</em> (doi:<a href="https://doi.org/10.1093/bib/bbx044">10.1093/bib/bbx044</a>)</p>
</div>
<div id="ref-gJE0ExFr">
<p>18. Gawehn E, Hiss JA, Schneider G. 2015 Deep Learning in Drug Discovery. <em>Molecular Informatics</em> <strong>35</strong>, 3–14. (doi:<a href="https://doi.org/10.1002/minf.201501008">10.1002/minf.201501008</a>)</p>
</div>
<div id="ref-zCt6PUXj">
<p>19. Goh GB, Hodas NO, Vishnu A. 2017 Deep learning for computational chemistry. <em>Journal of Computational Chemistry</em> <strong>38</strong>, 1291–1307. (doi:<a href="https://doi.org/10.1002/jcc.24764">10.1002/jcc.24764</a>)</p>
</div>
<div id="ref-1DTUK3YyI">
<p>20. Pérez-Sianes J, Pérez-Sánchez H, Díaz F. 2016 Virtual Screening: A Challenge for Deep Learning. In <em>Advances in Intelligent Systems and Computing</em>, pp. 13–22. Springer International Publishing. (doi:<a href="https://doi.org/10.1007/978-3-319-40126-3_2">10.1007/978-3-319-40126-3_2</a>)</p>
</div>
<div id="ref-xPkT1z7D">
<p>21. Baskin II, Winkler D, Tetko IV. 2016 A renaissance of neural networks in drug discovery. <em>Expert Opinion on Drug Discovery</em> <strong>11</strong>, 785–795. (doi:<a href="https://doi.org/10.1080/17460441.2016.1201262">10.1080/17460441.2016.1201262</a>)</p>
</div>
<div id="ref-lnK82Ey6">
<p>22. Parker JS <em>et al.</em> 2009 Supervised Risk Predictor of Breast Cancer Based on Intrinsic Subtypes. <em>Journal of Clinical Oncology</em> <strong>27</strong>, 1160–1167. (doi:<a href="https://doi.org/10.1200/jco.2008.18.1370">10.1200/jco.2008.18.1370</a>)</p>
</div>
<div id="ref-pEIw87Mp">
<p>23. Mayer IA, Abramson VG, Lehmann BD, Pietenpol JA. 2014 New Strategies for Triple-Negative Breast Cancer–Deciphering the Heterogeneity. <em>Clinical Cancer Research</em> <strong>20</strong>, 782–790. (doi:<a href="https://doi.org/10.1158/1078-0432.ccr-13-0583">10.1158/1078-0432.ccr-13-0583</a>)</p>
</div>
<div id="ref-PBiRSdXv">
<p>24. TAN J, UNG M, CHENG C, GREENE CS. 2014 UNSUPERVISED FEATURE CONSTRUCTION AND KNOWLEDGE EXTRACTION FROM GENOME-WIDE ASSAYS OF BREAST CANCER WITH DENOISING AUTOENCODERS. In <em>Biocomputing 2015</em>, WORLD SCIENTIFIC. (doi:<a href="https://doi.org/10.1142/9789814644730_0014">10.1142/9789814644730_0014</a>)</p>
</div>
<div id="ref-koEdZRcY">
<p>25. Cireşan DC, Giusti A, Gambardella LM, Schmidhuber J. 2013 Mitosis Detection in Breast Cancer Histology Images with Deep Neural Networks. In <em>Medical Image Computing and Computer-Assisted Intervention – MICCAI 2013</em>, pp. 411–418. Springer Berlin Heidelberg. (doi:<a href="https://doi.org/10.1007/978-3-642-40763-5_51">10.1007/978-3-642-40763-5_51</a>)</p>
</div>
<div id="ref-YUms527e">
<p>26. Zurada J. In press. End effector target position learning using feedforward with error back-propagation and recurrent neural networks. In <em>Proceedings of 1994 IEEE International Conference on Neural Networks (ICNN’94)</em>, IEEE. (doi:<a href="https://doi.org/10.1109/icnn.1994.374637">10.1109/icnn.1994.374637</a>)</p>
</div>
<div id="ref-BhfjKSY3">
<p>27. Wang S, Sun S, Li Z, Zhang R, Xu J. 2017 Accurate De Novo Prediction of Protein Contact Map by Ultra-Deep Learning Model. <em>PLOS Computational Biology</em> <strong>13</strong>, e1005324. (doi:<a href="https://doi.org/10.1371/journal.pcbi.1005324">10.1371/journal.pcbi.1005324</a>)</p>
</div>
<div id="ref-ZzaRyGuJ">
<p>28. Spencer M, Eickholt J, Cheng J. 2015 A Deep Learning Network Approach to <italic>ab initio</italic> Protein Secondary Structure Prediction. <em>IEEE/ACM Transactions on Computational Biology and Bioinformatics</em> <strong>12</strong>, 103–112. (doi:<a href="https://doi.org/10.1109/tcbb.2014.2343960">10.1109/tcbb.2014.2343960</a>)</p>
</div>
<div id="ref-UO8L6nd">
<p>29. Wang S, Peng J, Ma J, Xu J. 2016 Protein Secondary Structure Prediction Using Deep Convolutional Neural Fields. <em>Scientific Reports</em> <strong>6</strong>. (doi:<a href="https://doi.org/10.1038/srep18962">10.1038/srep18962</a>)</p>
</div>
<div id="ref-s5sy4AOi">
<p>30. Liu F, Li H, Ren C, Bo X, Shu W. 2016 PEDLA: predicting enhancers with a deep learning-based algorithmic framework. (doi:<a href="https://doi.org/10.1101/036129">10.1101/036129</a>)</p>
</div>
<div id="ref-17B2QAA1k">
<p>31. Li Y, Chen C-Y, Wasserman WW. 2015 Deep Feature Selection: Theory and Application to Identify Enhancers and Promoters. In <em>Lecture Notes in Computer Science</em>, pp. 205–217. Springer International Publishing. (doi:<a href="https://doi.org/10.1007/978-3-319-16706-0_20">10.1007/978-3-319-16706-0_20</a>)</p>
</div>
<div id="ref-12aqvAgz6">
<p>32. Kleftogiannis D, Kalnis P, Bajic VB. 2014 DEEP: a general computational framework for predicting enhancers. <em>Nucleic Acids Research</em> <strong>43</strong>, e6–e6. (doi:<a href="https://doi.org/10.1093/nar/gku1058">10.1093/nar/gku1058</a>)</p>
</div>
<div id="ref-15E5yG1Ho">
<p>33. Quang D, Chen Y, Xie X. 2014 DANN: a deep learning approach for annotating the pathogenicity of genetic variants. <em>Bioinformatics</em> <strong>31</strong>, 761–763. (doi:<a href="https://doi.org/10.1093/bioinformatics/btu703">10.1093/bioinformatics/btu703</a>)</p>
</div>
<div id="ref-Z7fd0BYf">
<p>34. Wallach I, Dzamba M, Heifets A. 2015 AtomNet: A deep convolutional neural network for bioactivity prediction in structure-based drug discovery. </p>
</div>
<div id="ref-EMDwvRGb">
<p>35. Aliper A, Plis S, Artemov A, Ulloa A, Mamoshina P, Zhavoronkov A. 2016 Deep Learning Applications for Predicting Pharmacological Properties of Drugs and Drug Repurposing Using Transcriptomic Data. <em>Molecular Pharmaceutics</em> <strong>13</strong>, 2524–2530. (doi:<a href="https://doi.org/10.1021/acs.molpharmaceut.6b00248">10.1021/acs.molpharmaceut.6b00248</a>)</p>
</div>
<div id="ref-1AU7wzPqa">
<p>36. Wang Y, Zeng J. 2013 Predicting drug-target interactions using restricted Boltzmann machines. <em>Bioinformatics</em> <strong>29</strong>, i126–i134. (doi:<a href="https://doi.org/10.1093/bioinformatics/btt234">10.1093/bioinformatics/btt234</a>)</p>
</div>
<div id="ref-oTF8O79C">
<p>37. Wen M, Zhang Z, Niu S, Sha H, Yang R, Yun Y, Lu H. 2017 Deep-Learning-Based Drug–Target Interaction Prediction. <em>Journal of Proteome Research</em> <strong>16</strong>, 1401–1409. (doi:<a href="https://doi.org/10.1021/acs.jproteome.6b00618">10.1021/acs.jproteome.6b00618</a>)</p>
</div>
<div id="ref-WuOqsORY">
<p>38. Stenstrom G, Gottsater A, Bakhtadze E, Berger B, Sundkvist G. 2005 Latent Autoimmune Diabetes in Adults: Definition, Prevalence,  -Cell Function, and Treatment. <em>Diabetes</em> <strong>54</strong>, S68–S72. (doi:<a href="https://doi.org/10.2337/diabetes.54.suppl_2.s68">10.2337/diabetes.54.suppl_2.s68</a>)</p>
</div>
<div id="ref-ws1zvGoZ">
<p>39. Groop LC, Bottazzo GF, Doniach D. 1986 Islet Cell Antibodies Identify Latent Type I Diabetes in Patients Aged 35-75 Years at Diagnosis. <em>Diabetes</em> <strong>35</strong>, 237–241. (doi:<a href="https://doi.org/10.2337/diab.35.2.237">10.2337/diab.35.2.237</a>)</p>
</div>
<div id="ref-LL5huVs3">
<p>40. Litjens G, Kooi T, Bejnordi BE, Setio AAA, Ciompi F, Ghafoorian M, Laak JAWM van der, Ginneken B van, Sánchez CI. 2017 A survey on deep learning in medical image analysis. </p>
</div>
<div id="ref-yEstnIOT">
<p>41. Shen D, Wu G, Suk H-I. 2016 Deep Learning in Medical Image Analysis. <em>Annual Review of Biomedical Engineering</em> <strong>19</strong>. (doi:<a href="https://doi.org/10.1146/annurev-bioeng-071516-044442">10.1146/annurev-bioeng-071516-044442</a>)</p>
</div>
<div id="ref-sLPsrfbl">
<p>42. Codella N, Nguyen Q-B, Pankanti S, Gutman D, Helba B, Halpern A, Smith JR. 2016 Deep learning ensembles for melanoma recognition in dermoscopy images. </p>
</div>
<div id="ref-phRCihNB">
<p>43. Yu L, Chen H, Dou Q, Qin J, Heng P-A. 2017 Automated Melanoma Recognition in Dermoscopy Images via Very Deep Residual Networks. <em>IEEE Transactions on Medical Imaging</em> <strong>36</strong>, 994–1004. (doi:<a href="https://doi.org/10.1109/tmi.2016.2642839">10.1109/tmi.2016.2642839</a>)</p>
</div>
<div id="ref-1AJUcl1KV">
<p>44. Jafari MH, Nasr-Esfahani E, Karimi N, Soroushmehr SMR, Samavi S, Najarian K. 2016 Extraction of skin lesions from non-dermoscopic images using deep learning. (doi:<a href="https://doi.org/10.1007/s11548-017-1567-8">10.1007/s11548-017-1567-8</a>)</p>
</div>
<div id="ref-O39LDkX">
<p>45. Nasr-Esfahani E, Samavi S, Karimi N, Soroushmehr S, Jafari M, Ward K, Najarian K. 2016 Melanoma detection by analysis of clinical images using convolutional neural network. In <em>2016 38th Annual International Conference of the IEEE Engineering in Medicine and Biology Society (EMBC)</em>, IEEE. (doi:<a href="https://doi.org/10.1109/embc.2016.7590963">10.1109/embc.2016.7590963</a>)</p>
</div>
<div id="ref-ayTsooEM">
<p>46. Pratt H, Coenen F, Broadbent DM, Harding SP, Zheng Y. 2016 Convolutional Neural Networks for Diabetic Retinopathy. <em>Procedia Computer Science</em> <strong>90</strong>, 200–205. (doi:<a href="https://doi.org/10.1016/j.procs.2016.07.014">10.1016/j.procs.2016.07.014</a>)</p>
</div>
<div id="ref-14Ovc5nPg">
<p>47. Leibig C, Allken V, Berens P, Wahl S. 2016 Leveraging uncertainty information from deep neural networks for disease detection. (doi:<a href="https://doi.org/10.1101/084210">10.1101/084210</a>)</p>
</div>
<div id="ref-1mJW6umJ">
<p>48. Gulshan V <em>et al.</em> 2016 Development and Validation of a Deep Learning Algorithm for Detection of Diabetic Retinopathy in Retinal Fundus Photographs. <em>JAMA</em> <strong>316</strong>, 2402. (doi:<a href="https://doi.org/10.1001/jama.2016.17216">10.1001/jama.2016.17216</a>)</p>
</div>
<div id="ref-iBPOt78R">
<p>49. Burlina P, Freund DE, Joshi N, Wolfson Y, Bressler NM. 2016 Detection of age-related macular degeneration via deep learning. In <em>2016 IEEE 13th International Symposium on Biomedical Imaging (ISBI)</em>, IEEE. (doi:<a href="https://doi.org/10.1109/isbi.2016.7493240">10.1109/isbi.2016.7493240</a>)</p>
</div>
<div id="ref-VFw1VXDP">
<p>50. Dhungel N, Carneiro G, Bradley AP. 2015 Deep Learning and Structured Prediction for the Segmentation of Mass in Mammograms. In <em>Lecture Notes in Computer Science</em>, pp. 605–612. Springer International Publishing. (doi:<a href="https://doi.org/10.1007/978-3-319-24553-9_74">10.1007/978-3-319-24553-9_74</a>)</p>
</div>
<div id="ref-JK8NuXy3">
<p>51. Dhungel N, Carneiro G, Bradley AP. 2016 The Automated Learning of Deep Features for Breast Mass Classification from Mammograms. In <em>Medical Image Computing and Computer-Assisted Intervention – MICCAI 2016</em>, pp. 106–114. Springer International Publishing. (doi:<a href="https://doi.org/10.1007/978-3-319-46723-8_13">10.1007/978-3-319-46723-8_13</a>)</p>
</div>
<div id="ref-9G9Hv1Pp">
<p>52. Zhu W, Lou Q, Vang YS, Xie X. 2016 Deep Multi-instance Networks with Sparse Label Assignment for Whole Mammogram Classification. (doi:<a href="https://doi.org/10.1101/095794">10.1101/095794</a>)</p>
</div>
<div id="ref-Xxb4t3zO">
<p>53. Zhu W, Xie X. 2016 Adversarial Deep Structural Networks for Mammographic Mass Segmentation. (doi:<a href="https://doi.org/10.1101/095786">10.1101/095786</a>)</p>
</div>
<div id="ref-5kfDbGhA">
<p>54. Dhungel N, Carneiro G, Bradley AP. 2017 A deep learning approach for the analysis of masses in mammograms with minimal user intervention. <em>Medical Image Analysis</em> <strong>37</strong>, 114–128. (doi:<a href="https://doi.org/10.1016/j.media.2017.01.009">10.1016/j.media.2017.01.009</a>)</p>
</div>
<div id="ref-18cZbigDD">
<p>55. Kooi T, Litjens G, van Ginneken B, Gubern-Mérida A, Sánchez CI, Mann R, den Heeten A, Karssemeijer N. 2017 Large scale deep learning for computer aided detection of mammographic lesions. <em>Medical Image Analysis</em> <strong>35</strong>, 303–312. (doi:<a href="https://doi.org/10.1016/j.media.2016.07.007">10.1016/j.media.2016.07.007</a>)</p>
</div>
<div id="ref-1AWC7HsO0">
<p>56. Gawad C, Koh W, Quake SR. 2016 Single-cell genome sequencing: current state of the science. <em>Nature Reviews Genetics</em> <strong>17</strong>, 175–188. (doi:<a href="https://doi.org/10.1038/nrg.2015.16">10.1038/nrg.2015.16</a>)</p>
</div>
<div id="ref-1ExJjVKvT">
<p>57. Kooi T, van Ginneken B, Karssemeijer N, den Heeten A. 2017 Discriminating solitary cysts from soft tissue lesions in mammography using a pretrained deep convolutional neural network. <em>Medical Physics</em> <strong>44</strong>, 1017–1027. (doi:<a href="https://doi.org/10.1002/mp.12110">10.1002/mp.12110</a>)</p>
</div>
<div id="ref-5x3uMSKi">
<p>58. Beaulieu-Jones BK, Greene CS. 2016 Semi-supervised learning of the electronic health record for phenotype stratification. <em>Journal of Biomedical Informatics</em> <strong>64</strong>, 168–178. (doi:<a href="https://doi.org/10.1016/j.jbi.2016.10.007">10.1016/j.jbi.2016.10.007</a>)</p>
</div>
<div id="ref-1Fy5bcnCI">
<p>59. Bar Y, Diamant I, Wolf L, Greenspan H. 2015 Deep learning with non-medical training used for chest pathology identification. In <em>Medical Imaging 2015: Computer-Aided Diagnosis</em> (eds LM Hadjiiski, GD Tourassi), SPIE. (doi:<a href="https://doi.org/10.1117/12.2083124">10.1117/12.2083124</a>)</p>
</div>
<div id="ref-1GAyqYBNZ">
<p>60. Shin H-C, Roth HR, Gao M, Lu L, Xu Z, Nogues I, Yao J, Mollura D, Summers RM. 2016 Deep Convolutional Neural Networks for Computer-Aided Detection: CNN Architectures, Dataset Characteristics and Transfer Learning. <em>IEEE Transactions on Medical Imaging</em> <strong>35</strong>, 1285–1298. (doi:<a href="https://doi.org/10.1109/tmi.2016.2528162">10.1109/tmi.2016.2528162</a>)</p>
</div>
<div id="ref-x6HXFAS4">
<p>61. Rajkomar A, Lingam S, Taylor AG, Blum M, Mongan J. 2016 High-Throughput Classification of Radiographs Using Deep Convolutional Neural Networks. <em>Journal of Digital Imaging</em> <strong>30</strong>, 95–101. (doi:<a href="https://doi.org/10.1007/s10278-016-9914-9">10.1007/s10278-016-9914-9</a>)</p>
</div>
<div id="ref-Qve94Jra">
<p>62. Lakhani P, Sundaram B. 2017 Deep Learning at Chest Radiography: Automated Classification of Pulmonary Tuberculosis by Using Convolutional Neural Networks. <em>Radiology</em>, 162326. (doi:<a href="https://doi.org/10.1148/radiol.2017162326">10.1148/radiol.2017162326</a>)</p>
</div>
<div id="ref-cBVeXnZx">
<p>63. Russakovsky O <em>et al.</em> 2015 ImageNet Large Scale Visual Recognition Challenge. <em>International Journal of Computer Vision</em> <strong>115</strong>, 211–252. (doi:<a href="https://doi.org/10.1007/s11263-015-0816-y">10.1007/s11263-015-0816-y</a>)</p>
</div>
<div id="ref-KseoWN2w">
<p>64. Roth HR, Lu L, Liu J, Yao J, Seff A, Cherry K, Kim L, Summers RM. 2016 Improving Computer-Aided Detection Using_newlineConvolutional Neural Networks and Random View Aggregation. <em>IEEE Transactions on Medical Imaging</em> <strong>35</strong>, 1170–1181. (doi:<a href="https://doi.org/10.1109/tmi.2015.2482920">10.1109/tmi.2015.2482920</a>)</p>
</div>
<div id="ref-SOi9mAC2">
<p>65. Amit G, Ben-Ari R, Hadad O, Monovich E, Granot N, Hashoul S. 2017 Classification of breast MRI lesions using small-size training sets: comparison of deep learning approaches. In <em>Medical Imaging 2017: Computer-Aided Diagnosis</em> (eds SG Armato, NA Petrick), SPIE. (doi:<a href="https://doi.org/10.1117/12.2249981">10.1117/12.2249981</a>)</p>
</div>
<div id="ref-18EpaZ7QB">
<p>66. Nie D, Zhang H, Adeli E, Liu L, Shen D. 2016 3D Deep Learning for Multi-modal Imaging-Guided Survival Time Prediction of Brain Tumor Patients. In <em>Medical Image Computing and Computer-Assisted Intervention – MICCAI 2016</em>, pp. 212–220. Springer International Publishing. (doi:<a href="https://doi.org/10.1007/978-3-319-46723-8_25">10.1007/978-3-319-46723-8_25</a>)</p>
</div>
<div id="ref-apBChoyF">
<p>67. Wang X, Lu L, Shin H-c, Kim L, Bagheri M, Nogues I, Yao J, Summers RM. 2017 Unsupervised joint mining of deep features and image labels for large-scale radiology image categorization and scene recognition. </p>
</div>
<div id="ref-PGi9g7yV">
<p>68. Wang X, Peng Y, Lu L, Lu Z, Bagheri M, Summers RM. 2017 ChestX-ray8: Hospital-scale chest x-ray database and benchmarks on weakly-supervised classification and localization of common thorax diseases. </p>
</div>
<div id="ref-Bi92V99U">
<p>69. In press. See <a href="https://console.cloud.google.com/storage/browser/gcs-public-data--nih/radiology_2017/Chest_X-Ray_CVPR17" class="uri">https://console.cloud.google.com/storage/browser/gcs-public-data--nih/radiology_2017/Chest_X-Ray_CVPR17</a>.</p>
</div>
<div id="ref-dQCjqq0Q">
<p>70. Litjens G <em>et al.</em> 2016 Deep learning as a tool for increased accuracy and efficiency of histopathological diagnosis. <em>Scientific Reports</em> <strong>6</strong>. (doi:<a href="https://doi.org/10.1038/srep26286">10.1038/srep26286</a>)</p>
</div>
<div id="ref-mbEp6jNr">
<p>71. Wang D, Khosla A, Gargeya R, Irshad H, Beck AH. 2016 Deep learning for identifying metastatic breast cancer. </p>
</div>
<div id="ref-SxsZyrVM">
<p>72. Lee CS, Baughman DM, Lee AY. 2016 Deep learning is effective for the classification of OCT images of normal versus Age-related Macular Degeneration. (doi:<a href="https://doi.org/10.1101/094276">10.1101/094276</a>)</p>
</div>
<div id="ref-CCS5KSIM">
<p>73. In press. See <a href="https://papers.nips.cc/paper/4824-imagenet-classification-with-deep-convolutional-neural-networks.pdf" class="uri">https://papers.nips.cc/paper/4824-imagenet-classification-with-deep-convolutional-neural-networks.pdf</a>.</p>
</div>
<div id="ref-uDaRUyh9">
<p>74. Ohno-Machado L. 2011 Realizing the full potential of electronic health records: the role of natural language processing. <em>Journal of the American Medical Informatics Association</em> <strong>18</strong>, 539–539. (doi:<a href="https://doi.org/10.1136/amiajnl-2011-000501">10.1136/amiajnl-2011-000501</a>)</p>
</div>
<div id="ref-sG3iVOTS">
<p>75. de Bruijn B, Cherry C, Kiritchenko S, Martin J, Zhu X. 2011 Machine-learned solutions for three stages of clinical information extraction: the state of the art at i2b2 2010. <em>Journal of the American Medical Informatics Association</em> <strong>18</strong>, 557–562. (doi:<a href="https://doi.org/10.1136/amiajnl-2011-000150">10.1136/amiajnl-2011-000150</a>)</p>
</div>
<div id="ref-dO844vZn">
<p>76. Chalapathy R, Borzeshi EZ, Piccardi M. 2016 Bidirectional lstm-crf for clinical concept extraction. </p>
</div>
<div id="ref-yUgE09ve">
<p>77. Yoon H-J, Ramanathan A, Tourassi G. 2016 Multi-task Deep Neural Networks for Automated Extraction of Primary Site and Laterality Information from Cancer Pathology Reports. In <em>Advances in Big Data</em>, pp. 195–204. Springer International Publishing. (doi:<a href="https://doi.org/10.1007/978-3-319-47898-2_21">10.1007/978-3-319-47898-2_21</a>)</p>
</div>
<div id="ref-1GhHIDxuW">
<p>78. Mikolov T, Chen K, Corrado G, Dean J. 2013 Efficient estimation of word representations in vector space. </p>
</div>
<div id="ref-XQtuRkTU">
<p>79. De Vine L, Zuccon G, Koopman B, Sitbon L, Bruza P. 2014 Medical Semantic Similarity with a Neural Language Model. In <em>Proceedings of the 23rd ACM International Conference on Conference on Information and Knowledge Management - CIKM ’14</em>, ACM Press. (doi:<a href="https://doi.org/10.1145/2661829.2661974">10.1145/2661829.2661974</a>)</p>
</div>
<div id="ref-TwvauiTv">
<p>80. Choi E, Bahadori MT, Searles E, Coffey C, Thompson M, Bost J, Tejedor-Sojo J, Sun J. 2016 Multi-layer Representation Learning for Medical Concepts. In <em>Proceedings of the 22nd ACM SIGKDD International Conference on Knowledge Discovery and Data Mining - KDD ’16</em>, ACM Press. (doi:<a href="https://doi.org/10.1145/2939672.2939823">10.1145/2939672.2939823</a>)</p>
</div>
<div id="ref-1G2xP5yOM">
<p>81. Gligorijevic D, Stojanovic J, Djuric N, Radosavljevic V, Grbovic M, Kulathinal RJ, Obradovic Z. 2016 Large-Scale Discovery of Disease-Disease and Disease-Gene Associations. <em>Scientific Reports</em> <strong>6</strong>. (doi:<a href="https://doi.org/10.1038/srep32404">10.1038/srep32404</a>)</p>
</div>
<div id="ref-FLX0o7bL">
<p>82. Lasko TA, Denny JC, Levy MA. 2013 Computational Phenotype Discovery Using Unsupervised Feature Learning over Noisy, Sparse, and Irregular Clinical Data. <em>PLoS ONE</em> <strong>8</strong>, e66341. (doi:<a href="https://doi.org/10.1371/journal.pone.0066341">10.1371/journal.pone.0066341</a>)</p>
</div>
<div id="ref-aM2Uy2ix">
<p>83. Beaulieu-Jones BK, Greene CS. 2016 Semi-Supervised Learning of the Electronic Health Record for Phenotype Stratification. (doi:<a href="https://doi.org/10.1101/039800">10.1101/039800</a>)</p>
</div>
<div id="ref-WrNCJ9sO">
<p>84. Miotto R, Li L, Kidd BA, Dudley JT. 2016 Deep Patient: An Unsupervised Representation to Predict the Future of Patients from the Electronic Health Records. <em>Scientific Reports</em> <strong>6</strong>. (doi:<a href="https://doi.org/10.1038/srep26094">10.1038/srep26094</a>)</p>
</div>
<div id="ref-c6MfDdWP">
<p>85. Razavian N, Marcus J, Sontag D. 2016 Multi-task prediction of disease onsets from longitudinal lab tests. </p>
</div>
<div id="ref-qXdO2aMm">
<p>86. Ranganath R, Perotte A, Elhadad N, Blei D. 2016 Deep survival analysis. </p>
</div>
<div id="ref-1921Mctzh">
<p>87. Xiang A, Lapuerta P, Ryutov A, Buckley J, Azen S. 2000 Comparison of the performance of neural network methods and Cox regression for censored survival data. <em>Computational Statistics &amp; Data Analysis</em> <strong>34</strong>, 243–257. (doi:<a href="https://doi.org/10.1016/s0167-9473(99)00098-5">10.1016/s0167-9473(99)00098-5</a>)</p>
</div>
<div id="ref-1FE0F2pQ">
<p>88. Katzman J, Shaham U, Bates J, Cloninger A, Jiang T, Kluger Y. 2016 Deep survival: A deep cox proportional hazards network. </p>
</div>
<div id="ref-pxdeuhMS">
<p>89. Ranganath R, Tang L, Charlin L, Blei DM. 2014 Deep exponential families. </p>
</div>
<div id="ref-8RAYEOPl">
<p>90. Hoffman M, Blei DM, Wang C, Paisley J. 2012 Stochastic variational inference. </p>
</div>
<div id="ref-15lbUf0as">
<p>91. Ranganath R, Tran D, Blei DM. 2015 Hierarchical variational models. </p>
</div>
<div id="ref-1Ar4f4vfR">
<p>92. Zheng T, Xie W, Xu L, He X, Zhang Y, You M, Yang G, Chen Y. 2017 A machine learning-based framework to identify type 2 diabetes through electronic health records. <em>International Journal of Medical Informatics</em> <strong>97</strong>, 120–127. (doi:<a href="https://doi.org/10.1016/j.ijmedinf.2016.09.014">10.1016/j.ijmedinf.2016.09.014</a>)</p>
</div>
<div id="ref-ziudr6hx">
<p>93. In press. See <a href="https://phekb.org/implementations" class="uri">https://phekb.org/implementations</a>.</p>
</div>
<div id="ref-A9JeoGV8">
<p>94. Halpern Y, Horng S, Choi Y, Sontag D. 2016 Electronic medical record phenotyping using the anchor and learn framework. <em>Journal of the American Medical Informatics Association</em> <strong>23</strong>, 731–740. (doi:<a href="https://doi.org/10.1093/jamia/ocw011">10.1093/jamia/ocw011</a>)</p>
</div>
<div id="ref-5Il3kN32">
<p>95. Ratner A, Sa CD, Wu S, Selsam D, Ré C. 2016 Data programming: Creating large training sets, quickly. </p>
</div>
<div id="ref-daemz8Fm">
<p>96. In press. See <a href="http://ana.blogs.com/maestros/2006/11/data_is_the_new.html," class="uri">http://ana.blogs.com/maestros/2006/11/data_is_the_new.html,</a></p>
</div>
<div id="ref-o8mib4CN">
<p>97. In press. See <a href="https://medium.com/twenty-one-hundred/data-is-the-new-oil-a-ludicrous-proposition-1d91bba4f294" class="uri">https://medium.com/twenty-one-hundred/data-is-the-new-oil-a-ludicrous-proposition-1d91bba4f294</a>.</p>
</div>
<div id="ref-hfcf5Hmi">
<p>98. In press. See <a href="http://hazyresearch.github.io/snorkel/blog/weak_supervision.html" class="uri">http://hazyresearch.github.io/snorkel/blog/weak_supervision.html</a>.</p>
</div>
<div id="ref-FkSZ1qmz">
<p>99. Jensen PB, Jensen LJ, Brunak S. 2012 Mining electronic health records: towards better research applications and clinical care. <em>Nature Reviews Genetics</em> <strong>13</strong>, 395–405. (doi:<a href="https://doi.org/10.1038/nrg3208">10.1038/nrg3208</a>)</p>
</div>
<div id="ref-11sli93ov">
<p>100. Bowman S. 2013 Impact of Electronic Health Record Systems on Information Integrity: Quality and Safety Implications. <em>Perspect Health Inf Manag</em> <strong>10</strong>, 1c. </p>
</div>
<div id="ref-y9ONtSZ9">
<p>101. Botsis T, Hartvigsen G, Chen F, Weng C. 2010 Secondary Use of EHR: Data Quality Issues and Informatics Opportunities. <em>Summit on Translat Bioinforma</em> <strong>2010</strong>, 1–5. </p>
</div>
<div id="ref-7BctyA7f">
<p>102. Serdén L, Lindqvist R, Rosén M. 2003 Have DRG-based prospective payment systems influenced the number of secondary diagnoses in health care administrative data? <em>Health Policy</em> <strong>65</strong>, 101–107. (doi:<a href="https://doi.org/10.1016/s0168-8510(02)00208-7">10.1016/s0168-8510(02)00208-7</a>)</p>
</div>
<div id="ref-4rTluXLs">
<p>103. Just BH, Marc D, Munns M, Sandefer R. 2016 Why Patient Matching Is a Challenge: Research on Master Patient Index (MPI) Data Discrepancies in Key Identifying Fields. <em>Perspect Health Inf Manag</em> <strong>13</strong>, 1e. </p>
</div>
<div id="ref-DPsQumQ2">
<p>104. In press. See <a href="http://www.ncrr.nih.gov/publications/informatics/ehr.pdf" class="uri">http://www.ncrr.nih.gov/publications/informatics/ehr.pdf</a>.</p>
</div>
<div id="ref-13filvWwr">
<p>105. De Moor G <em>et al.</em> 2015 Using electronic health records for clinical research: The case of the EHR4CR project. <em>Journal of Biomedical Informatics</em> <strong>53</strong>, 162–173. (doi:<a href="https://doi.org/10.1016/j.jbi.2014.10.006">10.1016/j.jbi.2014.10.006</a>)</p>
</div>
<div id="ref-1CWhXZxos">
<p>106. Oemig F, Snelick R. 2016 <em>Healthcare Interoperability Standards Compliance Handbook</em>. Springer International Publishing. (doi:<a href="https://doi.org/10.1007/978-3-319-44839-8">10.1007/978-3-319-44839-8</a>)</p>
</div>
<div id="ref-Fx5qVQlk">
<p>107. Faber J, Fonseca LM. 2014 How sample size influences research outcomes. <em>Dental Press Journal of Orthodontics</em> <strong>19</strong>, 27–29. (doi:<a href="https://doi.org/10.1590/2176-9451.19.4.027-029.ebo">10.1590/2176-9451.19.4.027-029.ebo</a>)</p>
</div>
<div id="ref-11OyzMl87">
<p>108. Shivade C, Raghavan P, Fosler-Lussier E, Embi PJ, Elhadad N, Johnson SB, Lai AM. 2014 A review of approaches to identifying patient phenotype cohorts using electronic health records. <em>Journal of the American Medical Informatics Association</em> <strong>21</strong>, 221–230. (doi:<a href="https://doi.org/10.1136/amiajnl-2013-001935">10.1136/amiajnl-2013-001935</a>)</p>
</div>
<div id="ref-qe90c1CL">
<p>109. WILEY LK, VANHOUTEN JP, SAMUELS DC, ALDRICH MC, RODEN DM, PETERSON JF, DENNY JC. 2016 STRATEGIES FOR EQUITABLE PHARMACOGENOMIC-GUIDED WARFARIN DOSING AMONG EUROPEAN AND AFRICAN AMERICAN INDIVIDUALS IN A CLINICAL POPULATION. In <em>Biocomputing 2017</em>, WORLD SCIENTIFIC. (doi:<a href="https://doi.org/10.1142/9789813207813_0050">10.1142/9789813207813_0050</a>)</p>
</div>
<div id="ref-CVnO5njl">
<p>110. Rahu M, McKee M. 2008 Epidemiological research labelled as a violation of privacy: the case of Estonia. <em>International Journal of Epidemiology</em> <strong>37</strong>, 678–682. (doi:<a href="https://doi.org/10.1093/ije/dyn022">10.1093/ije/dyn022</a>)</p>
</div>
<div id="ref-SfxIiPJ1">
<p>111. Gaye A <em>et al.</em> 2014 DataSHIELD: taking the analysis to the data, not the data to the analysis. <em>International Journal of Epidemiology</em> <strong>43</strong>, 1929–1944. (doi:<a href="https://doi.org/10.1093/ije/dyu188">10.1093/ije/dyu188</a>)</p>
</div>
<div id="ref-1D6b3tMu9">
<p>112. Carter KW <em>et al.</em> 2015 ViPAR: a software platform for the Virtual Pooling and Analysis of Research Data. <em>International Journal of Epidemiology</em> <strong>45</strong>, 408–416. (doi:<a href="https://doi.org/10.1093/ije/dyv193">10.1093/ije/dyv193</a>)</p>
</div>
<div id="ref-Qh7xTLwz">
<p>113. Beaulieu-Jones BK, Greene CS. 2017 Reproducibility of computational workflows is automated using continuous analysis. <em>Nature Biotechnology</em> <strong>35</strong>, 342–346. (doi:<a href="https://doi.org/10.1038/nbt.3780">10.1038/nbt.3780</a>)</p>
</div>
<div id="ref-ULSPV0rh">
<p>114. Tramèr F, Zhang F, Juels A, Reiter MK, Ristenpart T. 2016 Stealing machine learning models via prediction apis. </p>
</div>
<div id="ref-v8Lp4ibI">
<p>115. Dwork C, Roth A. 2013 The Algorithmic Foundations of Differential Privacy. <em>Foundations and Trends® in Theoretical Computer Science</em> <strong>9</strong>, 211–407. (doi:<a href="https://doi.org/10.1561/0400000042">10.1561/0400000042</a>)</p>
</div>
<div id="ref-1HbRTExaU">
<p>116. Shokri R, Stronati M, Song C, Shmatikov V. 2016 Membership inference attacks against machine learning models. </p>
</div>
<div id="ref-xl1ijigK">
<p>117. Choi E, Biswal S, Malin B, Duke J, Stewart WF, Sun J. 2017 Generating multi-label discrete electronic health records using generative adversarial networks. </p>
</div>
<div id="ref-6XtEfQMC">
<p>118. Simmons S, Sahinalp C, Berger B. 2016 Enabling Privacy-Preserving GWASs in Heterogeneous Human Populations. <em>Cell Systems</em> <strong>3</strong>, 54–61. (doi:<a href="https://doi.org/10.1016/j.cels.2016.04.013">10.1016/j.cels.2016.04.013</a>)</p>
</div>
<div id="ref-ucHUOABT">
<p>119. Abadi M, Chu A, Goodfellow I, McMahan HB, Mironov I, Talwar K, Zhang L. 2016 Deep learning with differential privacy. (doi:<a href="https://doi.org/10.1145/2976749.2978318">10.1145/2976749.2978318</a>)</p>
</div>
<div id="ref-TaPZBxYS">
<p>120. McMahan HB, Moore E, Ramage D, Hampson S, Arcas BA y. 2016 Communication-efficient learning of deep networks from decentralized data. </p>
</div>
<div id="ref-U0ySdznJ">
<p>121. In press. See <a href="http://proceedings.mlr.press/v54/mcmahan17a.html" class="uri">http://proceedings.mlr.press/v54/mcmahan17a.html</a>.</p>
</div>
<div id="ref-1GprsH3DV">
<p>122. In press. See <a href="https://eprint.iacr.org/2017/281.pdf" class="uri">https://eprint.iacr.org/2017/281.pdf</a>.</p>
</div>
<div id="ref-b8DJ1u6W">
<p>123. In press. See <a href="https://openreview.net/forum?id=HkwoSDPgg" class="uri">https://openreview.net/forum?id=HkwoSDPgg</a>.</p>
</div>
<div id="ref-7yE9K08a">
<p>124. Goodman B, Flaxman S. 2016 European union regulations on algorithmic decision-making and a ‘right to explanation’. </p>
</div>
<div id="ref-10shRODux">
<p>125. Zöllner S, Pritchard JK. 2007 Overcoming the Winner’s Curse: Estimating Penetrance Parameters from Case-Control Data. <em>The American Journal of Human Genetics</em> <strong>80</strong>, 605–615. (doi:<a href="https://doi.org/10.1086/512821">10.1086/512821</a>)</p>
</div>
<div id="ref-sOBzMC57">
<p>126. Beery AK, Zucker I. 2011 Sex bias in neuroscience and biomedical research. <em>Neuroscience &amp; Biobehavioral Reviews</em> <strong>35</strong>, 565–572. (doi:<a href="https://doi.org/10.1016/j.neubiorev.2010.07.002">10.1016/j.neubiorev.2010.07.002</a>)</p>
</div>
<div id="ref-dKwyEWWF">
<p>127. Carlson CS <em>et al.</em> 2013 Generalization and Dilution of Association Results from European GWAS in Populations of Non-European Ancestry: The PAGE Study. <em>PLoS Biology</em> <strong>11</strong>, e1001661. (doi:<a href="https://doi.org/10.1371/journal.pbio.1001661">10.1371/journal.pbio.1001661</a>)</p>
</div>
<div id="ref-T3GG8iJN">
<p>128. Price AL, Zaitlen NA, Reich D, Patterson N. 2010 New approaches to population stratification in genome-wide association studies. <em>Nature Reviews Genetics</em> <strong>11</strong>, 459–463. (doi:<a href="https://doi.org/10.1038/nrg2813">10.1038/nrg2813</a>)</p>
</div>
<div id="ref-DmQPI43R">
<p>129. Sebastiani P <em>et al.</em> 2011 Retraction. <em>Science</em> <strong>333</strong>, 404–404. (doi:<a href="https://doi.org/10.1126/science.333.6041.404-a">10.1126/science.333.6041.404-a</a>)</p>
</div>
<div id="ref-889LsjDi">
<p>130. Kaufman S, Rosset S, Perlich C, Stitelman O. 2012 Leakage in data mining. <em>ACM Transactions on Knowledge Discovery from Data</em> <strong>6</strong>, 1–21. (doi:<a href="https://doi.org/10.1145/2382577.2382579">10.1145/2382577.2382579</a>)</p>
</div>
<div id="ref-6co0adq">
<p>131. Lum K, Isaac W. 2016 To predict and serve? <em>Significance</em> <strong>13</strong>, 14–19. (doi:<a href="https://doi.org/10.1111/j.1740-9713.2016.00960.x">10.1111/j.1740-9713.2016.00960.x</a>)</p>
</div>
<div id="ref-1ENxzq6pT">
<p>132. Hardt M, Price E, Srebro N. 2016 Equality of opportunity in supervised learning. </p>
</div>
<div id="ref-11aqfNfQx">
<p>133. Joseph M, Kearns M, Morgenstern J, Neel S, Roth A. 2016 Rawlsian fairness for machine learning. </p>
</div>
<div id="ref-N96QKgly">
<p>134. Mahmood SS, Levy D, Vasan RS, Wang TJ. 2014 The Framingham Heart Study and the epidemiology of cardiovascular disease: a historical perspective. <em>The Lancet</em> <strong>383</strong>, 999–1008. (doi:<a href="https://doi.org/10.1016/s0140-6736(13)61752-3">10.1016/s0140-6736(13)61752-3</a>)</p>
</div>
<div id="ref-1FjSxrV1k">
<p>135. Pearson H. 2012 Children of the 90s: Coming of age. <em>Nature</em> <strong>484</strong>, 155–158. (doi:<a href="https://doi.org/10.1038/484155a">10.1038/484155a</a>)</p>
</div>
<div id="ref-6RHepB1T">
<p>136. Kaplan EL, Meier P. 1958 Nonparametric Estimation from Incomplete Observations. <em>Journal of the American Statistical Association</em> <strong>53</strong>, 457–481. (doi:<a href="https://doi.org/10.1080/01621459.1958.10501452">10.1080/01621459.1958.10501452</a>)</p>
</div>
<div id="ref-ogs3PPp7">
<p>137. Jensen AB, Moseley PL, Oprea TI, Ellesøe SG, Eriksson R, Schmock H, Jensen PB, Jensen LJ, Brunak S. 2014 Temporal disease trajectories condensed from population-wide registry data covering 6.2 million patients. <em>Nature Communications</em> <strong>5</strong>. (doi:<a href="https://doi.org/10.1038/ncomms5022">10.1038/ncomms5022</a>)</p>
</div>
<div id="ref-Ohd1Q9Xw">
<p>138. Nguyen P, Tran T, Wickramasinghe N, Venkatesh S. 2016 Deepr: A convolutional net for medical records. </p>
</div>
<div id="ref-HRXii6Ni">
<p>139. Pham T, Tran T, Phung D, Venkatesh S. 2016 DeepCare: A deep dynamic memory model for predictive medicine. </p>
</div>
<div id="ref-ru0hjGeQ">
<p>140. In press. See <a href="https://www.nigms.nih.gov/Education/Documents/curiosity.pdf" class="uri">https://www.nigms.nih.gov/Education/Documents/curiosity.pdf</a>.</p>
</div>
<div id="ref-8SMDF816">
<p>141. Kim M, Rai N, Zorraquino V, Tagkopoulos I. 2016 Multi-omics integration accurately predicts cellular state in unexplored conditions for Escherichia coli. <em>Nature Communications</em> <strong>7</strong>, 13090. (doi:<a href="https://doi.org/10.1038/ncomms13090">10.1038/ncomms13090</a>)</p>
</div>
<div id="ref-rmjDc5rm">
<p>142. Chen L, Cai C, Chen V, Lu X. 2015 Trans-species learning of cellular signaling systems with bimodal deep belief networks. <em>Bioinformatics</em> <strong>31</strong>, 3008–3015. (doi:<a href="https://doi.org/10.1093/bioinformatics/btv315">10.1093/bioinformatics/btv315</a>)</p>
</div>
<div id="ref-AnenJOuU">
<p>143. Gupta A, Wang H, Ganapathiraju M. 2015 Learning structure in gene expression data using deep architectures, with an application to gene clustering. (doi:<a href="https://doi.org/10.1101/031906">10.1101/031906</a>)</p>
</div>
<div id="ref-yVBx9Qx4">
<p>144. Chen L, Cai C, Chen V, Lu X. 2016 Learning a hierarchical representation of the yeast transcriptomic machinery using an autoencoder model. <em>BMC Bioinformatics</em> <strong>17</strong>. (doi:<a href="https://doi.org/10.1186/s12859-015-0852-1">10.1186/s12859-015-0852-1</a>)</p>
</div>
<div id="ref-1CFhfCyWN">
<p>145. Tan J, Hammond JH, Hogan DA, Greene CS. 2016 ADAGE-Based Integration of Publicly AvailablePseudomonas aeruginosaGene Expression Data with Denoising Autoencoders Illuminates Microbe-Host Interactions. <em>mSystems</em> <strong>1</strong>, e00025–15. (doi:<a href="https://doi.org/10.1128/msystems.00025-15">10.1128/msystems.00025-15</a>)</p>
</div>
<div id="ref-zuLdSQx3">
<p>146. Tan J <em>et al.</em> 2016 Unsupervised extraction of stable expression signatures from public compendia with eADAGE. (doi:<a href="https://doi.org/10.1101/078659">10.1101/078659</a>)</p>
</div>
<div id="ref-12QQw9p7v">
<p>147. Chen Y, Li Y, Narayan R, Subramanian A, Xie X. 2016 Gene expression inference with deep learning. <em>Bioinformatics</em> <strong>32</strong>, 1832–1839. (doi:<a href="https://doi.org/10.1093/bioinformatics/btw074">10.1093/bioinformatics/btw074</a>)</p>
</div>
<div id="ref-G10wkFHt">
<p>148. Singh R, Lanchantin J, Robins G, Qi Y. 2016 DeepChrome: Deep-learning for predicting gene expression from histone modifications. </p>
</div>
<div id="ref-1EtavGKI4">
<p>149. Liang M, Li Z, Chen T, Zeng J. 2015 Integrative Data Analysis of Multi-Platform Cancer Data with a Multimodal Deep Learning Approach. <em>IEEE/ACM Transactions on Computational Biology and Bioinformatics</em> <strong>12</strong>, 928–937. (doi:<a href="https://doi.org/10.1109/tcbb.2014.2377729">10.1109/tcbb.2014.2377729</a>)</p>
</div>
<div id="ref-QFK6GapR">
<p>150. Scotti MM, Swanson MS. 2015 RNA mis-splicing in disease. <em>Nature Reviews Genetics</em> <strong>17</strong>, 19–32. (doi:<a href="https://doi.org/10.1038/nrg.2015.3">10.1038/nrg.2015.3</a>)</p>
</div>
<div id="ref-b6p6wxpC">
<p>151. Li YI, van de Geijn B, Raj A, Knowles DA, Petti AA, Golan D, Gilad Y, Pritchard JK. 2016 RNA splicing is a primary link between genetic variation and disease. <em>Science</em> <strong>352</strong>, 600–604. (doi:<a href="https://doi.org/10.1126/science.aad9417">10.1126/science.aad9417</a>)</p>
</div>
<div id="ref-11ETDdRKr">
<p>152. Barash Y, Calarco JA, Gao W, Pan Q, Wang X, Shai O, Blencowe BJ, Frey BJ. 2010 Deciphering the splicing code. <em>Nature</em> <strong>465</strong>, 53–59. (doi:<a href="https://doi.org/10.1038/nature09000">10.1038/nature09000</a>)</p>
</div>
<div id="ref-8VPGUHcf">
<p>153. Xiong HY, Barash Y, Frey BJ. 2011 Bayesian prediction of tissue-regulated splicing using RNA sequence and cellular context. <em>Bioinformatics</em> (doi:<a href="https://doi.org/10.1093/bioinformatics/btr444">10.1093/bioinformatics/btr444</a>)</p>
</div>
<div id="ref-17sgPdcMT">
<p>154. Xiong HY <em>et al.</em> 2014 The human splicing code reveals new insights into the genetic determinants of disease. <em>Science</em> <strong>347</strong>, 1254806–1254806. (doi:<a href="https://doi.org/10.1126/science.1254806">10.1126/science.1254806</a>)</p>
</div>
<div id="ref-N0HBi8MH">
<p>155. Jha A, Gazzara MR, Barash Y. 2017 Integrative Deep Models for Alternative Splicing. (doi:<a href="https://doi.org/10.1101/104869">10.1101/104869</a>)</p>
</div>
<div id="ref-Qbtqlmhf">
<p>156. Qin Q, Feng J. 2017 Imputation for transcription factor binding predictions based on deep learning. <em>PLOS Computational Biology</em> <strong>13</strong>, e1005403. (doi:<a href="https://doi.org/10.1371/journal.pcbi.1005403">10.1371/journal.pcbi.1005403</a>)</p>
</div>
<div id="ref-mlqKTlZY">
<p>157. Rosenberg A, Patwardhan R, Shendure J, Seelig G. 2015 Learning the Sequence Determinants of Alternative Splicing from Millions of Random Sequences. <em>Cell</em> <strong>163</strong>, 698–711. (doi:<a href="https://doi.org/10.1016/j.cell.2015.09.054">10.1016/j.cell.2015.09.054</a>)</p>
</div>
<div id="ref-CNz9HwZ3">
<p>158. Juan-Mateu J, Villate O, Eizirik DL. 2015 MECHANISMS IN ENDOCRINOLOGY: Alternative splicing: the new frontier in diabetes research. <em>European Journal of Endocrinology</em> <strong>174</strong>, R225–R238. (doi:<a href="https://doi.org/10.1530/eje-15-0916">10.1530/eje-15-0916</a>)</p>
</div>
<div id="ref-qnKdqG0P">
<p>159. Pan X, Shen H-B. 2017 RNA-protein binding motifs mining with a new hybrid deep learning based cross-domain knowledge integration approach. <em>BMC Bioinformatics</em> <strong>18</strong>. (doi:<a href="https://doi.org/10.1186/s12859-017-1561-8">10.1186/s12859-017-1561-8</a>)</p>
</div>
<div id="ref-1Bs5k1MVg">
<p>160. 2004 The ENCODE (ENCyclopedia Of DNA Elements) Project. <em>Science</em> <strong>306</strong>, 636–640. (doi:<a href="https://doi.org/10.1126/science.1105136">10.1126/science.1105136</a>)</p>
</div>
<div id="ref-ywDQIvZJ">
<p>161. Stormo GD. 2000 DNA binding sites: representation and discovery. <em>Bioinformatics</em> <strong>16</strong>, 16–23. (doi:<a href="https://doi.org/10.1093/bioinformatics/16.1.16">10.1093/bioinformatics/16.1.16</a>)</p>
</div>
<div id="ref-uZvDdFZo">
<p>162. Horton PB, Kanehisa M. 1992 An assessment of neural network and statistical approaches for prediction of E.coli Promoter sites. <em>Nucleic Acids Research</em> <strong>20</strong>, 4331–4338. (doi:<a href="https://doi.org/10.1093/nar/20.16.4331">10.1093/nar/20.16.4331</a>)</p>
</div>
<div id="ref-JxuQvvyk">
<p>163. Ghandi M, Lee D, Mohammad-Noori M, Beer MA. 2014 Enhanced Regulatory Sequence Prediction Using Gapped k-mer Features. <em>PLoS Computational Biology</em> <strong>10</strong>, e1003711. (doi:<a href="https://doi.org/10.1371/journal.pcbi.1003711">10.1371/journal.pcbi.1003711</a>)</p>
</div>
<div id="ref-138dgb9Ca">
<p>164. Setty M, Leslie CS. 2015 SeqGL Identifies Context-Dependent Binding Signals in Genome-Wide Regulatory Element Maps. <em>PLOS Computational Biology</em> <strong>11</strong>, e1004271. (doi:<a href="https://doi.org/10.1371/journal.pcbi.1004271">10.1371/journal.pcbi.1004271</a>)</p>
</div>
<div id="ref-2UI1BZuD">
<p>165. Zhou J, Troyanskaya OG. 2015 Predicting effects of noncoding variants with deep learning–based sequence model. <em>Nature Methods</em> <strong>12</strong>, 931–934. (doi:<a href="https://doi.org/10.1038/nmeth.3547">10.1038/nmeth.3547</a>)</p>
</div>
<div id="ref-Dwi2eAvT">
<p>166. Lanchantin J, Singh R, Wang B, Qi Y. 2016 Deep motif dashboard: Visualizing and understanding genomic sequences using deep neural networks. </p>
</div>
<div id="ref-182UhQqzp">
<p>167. Zeng H, Edwards MD, Liu G, Gifford DK. 2016 Convolutional neural network architectures for predicting DNA–protein binding. <em>Bioinformatics</em> <strong>32</strong>, i121–i127. (doi:<a href="https://doi.org/10.1093/bioinformatics/btw255">10.1093/bioinformatics/btw255</a>)</p>
</div>
<div id="ref-iEmvzeT8">
<p>168. Shrikumar A, Greenside P, Kundaje A. 2017 Reverse-complement parameter sharing improves deep learning models for genomics. (doi:<a href="https://doi.org/10.1101/103663">10.1101/103663</a>)</p>
</div>
<div id="ref-xAbGxia4">
<p>169. Shrikumar A, Greenside P, Shcherbina A, Kundaje A. 2016 Not just a black box: Learning important features through propagating activation differences. </p>
</div>
<div id="ref-fSpvdh5l">
<p>170. Lek M <em>et al.</em> 2016 Analysis of protein-coding genetic variation in 60,706 humans. <em>Nature</em> <strong>536</strong>, 285–291. (doi:<a href="https://doi.org/10.1038/nature19057">10.1038/nature19057</a>)</p>
</div>
<div id="ref-19jjiGHWc">
<p>171. Werner T. 2003 The state of the art of mammalian promoter recognition. <em>Briefings in Bioinformatics</em> <strong>4</strong>, 22–30. (doi:<a href="https://doi.org/10.1093/bib/4.1.22">10.1093/bib/4.1.22</a>)</p>
</div>
<div id="ref-8yA3foA6">
<p>172. Pennacchio LA, Bickmore W, Dean A, Nobrega MA, Bejerano G. 2013 Enhancers: five essential questions. <em>Nature Reviews Genetics</em> <strong>14</strong>, 288–295. (doi:<a href="https://doi.org/10.1038/nrg3458">10.1038/nrg3458</a>)</p>
</div>
<div id="ref-J0PJHcHK">
<p>173. Andersson R, Sandelin A, Danko CG. 2015 A unified architecture of transcriptional regulatory elements. <em>Trends in Genetics</em> <strong>31</strong>, 426–433. (doi:<a href="https://doi.org/10.1016/j.tig.2015.05.007">10.1016/j.tig.2015.05.007</a>)</p>
</div>
<div id="ref-5zmE7Qkb">
<p>174. Kwasnieski JC, Fiore C, Chaudhari HG, Cohen BA. 2014 High-throughput functional testing of ENCODE segmentation predictions. <em>Genome Research</em> <strong>24</strong>, 1595–1602. (doi:<a href="https://doi.org/10.1101/gr.173518.114">10.1101/gr.173518.114</a>)</p>
</div>
<div id="ref-huFxo9OA">
<p>175. Fickett JW, Hatzigeorgiou AG. 1997 Eukaryotic Promoter Recognition. <em>Genome Research</em> <strong>7</strong>, 861–878. (doi:<a href="https://doi.org/10.1101/gr.7.9.861">10.1101/gr.7.9.861</a>)</p>
</div>
<div id="ref-3Ew5V1iC">
<p>176. Matis S, Xu Y, Shah M, Guan X, Einstein J, Mural R, Uberbacher E. 1996 Detection of RNA polymerase II promoters and polyadenylation sites in human DNA sequence. <em>Computers &amp; Chemistry</em> <strong>20</strong>, 135–140. (doi:<a href="https://doi.org/10.1016/s0097-8485(96)80015-5">10.1016/s0097-8485(96)80015-5</a>)</p>
</div>
<div id="ref-2CbHXoFn">
<p>177. Kelley DR, Snoek J, Rinn JL. 2016 Basset: learning the regulatory code of the accessible genome with deep convolutional neural networks. <em>Genome Research</em> <strong>26</strong>, 990–999. (doi:<a href="https://doi.org/10.1101/gr.200535.115">10.1101/gr.200535.115</a>)</p>
</div>
<div id="ref-as2HfoSh">
<p>178. Umarov RK, Solovyev VV. 2017 Recognition of prokaryotic and eukaryotic promoters using convolutional deep learning neural networks. <em>PLOS ONE</em> <strong>12</strong>, e0171410. (doi:<a href="https://doi.org/10.1371/journal.pone.0171410">10.1371/journal.pone.0171410</a>)</p>
</div>
<div id="ref-jV2YerUS">
<p>179. Xu Min, Ning Chen, Ting Chen, Rui Jiang. 2016 DeepEnhancer: Predicting enhancers by convolutional neural networks. In <em>2016 IEEE International Conference on Bioinformatics and Biomedicine (BIBM)</em>, IEEE. (doi:<a href="https://doi.org/10.1109/bibm.2016.7822593">10.1109/bibm.2016.7822593</a>)</p>
</div>
<div id="ref-14TqLB9iZ">
<p>180. Singh S, Yang Y, Poczos B, Ma J. 2016 Predicting Enhancer-Promoter Interaction from Genomic Sequence with Deep Neural Networks. (doi:<a href="https://doi.org/10.1101/085241">10.1101/085241</a>)</p>
</div>
<div id="ref-1HbQQcY2q">
<p>181. Li Y, Shi W, Wasserman WW. 2016 Genome-Wide Prediction of cis-Regulatory Regions Using Supervised Deep Learning Methods. (doi:<a href="https://doi.org/10.1101/041616">10.1101/041616</a>)</p>
</div>
<div id="ref-yVKIhIAf">
<p>182. Bracken CP, Scott HS, Goodall GJ. 2016 A network-biology perspective of microRNA function and dysfunction in cancer. <em>Nature Reviews Genetics</em> <strong>17</strong>, 719–732. (doi:<a href="https://doi.org/10.1038/nrg.2016.134">10.1038/nrg.2016.134</a>)</p>
</div>
<div id="ref-8lpCCppx">
<p>183. Berezikov E. 2011 Evolution of microRNA diversity and regulation in animals. <em>Nature Reviews Genetics</em> <strong>12</strong>, 846–860. (doi:<a href="https://doi.org/10.1038/nrg3079">10.1038/nrg3079</a>)</p>
</div>
<div id="ref-12vPQi3gp">
<p>184. Agarwal V, Bell GW, Nam J-W, Bartel DP. 2015 Predicting effective microRNA target sites in mammalian mRNAs. <em>eLife</em> <strong>4</strong>. (doi:<a href="https://doi.org/10.7554/elife.05005">10.7554/elife.05005</a>)</p>
</div>
<div id="ref-1GwC1ll6h">
<p>185. Lee B, Baek J, Park S, Yoon S. 2016 DeepTarget: End-to-end learning framework for microRNA target prediction using deep recurrent neural networks. </p>
</div>
<div id="ref-1TeyWffV">
<p>186. Park S, Min S, Choi H, Yoon S. 2016 DeepMiRGene: Deep neural network based precursor microRNA prediction. </p>
</div>
<div id="ref-pNoAbBEu">
<p>187. Wang S, Sun S, Xu J. 2016 AUC-Maximized Deep Convolutional Neural Fields for Protein Sequence Labeling. In <em>Machine Learning and Knowledge Discovery in Databases</em>, pp. 1–16. Springer International Publishing. (doi:<a href="https://doi.org/10.1007/978-3-319-46227-1_1">10.1007/978-3-319-46227-1_1</a>)</p>
</div>
<div id="ref-7atXz0r">
<p>188. Jones DT, Singh T, Kosciolek T, Tetchner S. 2014 MetaPSICOV: combining coevolution methods for accurate prediction of contacts and long range hydrogen bonding in proteins. <em>Bioinformatics</em> <strong>31</strong>, 999–1006. (doi:<a href="https://doi.org/10.1093/bioinformatics/btu791">10.1093/bioinformatics/btu791</a>)</p>
</div>
<div id="ref-kboAopkh">
<p>189. Weigt M, White RA, Szurmant H, Hoch JA, Hwa T. 2008 Identification of direct residue contacts in protein-protein interaction by message passing. <em>Proceedings of the National Academy of Sciences</em> <strong>106</strong>, 67–72. (doi:<a href="https://doi.org/10.1073/pnas.0805923106">10.1073/pnas.0805923106</a>)</p>
</div>
<div id="ref-10dNuD89l">
<p>190. Marks DS, Colwell LJ, Sheridan R, Hopf TA, Pagnani A, Zecchina R, Sander C. 2011 Protein 3D Structure Computed from Evolutionary Sequence Variation. <em>PLoS ONE</em> <strong>6</strong>, e28766. (doi:<a href="https://doi.org/10.1371/journal.pone.0028766">10.1371/journal.pone.0028766</a>)</p>
</div>
<div id="ref-1AlhRKQbe">
<p>191. Qi Y, Oja M, Weston J, Noble WS. 2012 A Unified Multitask Architecture for Predicting Local Protein Properties. <em>PLoS ONE</em> <strong>7</strong>, e32235. (doi:<a href="https://doi.org/10.1371/journal.pone.0032235">10.1371/journal.pone.0032235</a>)</p>
</div>
<div id="ref-UpFrhdJf">
<p>192. Heffernan R, Paliwal K, Lyons J, Dehzangi A, Sharma A, Wang J, Sattar A, Yang Y, Zhou Y. 2015 Improving prediction of secondary structure, local backbone angles, and solvent accessible surface area of proteins by iterative deep learning. <em>Scientific Reports</em> <strong>5</strong>, 11476. (doi:<a href="https://doi.org/10.1038/srep11476">10.1038/srep11476</a>)</p>
</div>
<div id="ref-Aic7UyXM">
<p>193. Jones DT. 1999 Protein secondary structure prediction based on position-specific scoring matrices. <em>Journal of Molecular Biology</em> <strong>292</strong>, 195–202. (doi:<a href="https://doi.org/10.1006/jmbi.1999.3091">10.1006/jmbi.1999.3091</a>)</p>
</div>
<div id="ref-8t43CQ9m">
<p>194. Zhou J, Troyanskaya OG. 2014 Deep supervised and convolutional generative stochastic network for protein secondary structure prediction. </p>
</div>
<div id="ref-kqjqFesT">
<p>195. Ma J, Wang S, Wang Z, Xu J. 2015 Protein contact prediction by integrating joint evolutionary coupling analysis and supervised learning. <em>Bioinformatics</em> <strong>31</strong>, 3506–3513. (doi:<a href="https://doi.org/10.1093/bioinformatics/btv472">10.1093/bioinformatics/btv472</a>)</p>
</div>
<div id="ref-xdoT1yUx">
<p>196. Di Lena P, Nagata K, Baldi P. 2012 Deep architectures for protein contact map prediction. <em>Bioinformatics</em> <strong>28</strong>, 2449–2457. (doi:<a href="https://doi.org/10.1093/bioinformatics/bts475">10.1093/bioinformatics/bts475</a>)</p>
</div>
<div id="ref-18bNbDNlc">
<p>197. Eickholt J, Cheng J. 2012 Predicting protein residue-residue contacts using deep networks and boosting. <em>Bioinformatics</em> <strong>28</strong>, 3066–3072. (doi:<a href="https://doi.org/10.1093/bioinformatics/bts598">10.1093/bioinformatics/bts598</a>)</p>
</div>
<div id="ref-F13xtRbV">
<p>198. Skwark MJ, Raimondi D, Michel M, Elofsson A. 2014 Improved Contact Predictions Using the Recognition of Protein Like Contact Patterns. <em>PLoS Computational Biology</em> <strong>10</strong>, e1003889. (doi:<a href="https://doi.org/10.1371/journal.pcbi.1003889">10.1371/journal.pcbi.1003889</a>)</p>
</div>
<div id="ref-zScWGveU">
<p>199. In press. See <a href="http://www.predictioncenter.org/casp12/rrc_avrg_results.cgi" class="uri">http://www.predictioncenter.org/casp12/rrc_avrg_results.cgi</a>.</p>
</div>
<div id="ref-u9uApoaB">
<p>200. In press. See <a href="http://www.cameo3d.org/" class="uri">http://www.cameo3d.org/</a>.</p>
</div>
<div id="ref-39RPiE10">
<p>201. Li Z, Wang S, Yu Y, Xu J. 2017 Predicting membrane protein contacts from non-membrane proteins by deep transfer learning. </p>
</div>
<div id="ref-40EG4ZEU">
<p>202. Van Valen DA <em>et al.</em> 2016 Deep Learning Automates the Quantitative Analysis of Individual Cells in Live-Cell Imaging Experiments. <em>PLOS Computational Biology</em> <strong>12</strong>, e1005177. (doi:<a href="https://doi.org/10.1371/journal.pcbi.1005177">10.1371/journal.pcbi.1005177</a>)</p>
</div>
<div id="ref-TutLhFSz">
<p>203. Ronneberger O, Fischer P, Brox T. 2015 U-Net: Convolutional Networks for Biomedical Image Segmentation. In <em>Lecture Notes in Computer Science</em>, pp. 234–241. Springer International Publishing. (doi:<a href="https://doi.org/10.1007/978-3-319-24574-4_28">10.1007/978-3-319-24574-4_28</a>)</p>
</div>
<div id="ref-On4vW5aU">
<p>204. Buggenthin F <em>et al.</em> 2017 Prospective identification of hematopoietic lineage choice by deep learning. <em>Nature Methods</em> <strong>14</strong>, 403–406. (doi:<a href="https://doi.org/10.1038/nmeth.4182">10.1038/nmeth.4182</a>)</p>
</div>
<div id="ref-gllSeTW">
<p>205. Eulenberg P, Koehler N, Blasi T, Filby A, Carpenter AE, Rees P, Theis FJ, Wolf FA. 2016 Deep Learning for Imaging Flow Cytometry: Cell Cycle Analysis of Jurkat Cells. (doi:<a href="https://doi.org/10.1101/081364">10.1101/081364</a>)</p>
</div>
<div id="ref-BMg062hc">
<p>206. Pawlowski N, Caicedo JC, Singh S, Carpenter AE, Storkey A. 2016 Automating Morphological Profiling with Generic Deep Convolutional Networks. (doi:<a href="https://doi.org/10.1101/085118">10.1101/085118</a>)</p>
</div>
<div id="ref-hkKO4QYl">
<p>207. Caicedo JC, Singh S, Carpenter AE. 2016 Applications in image-based profiling of perturbations. <em>Current Opinion in Biotechnology</em> <strong>39</strong>, 134–142. (doi:<a href="https://doi.org/10.1016/j.copbio.2016.04.003">10.1016/j.copbio.2016.04.003</a>)</p>
</div>
<div id="ref-m3Ij21U8">
<p>208. Bougen-Zhukov N, Loh SY, Lee HK, Loo L-H. 2016 Large-scale image-based screening and profiling of cellular phenotypes. <em>Cytometry Part A</em> <strong>91</strong>, 115–125. (doi:<a href="https://doi.org/10.1002/cyto.a.22909">10.1002/cyto.a.22909</a>)</p>
</div>
<div id="ref-McjXFLLq">
<p>209. Grys BT, Lo DS, Sahin N, Kraus OZ, Morris Q, Boone C, Andrews BJ. 2016 Machine learning and computer vision approaches for phenotypic profiling. <em>The Journal of Cell Biology</em> <strong>216</strong>, 65–71. (doi:<a href="https://doi.org/10.1083/jcb.201610026">10.1083/jcb.201610026</a>)</p>
</div>
<div id="ref-1GvfSy48x">
<p>210. Lodato MA <em>et al.</em> 2015 Somatic mutation in single human neurons tracks developmental and transcriptional history. <em>Science</em> <strong>350</strong>, 94–98. (doi:<a href="https://doi.org/10.1126/science.aab1785">10.1126/science.aab1785</a>)</p>
</div>
<div id="ref-QafUwNKn">
<p>211. Liu S, Trapnell C. 2016 Single-cell transcriptome sequencing: recent advances and remaining challenges. <em>F1000Research</em> (doi:<a href="https://doi.org/10.12688/f1000research.7223.1">10.12688/f1000research.7223.1</a>)</p>
</div>
<div id="ref-v97iPXDw">
<p>212. Vera M, Biswas J, Senecal A, Singer RH, Park HY. 2016 Single-Cell and Single-Molecule Analysis of Gene Expression Regulation. <em>Annual Review of Genetics</em> <strong>50</strong>, 267–291. (doi:<a href="https://doi.org/10.1146/annurev-genet-120215-034854">10.1146/annurev-genet-120215-034854</a>)</p>
</div>
<div id="ref-19EJTHByG">
<p>213. Angermueller C, Lee HJ, Reik W, Stegle O. 2017 DeepCpG: accurate prediction of single-cell DNA methylation states using deep learning. <em>Genome Biology</em> <strong>18</strong>. (doi:<a href="https://doi.org/10.1186/s13059-017-1189-z">10.1186/s13059-017-1189-z</a>)</p>
</div>
<div id="ref-XimuXZlz">
<p>214. Koh PW, Pierson E, Kundaje A. 2016 Denoising genome-wide histone ChIP-seq with convolutional neural networks. (doi:<a href="https://doi.org/10.1101/052118">10.1101/052118</a>)</p>
</div>
<div id="ref-T2Md9xLY">
<p>215. Shaham U, Stanton KP, Zhao J, Li H, Raddassi K, Montgomery R, Kluger Y. 2016 Removal of batch effects using distribution-matching residual networks. </p>
</div>
<div id="ref-1HPu3R2B4">
<p>216. Gaublomme J <em>et al.</em> 2015 Single-Cell Genomics Unveils Critical Regulators of Th17 Cell Pathogenicity. <em>Cell</em> <strong>163</strong>, 1400–1412. (doi:<a href="https://doi.org/10.1016/j.cell.2015.11.009">10.1016/j.cell.2015.11.009</a>)</p>
</div>
<div id="ref-r3Gbjksq">
<p>217. Arvaniti E, Claassen M. 2016 Sensitive detection of rare disease-associated cell subsets via representation learning. (doi:<a href="https://doi.org/10.1101/046508">10.1101/046508</a>)</p>
</div>
<div id="ref-j7KrVyi8">
<p>218. He K, Zhang X, Ren S, Sun J. 2015 Deep residual learning for image recognition. </p>
</div>
<div id="ref-Oljj2W96">
<p>219. Qiu X, Mao Q, Tang Y, Wang L, Chawla R, Pliner H, Trapnell C. 2017 Reversed graph embedding resolves complex single-cell developmental trajectories. (doi:<a href="https://doi.org/10.1101/110668">10.1101/110668</a>)</p>
</div>
<div id="ref-2gn6PKkv">
<p>220. Silver D <em>et al.</em> 2016 Mastering the game of Go with deep neural networks and tree search. <em>Nature</em> <strong>529</strong>, 484–489. (doi:<a href="https://doi.org/10.1038/nature16961">10.1038/nature16961</a>)</p>
</div>
<div id="ref-N9NzkOjA">
<p>221. Karlin S, Mrázek J, Campbell AM. 1997 Compositional biases of bacterial genomes and evolutionary implications. <em>Journal of Bacteriology</em> <strong>179</strong>, 3899–3913. (doi:<a href="https://doi.org/10.1128/jb.179.12.3899-3913.1997">10.1128/jb.179.12.3899-3913.1997</a>)</p>
</div>
<div id="ref-QV551Nlx">
<p>222. McHardy AC, Martín HG, Tsirigos A, Hugenholtz P, Rigoutsos I. 2006 Accurate phylogenetic classification of variable-length DNA fragments. <em>Nature Methods</em> <strong>4</strong>, 63–72. (doi:<a href="https://doi.org/10.1038/nmeth976">10.1038/nmeth976</a>)</p>
</div>
<div id="ref-1HtJuEkb2">
<p>223. Rosen GL, Reichenberger ER, Rosenfeld AM. 2010 NBC: the Naive Bayes Classification tool webserver for taxonomic classification of metagenomic reads. <em>Bioinformatics</em> <strong>27</strong>, 127–129. (doi:<a href="https://doi.org/10.1093/bioinformatics/btq619">10.1093/bioinformatics/btq619</a>)</p>
</div>
<div id="ref-1HhqhBwrM">
<p>224. Abe T. 2003 Informatics for Unveiling Hidden Genome Signatures. <em>Genome Research</em> <strong>13</strong>, 693–702. (doi:<a href="https://doi.org/10.1101/gr.634603">10.1101/gr.634603</a>)</p>
</div>
<div id="ref-56wEWVIl">
<p>225. Segata N, Waldron L, Ballarini A, Narasimhan V, Jousson O, Huttenhower C. 2012 Metagenomic microbial community profiling using unique clade-specific marker genes. <em>Nature Methods</em> <strong>9</strong>, 811–814. (doi:<a href="https://doi.org/10.1038/nmeth.2066">10.1038/nmeth.2066</a>)</p>
</div>
<div id="ref-RqhGD9c7">
<p>226. Koslicki D, Foucart S, Rosen G. 2014 WGSQuikr: Fast Whole-Genome Shotgun Metagenomic Classification. <em>PLoS ONE</em> <strong>9</strong>, e91784. (doi:<a href="https://doi.org/10.1371/journal.pone.0091784">10.1371/journal.pone.0091784</a>)</p>
</div>
<div id="ref-189TQrQA9">
<p>227. Ames SK, Hysom DA, Gardner SN, Lloyd GS, Gokhale MB, Allen JE. 2013 Scalable metagenomic taxonomy classification using a reference genome database. <em>Bioinformatics</em> <strong>29</strong>, 2253–2260. (doi:<a href="https://doi.org/10.1093/bioinformatics/btt389">10.1093/bioinformatics/btt389</a>)</p>
</div>
<div id="ref-8DLzxOEt">
<p>228. Vervier K, Mahé P, Tournoud M, Veyrieras J-B, Vert J-P. 2015 Large-scale machine learning for metagenomics sequence classification. <em>Bioinformatics</em> <strong>32</strong>, 1023–1032. (doi:<a href="https://doi.org/10.1093/bioinformatics/btv683">10.1093/bioinformatics/btv683</a>)</p>
</div>
<div id="ref-qUGH5CX8">
<p>229. Yok NG, Rosen GL. 2011 Combining gene prediction methods to improve metagenomic gene annotation. <em>BMC Bioinformatics</em> <strong>12</strong>, 20. (doi:<a href="https://doi.org/10.1186/1471-2105-12-20">10.1186/1471-2105-12-20</a>)</p>
</div>
<div id="ref-yFOAeemA">
<p>230. Soueidan H, Nikolski M. 2017 Machine learning for metagenomics: methods and tools. <em>Metagenomics</em> <strong>1</strong>. (doi:<a href="https://doi.org/10.1515/metgen-2016-0001">10.1515/metgen-2016-0001</a>)</p>
</div>
<div id="ref-W0cYSf89">
<p>231. In press. See <a href="http://www.fasebj.org/content/30/1_Supplement/406.3" class="uri">http://www.fasebj.org/content/30/1_Supplement/406.3</a>.</p>
</div>
<div id="ref-aI9g2UOc">
<p>232. Knights D, Costello EK, Knight R. 2011 Supervised classification of human microbiota. <em>FEMS Microbiology Reviews</em> <strong>35</strong>, 343–359. (doi:<a href="https://doi.org/10.1111/j.1574-6976.2010.00251.x">10.1111/j.1574-6976.2010.00251.x</a>)</p>
</div>
<div id="ref-c5P9jHCg">
<p>233. Statnikov A <em>et al.</em> 2013 A comprehensive evaluation of multicategory classification methods for microbiomic data. <em>Microbiome</em> <strong>1</strong>, 11. (doi:<a href="https://doi.org/10.1186/2049-2618-1-11">10.1186/2049-2618-1-11</a>)</p>
</div>
<div id="ref-y9s5irW">
<p>234. Pasolli E, Truong DT, Malik F, Waldron L, Segata N. 2016 Machine Learning Meta-analysis of Large Metagenomic Datasets: Tools and Biological Insights. <em>PLOS Computational Biology</em> <strong>12</strong>, e1004977. (doi:<a href="https://doi.org/10.1371/journal.pcbi.1004977">10.1371/journal.pcbi.1004977</a>)</p>
</div>
<div id="ref-5W4KMSdT">
<p>235. Ding X, Cheng F, Cao C, Sun X. 2015 DectICO: an alignment-free supervised metagenomic classification method based on feature extraction and dynamic selection. <em>BMC Bioinformatics</em> <strong>16</strong>. (doi:<a href="https://doi.org/10.1186/s12859-015-0753-3">10.1186/s12859-015-0753-3</a>)</p>
</div>
<div id="ref-Kt9NojjR">
<p>236. Liu Z, Chen D, Sheng L, Liu AY. 2014 Correction: Class Prediction and Feature Selection with Linear Optimization for Metagenomic Count Data. <em>PLoS ONE</em> <strong>9</strong>, e97958. (doi:<a href="https://doi.org/10.1371/journal.pone.0097958">10.1371/journal.pone.0097958</a>)</p>
</div>
<div id="ref-1AN5UPfb1">
<p>237. Ditzler G, Morrison JC, Lan Y, Rosen GL. 2015 Fizzy: feature subset selection for metagenomics. <em>BMC Bioinformatics</em> <strong>16</strong>. (doi:<a href="https://doi.org/10.1186/s12859-015-0793-8">10.1186/s12859-015-0793-8</a>)</p>
</div>
<div id="ref-O9D66oYa">
<p>238. Ditzler G, Polikar R, Rosen G. 2015 A Bootstrap Based Neyman-Pearson Test for Identifying Variable Importance. <em>IEEE Transactions on Neural Networks and Learning Systems</em> <strong>26</strong>, 880–886. (doi:<a href="https://doi.org/10.1109/tnnls.2014.2320415">10.1109/tnnls.2014.2320415</a>)</p>
</div>
<div id="ref-q1A2AEtO">
<p>239. Hoff KJ, Lingner T, Meinicke P, Tech M. 2009 Orphelia: predicting genes in metagenomic sequencing reads. <em>Nucleic Acids Research</em> <strong>37</strong>, W101–W105. (doi:<a href="https://doi.org/10.1093/nar/gkp327">10.1093/nar/gkp327</a>)</p>
</div>
<div id="ref-QlbXLqH">
<p>240. Rho M, Tang H, Ye Y. 2010 FragGeneScan: predicting genes in short and error-prone reads. <em>Nucleic Acids Research</em> <strong>38</strong>, e191–e191. (doi:<a href="https://doi.org/10.1093/nar/gkq747">10.1093/nar/gkq747</a>)</p>
</div>
<div id="ref-1E1PWjqTm">
<p>241. Asgari E, Mofrad MRK. 2015 Continuous Distributed Representation of Biological Sequences for Deep Proteomics and Genomics. <em>PLOS ONE</em> <strong>10</strong>, e0141287. (doi:<a href="https://doi.org/10.1371/journal.pone.0141287">10.1371/journal.pone.0141287</a>)</p>
</div>
<div id="ref-G8RKF6sz">
<p>242. Hochreiter S, Heusel M, Obermayer K. 2007 Fast model-based protein homology detection without alignment. <em>Bioinformatics</em> <strong>23</strong>, 1728–1736. (doi:<a href="https://doi.org/10.1093/bioinformatics/btm247">10.1093/bioinformatics/btm247</a>)</p>
</div>
<div id="ref-81Cl5QSM">
<p>243. Sønderby SK, Sønderby CK, Nielsen H, Winther O. 2015 Convolutional lstm networks for subcellular localization of proteins. (doi:<a href="https://doi.org/10.1007/978-3-319-21233-3_6">10.1007/978-3-319-21233-3_6</a>)</p>
</div>
<div id="ref-11wVLI2Hn">
<p>244. Essinger SD, Polikar R, Rosen GL. 2010 Neural network-based taxonomic clustering for metagenomics. In <em>The 2010 International Joint Conference on Neural Networks (IJCNN)</em>, IEEE. (doi:<a href="https://doi.org/10.1109/ijcnn.2010.5596644">10.1109/ijcnn.2010.5596644</a>)</p>
</div>
<div id="ref-c4rnN1wo">
<p>245. Kelley DR, Salzberg SL. 2010 Clustering metagenomic sequences with interpolated Markov models. <em>BMC Bioinformatics</em> <strong>11</strong>, 544. (doi:<a href="https://doi.org/10.1186/1471-2105-11-544">10.1186/1471-2105-11-544</a>)</p>
</div>
<div id="ref-Wz7VUS03">
<p>246. RASHEED Z, RANGWALA H. 2012 METAGENOMIC TAXONOMIC CLASSIFICATION USING EXTREME LEARNING MACHINES. <em>Journal of Bioinformatics and Computational Biology</em> <strong>10</strong>, 1250015. (doi:<a href="https://doi.org/10.1142/s0219720012500151">10.1142/s0219720012500151</a>)</p>
</div>
<div id="ref-iPIJrVVs">
<p>247. In press. See <a href="https://repozitorij.uni-lj.si/IzpisGradiva.php?id=85515" class="uri">https://repozitorij.uni-lj.si/IzpisGradiva.php?id=85515</a>.</p>
</div>
<div id="ref-oas5tbC7">
<p>248. Chudobova D <em>et al.</em> 2015 Influence of microbiome species in hard-to-heal wounds on disease severity and treatment duration. <em>The Brazilian Journal of Infectious Diseases</em> <strong>19</strong>, 604–613. (doi:<a href="https://doi.org/10.1016/j.bjid.2015.08.013">10.1016/j.bjid.2015.08.013</a>)</p>
</div>
<div id="ref-i38A0beL">
<p>249. Ditzler G, Polikar R, Rosen G. 2015 Multi-Layer and Recursive Neural Networks for Metagenomic Classification. <em>IEEE Transactions on NanoBioscience</em> <strong>14</strong>, 608–616. (doi:<a href="https://doi.org/10.1109/tnb.2015.2461219">10.1109/tnb.2015.2461219</a>)</p>
</div>
<div id="ref-NQ5jiN7B">
<p>250. In press. See <a href="http://alifar76.github.io/sklearn-metrics/" class="uri">http://alifar76.github.io/sklearn-metrics/</a>.</p>
</div>
<div id="ref-g2vvbB91">
<p>251. Bengio Y, Boulanger-Lewandowski N, Pascanu R. 2012 Advances in optimizing recurrent networks. </p>
</div>
<div id="ref-1BTJ1KqRa">
<p>252. Boža V, Brejová B, Vinař T. 2016 DeepNano: Deep recurrent neural networks for base calling in minion nanopore reads. </p>
</div>
<div id="ref-2cMhMv5A">
<p>253. Sutskever I, Vinyals O, Le QV. 2014 Sequence to sequence learning with neural networks. </p>
</div>
<div id="ref-FVfZESYP">
<p>254. Poplin R, Newburger D, Dijamco J, Nguyen N, Loy D, Gross SS, McLean CY, DePristo MA. 2016 Creating a universal SNP and small indel variant caller with deep neural networks. (doi:<a href="https://doi.org/10.1101/092890">10.1101/092890</a>)</p>
</div>
<div id="ref-GSLRw2L5">
<p>255. Torracinta R, Campagne F. 2016 Training Genotype Callers with Neural Networks. (doi:<a href="https://doi.org/10.1101/097469">10.1101/097469</a>)</p>
</div>
<div id="ref-VMkPJjVk">
<p>256. Chollet F. 2016 Xception: Deep learning with depthwise separable convolutions. </p>
</div>
<div id="ref-ECTm1SuA">
<p>257. Torracinta R, Mesnard L, Levine S, Shaknovich R, Hanson M, Campagne F. 2016 Adaptive Somatic Mutations Calls with Deep Learning and Semi-Simulated Data. (doi:<a href="https://doi.org/10.1101/079087">10.1101/079087</a>)</p>
</div>
<div id="ref-VOQtVhWs">
<p>258. Hamburg MA, Collins FS. 2010 The Path to Personalized Medicine. <em>New England Journal of Medicine</em> <strong>363</strong>, 301–304. (doi:<a href="https://doi.org/10.1056/nejmp1006304">10.1056/nejmp1006304</a>)</p>
</div>
<div id="ref-3JyJ3DTh">
<p>259. Belle A, Kon MA, Najarian K. 2013 Biomedical Informatics for Computer-Aided Decision Support Systems: A Survey. <em>The Scientific World Journal</em> <strong>2013</strong>, 1–8. (doi:<a href="https://doi.org/10.1155/2013/769639">10.1155/2013/769639</a>)</p>
</div>
<div id="ref-kL0B4m9d">
<p>260. Tu JV. 1996 Advantages and disadvantages of using artificial neural networks versus logistic regression for predicting medical outcomes. <em>Journal of Clinical Epidemiology</em> <strong>49</strong>, 1225–1231. (doi:<a href="https://doi.org/10.1016/s0895-4356(96)00002-9">10.1016/s0895-4356(96)00002-9</a>)</p>
</div>
<div id="ref-jdg2u7bX">
<p>261. Baxt WG. 1991 Use of an Artificial Neural Network for the Diagnosis of Myocardial Infarction. <em>Annals of Internal Medicine</em> <strong>115</strong>, 843. (doi:<a href="https://doi.org/10.7326/0003-4819-115-11-843">10.7326/0003-4819-115-11-843</a>)</p>
</div>
<div id="ref-xX68eyvs">
<p>262. Wasson JH, Sox HC, Neff RK, Goldman L. 1985 Clinical Prediction Rules. <em>New England Journal of Medicine</em> <strong>313</strong>, 793–799. (doi:<a href="https://doi.org/10.1056/nejm198509263131306">10.1056/nejm198509263131306</a>)</p>
</div>
<div id="ref-qxxwkSAT">
<p>263. Lisboa PJ, Taktak AF. 2006 The use of artificial neural networks in decision support in cancer: A systematic review. <em>Neural Networks</em> <strong>19</strong>, 408–415. (doi:<a href="https://doi.org/10.1016/j.neunet.2005.10.007">10.1016/j.neunet.2005.10.007</a>)</p>
</div>
<div id="ref-cpNVdlL7">
<p>264. Rubin DB. 1974 Estimating causal effects of treatments in randomized and nonrandomized studies. <em>Journal of Educational Psychology</em> <strong>66</strong>, 688–701. (doi:<a href="https://doi.org/10.1037/h0037350">10.1037/h0037350</a>)</p>
</div>
<div id="ref-173ftiSzF">
<p>265. Johansson FD, Shalit U, Sontag D. 2016 Learning representations for counterfactual inference. </p>
</div>
<div id="ref-FUIfIdE">
<p>266. Kale DC, Che Z, Bahadori MT, Li W, Liu Y, Wetzel R. 2015 Causal Phenotype Discovery via Deep Networks. <em>AMIA Annu Symp Proc</em> <strong>2015</strong>, 677–686. </p>
</div>
<div id="ref-4zpZxjHR">
<p>267. Lipton ZC, Kale DC, Wetzel R. 2016 Modeling missing data in clinical time series with rnns. </p>
</div>
<div id="ref-O7Vbecm2">
<p>268. Che Z, Purushotham S, Cho K, Sontag D, Liu Y. 2016 Recurrent neural networks for multivariate time series with missing values. </p>
</div>
<div id="ref-fOaBA9Vc">
<p>269. Huddar V, Desiraju BK, Rajan V, Bhattacharya S, Roy S, Reddy CK. 2016 Predicting Complications in Critical Care Using Heterogeneous Clinical Data. <em>IEEE Access</em> <strong>4</strong>, 7988–8001. (doi:<a href="https://doi.org/10.1109/access.2016.2618775">10.1109/access.2016.2618775</a>)</p>
</div>
<div id="ref-glyI7H6F">
<p>270. Lipton ZC, Kale DC, Wetzel RC. 2015 Phenotyping of clinical time series with lstm recurrent neural networks. </p>
</div>
<div id="ref-16OQvsRqJ">
<p>271. Nemati S, Ghassemi MM, Clifford GD. 2016 Optimal medication dosing from suboptimal clinical examples: A deep reinforcement learning approach. In <em>2016 38th Annual International Conference of the IEEE Engineering in Medicine and Biology Society (EMBC)</em>, IEEE. (doi:<a href="https://doi.org/10.1109/embc.2016.7591355">10.1109/embc.2016.7591355</a>)</p>
</div>
<div id="ref-eCrLGgiX">
<p>272. Gultepe E, Green JP, Nguyen H, Adams J, Albertson T, Tagkopoulos I. 2014 From vital signs to clinical outcomes for patients with sepsis: a machine learning basis for a clinical decision support system. <em>Journal of the American Medical Informatics Association</em> <strong>21</strong>, 315–325. (doi:<a href="https://doi.org/10.1136/amiajnl-2013-001815">10.1136/amiajnl-2013-001815</a>)</p>
</div>
<div id="ref-eehGXQlY">
<p>273. Ithapu VK, Singh V, Okonkwo OC, Chappell RJ, Dowling NM, Johnson SC. 2015 Imaging-based enrichment criteria using deep learning algorithms for efficient clinical trials in mild cognitive impairment. <em>Alzheimer’s &amp; Dementia</em> <strong>11</strong>, 1489–1499. (doi:<a href="https://doi.org/10.1016/j.jalz.2015.01.010">10.1016/j.jalz.2015.01.010</a>)</p>
</div>
<div id="ref-mo3GQwJj">
<p>274. Artemov AV, Putin E, Vanhaelen Q, Aliper A, Ozerov IV, Zhavoronkov A. 2016 Integrated deep learned transcriptomic and structure-based predictor of clinical trials outcomes. (doi:<a href="https://doi.org/10.1101/095653">10.1101/095653</a>)</p>
</div>
<div id="ref-13c9OPizf">
<p>275. DiMasi JA, Grabowski HG, Hansen RW. 2016 Innovation in the pharmaceutical industry: New estimates of R&amp;D costs. <em>Journal of Health Economics</em> <strong>47</strong>, 20–33. (doi:<a href="https://doi.org/10.1016/j.jhealeco.2016.01.012">10.1016/j.jhealeco.2016.01.012</a>)</p>
</div>
<div id="ref-79Ktl2">
<p>276. Waring MJ <em>et al.</em> 2015 An analysis of the attrition of drug candidates from four major pharmaceutical companies. <em>Nature Reviews Drug Discovery</em> <strong>14</strong>, 475–486. (doi:<a href="https://doi.org/10.1038/nrd4609">10.1038/nrd4609</a>)</p>
</div>
<div id="ref-Ot5bUkmI">
<p>277. Lamb J. 2006 The Connectivity Map: Using Gene-Expression Signatures to Connect Small Molecules, Genes, and Disease. <em>Science</em> <strong>313</strong>, 1929–1935. (doi:<a href="https://doi.org/10.1126/science.1132939">10.1126/science.1132939</a>)</p>
</div>
<div id="ref-gTwjIQqB">
<p>278. Li J, Zheng S, Chen B, Butte AJ, Swamidass SJ, Lu Z. 2015 A survey of current trends in computational drug repositioning. <em>Briefings in Bioinformatics</em> <strong>17</strong>, 2–12. (doi:<a href="https://doi.org/10.1093/bib/bbv020">10.1093/bib/bbv020</a>)</p>
</div>
<div id="ref-1BkEtNVsj">
<p>279. Musa A, Ghoraie LS, Zhang S-D, Galzko G, Yli-Harja O, Dehmer M, Haibe-Kains B, Emmert-Streib F. 2017 A review of connectivity map and computational approaches in pharmacogenomics. <em>Briefings in Bioinformatics</em>, bbw112. (doi:<a href="https://doi.org/10.1093/bib/bbw112">10.1093/bib/bbw112</a>)</p>
</div>
<div id="ref-ir7ElHha">
<p>280. 2016 OUP accepted manuscript. <em>Briefings In Bioinformatics</em> (doi:<a href="https://doi.org/10.1093/bib/bbw110">10.1093/bib/bbw110</a>)</p>
</div>
<div id="ref-M1EW8Rfl">
<p>281. Napolitano F, Zhao Y, Moreira VM, Tagliaferri R, Kere J, D’Amato M, Greco D. 2013 Drug Repositioning: A Machine-Learning Approach through Data Integration. <em>Journal of Cheminformatics</em> <strong>5</strong>, 30. (doi:<a href="https://doi.org/10.1186/1758-2946-5-30">10.1186/1758-2946-5-30</a>)</p>
</div>
<div id="ref-16FEYidu2">
<p>282. Yang J, Li Z, Fan X, Cheng Y. 2014 Drug–Disease Association and Drug-Repositioning Predictions in Complex Diseases Using Causal Inference–Probabilistic Matrix Factorization. <em>Journal of Chemical Information and Modeling</em> <strong>54</strong>, 2562–2569. (doi:<a href="https://doi.org/10.1021/ci500340n">10.1021/ci500340n</a>)</p>
</div>
<div id="ref-18lqFDKRR">
<p>283. Huang C-H, Chang PM-H, Hsu C-W, Huang C-YF, Ng K-L. 2016 Drug repositioning for non-small cell lung cancer by using machine learning algorithms and topological graph theory. <em>BMC Bioinformatics</em> <strong>17</strong>. (doi:<a href="https://doi.org/10.1186/s12859-015-0845-0">10.1186/s12859-015-0845-0</a>)</p>
</div>
<div id="ref-QcwZC8wG">
<p>284. Menden MP, Iorio F, Garnett M, McDermott U, Benes CH, Ballester PJ, Saez-Rodriguez J. 2013 Machine Learning Prediction of Cancer Cell Sensitivity to Drugs Based on Genomic and Chemical Properties. <em>PLoS ONE</em> <strong>8</strong>, e61318. (doi:<a href="https://doi.org/10.1371/journal.pone.0061318">10.1371/journal.pone.0061318</a>)</p>
</div>
<div id="ref-ppGS5h4v">
<p>285. VidoviÄ‡ D, Koleti A, SchÃ¼rer SC. 2014 Large-scale integration of small molecule-induced genome-wide transcriptional responses, Kinome-wide binding affinities and cell-growth inhibition profiles reveal global trends characterizing systems-level drug action. <em>Frontiers in Genetics</em> <strong>5</strong>. (doi:<a href="https://doi.org/10.3389/fgene.2014.00342">10.3389/fgene.2014.00342</a>)</p>
</div>
<div id="ref-tOpadZQw">
<p>286. Coelho ED, Arrais JP, Oliveira JL. 2016 Computational Discovery of Putative Leads for Drug Repositioning through Drug-Target Interaction Prediction. <em>PLOS Computational Biology</em> <strong>12</strong>, e1005219. (doi:<a href="https://doi.org/10.1371/journal.pcbi.1005219">10.1371/journal.pcbi.1005219</a>)</p>
</div>
<div id="ref-1SIuofeg">
<p>287. Lim H, Poleksic A, Yao Y, Tong H, He D, Zhuang L, Meng P, Xie L. 2016 Large-Scale Off-Target Identification Using Fast and Accurate Dual Regularized One-Class Collaborative Filtering and Its Application to Drug Repurposing. <em>PLOS Computational Biology</em> <strong>12</strong>, e1005135. (doi:<a href="https://doi.org/10.1371/journal.pcbi.1005135">10.1371/journal.pcbi.1005135</a>)</p>
</div>
<div id="ref-TeIxEjqm">
<p>288. Wang C, Liu J, Luo F, Tan Y, Deng Z, Hu Q-N. 2014 Pairwise input neural network for target-ligand interaction prediction. In <em>2014 IEEE International Conference on Bioinformatics and Biomedicine (BIBM)</em>, IEEE. (doi:<a href="https://doi.org/10.1109/bibm.2014.6999129">10.1109/bibm.2014.6999129</a>)</p>
</div>
<div id="ref-cQAldRdg">
<p>289. Duan Q <em>et al.</em> 2016 L1000CDS2: LINCS L1000 characteristic direction signatures search engine. <em>npj Systems Biology and Applications</em> <strong>2</strong>. (doi:<a href="https://doi.org/10.1038/npjsba.2016.15">10.1038/npjsba.2016.15</a>)</p>
</div>
<div id="ref-RAadmvJN">
<p>290. Bleicher KH, Böhm H-J, Müller K, Alanine AI. 2003 A guide to drug discovery: Hit and lead generation: beyond high-throughput screening. <em>Nature Reviews Drug Discovery</em> <strong>2</strong>, 369–378. (doi:<a href="https://doi.org/10.1038/nrd1086">10.1038/nrd1086</a>)</p>
</div>
<div id="ref-1D6emOV6q">
<p>291. Keserű GM, Makara GM. 2006 Hit discovery and hit-to-lead approaches. <em>Drug Discovery Today</em> <strong>11</strong>, 741–748. (doi:<a href="https://doi.org/10.1016/j.drudis.2006.06.016">10.1016/j.drudis.2006.06.016</a>)</p>
</div>
<div id="ref-cjj5vT3H">
<p>292. Swamidass SJ, Azencott C-A, Lin T-W, Gramajo H, Tsai S-C, Baldi P. 2009 Influence Relevance Voting: An Accurate And Interpretable Virtual High Throughput Screening Method. <em>Journal of Chemical Information and Modeling</em> <strong>49</strong>, 756–766. (doi:<a href="https://doi.org/10.1021/ci8004379">10.1021/ci8004379</a>)</p>
</div>
<div id="ref-uP7SgBVd">
<p>293. Kearnes S, Goldman B, Pande V. 2016 Modeling industrial admet data with multitask networks. </p>
</div>
<div id="ref-7QsMcDYy">
<p>294. Zaretzki J, Matlock M, Swamidass SJ. 2013 XenoSite: Accurately Predicting CYP-Mediated Sites of Metabolism with Neural Networks. <em>Journal of Chemical Information and Modeling</em> <strong>53</strong>, 3373–3383. (doi:<a href="https://doi.org/10.1021/ci400518g">10.1021/ci400518g</a>)</p>
</div>
<div id="ref-17eGl2pn9">
<p>295. Todeschini R, Consonni V, editors. 2009 <em>Molecular Descriptors for Chemoinformatics</em>. Wiley-VCH Verlag GmbH &amp; Co. KGaA. (doi:<a href="https://doi.org/10.1002/9783527628766">10.1002/9783527628766</a>)</p>
</div>
<div id="ref-1Dzz0P0qr">
<p>296. Dahl GE, Jaitly N, Salakhutdinov R. 2014 Multi-task neural networks for qsar predictions. </p>
</div>
<div id="ref-xOaTIeBY">
<p>297. Ma J, Sheridan RP, Liaw A, Dahl GE, Svetnik V. 2015 Deep Neural Nets as a Method for Quantitative Structure–Activity Relationships. <em>Journal of Chemical Information and Modeling</em> <strong>55</strong>, 263–274. (doi:<a href="https://doi.org/10.1021/ci500747n">10.1021/ci500747n</a>)</p>
</div>
<div id="ref-F8fP2vAg">
<p>298. In press. See <a href="http://www.bioinf.at/publications/2014/NIPS2014a.pdf" class="uri">http://www.bioinf.at/publications/2014/NIPS2014a.pdf</a>.</p>
</div>
<div id="ref-yAoN5gTU">
<p>299. Ramsundar B, Kearnes S, Riley P, Webster D, Konerding D, Pande V. 2015 Massively multitask networks for drug discovery. </p>
</div>
<div id="ref-Y1D0SZrO">
<p>300. Mayr A, Klambauer G, Unterthiner T, Hochreiter S. 2016 DeepTox: Toxicity Prediction using Deep Learning. <em>Frontiers in Environmental Science</em> <strong>3</strong>. (doi:<a href="https://doi.org/10.3389/fenvs.2015.00080">10.3389/fenvs.2015.00080</a>)</p>
</div>
<div id="ref-B4cL1o2P">
<p>301. Subramanian G, Ramsundar B, Pande V, Denny RA. 2016 Computational Modeling of β-Secretase 1 (BACE-1) Inhibitors Using Ligand Based Approaches. <em>Journal of Chemical Information and Modeling</em> <strong>56</strong>, 1936–1949. (doi:<a href="https://doi.org/10.1021/acs.jcim.6b00290">10.1021/acs.jcim.6b00290</a>)</p>
</div>
<div id="ref-WeiyYhfy">
<p>302. Reymond J-L, Ruddigkeit L, Blum L, van Deursen R. 2012 The enumeration of chemical space. <em>Wiley Interdisciplinary Reviews: Computational Molecular Science</em> <strong>2</strong>, 717–733. (doi:<a href="https://doi.org/10.1002/wcms.1104">10.1002/wcms.1104</a>)</p>
</div>
<div id="ref-1E0x7QgLP">
<p>303. Lusci A, Fooshee D, Browning M, Swamidass J, Baldi P. 2015 Accurate and efficient target prediction using a potency-sensitive influence-relevance voter. <em>Journal of Cheminformatics</em> <strong>7</strong>. (doi:<a href="https://doi.org/10.1186/s13321-015-0110-6">10.1186/s13321-015-0110-6</a>)</p>
</div>
<div id="ref-QnZ7V9Rd">
<p>304. Rogers D, Hahn M. 2010 Extended-Connectivity Fingerprints. <em>Journal of Chemical Information and Modeling</em> <strong>50</strong>, 742–754. (doi:<a href="https://doi.org/10.1021/ci100050t">10.1021/ci100050t</a>)</p>
</div>
<div id="ref-Oe573FaL">
<p>305. In press. See <a href="http://papers.nips.cc/paper/5954-convolutional-networks-on-graphs-for-learning-molecular-fingerprints" class="uri">http://papers.nips.cc/paper/5954-convolutional-networks-on-graphs-for-learning-molecular-fingerprints</a>.</p>
</div>
<div id="ref-17Wih4Hd5">
<p>306. Lusci A, Pollastri G, Baldi P. 2013 Deep Architectures and Deep Learning in Chemoinformatics: The Prediction of Aqueous Solubility for Drug-Like Molecules. <em>Journal of Chemical Information and Modeling</em> <strong>53</strong>, 1563–1575. (doi:<a href="https://doi.org/10.1021/ci400187y">10.1021/ci400187y</a>)</p>
</div>
<div id="ref-145os4Y6t">
<p>307. Kearnes S, McCloskey K, Berndl M, Pande V, Riley P. 2016 Molecular graph convolutions: moving beyond fingerprints. <em>Journal of Computer-Aided Molecular Design</em> <strong>30</strong>, 595–608. (doi:<a href="https://doi.org/10.1007/s10822-016-9938-8">10.1007/s10822-016-9938-8</a>)</p>
</div>
<div id="ref-P4ixsM8i">
<p>308. Altae-Tran H, Ramsundar B, Pappu AS, Pande V. 2017 Low Data Drug Discovery with One-Shot Learning. <em>ACS Central Science</em> (doi:<a href="https://doi.org/10.1021/acscentsci.6b00367">10.1021/acscentsci.6b00367</a>)</p>
</div>
<div id="ref-16OPHvAij">
<p>309. Wu Z, Ramsundar B, Feinberg EN, Gomes J, Geniesse C, Pappu AS, Leswing K, Pande V. 2017 MoleculeNet: A benchmark for molecular machine learning. </p>
</div>
<div id="ref-Ytvk62dX">
<p>310. In press. See <a href="https://github.com/deepchem/deepchem" class="uri">https://github.com/deepchem/deepchem</a>.</p>
</div>
<div id="ref-2dU8f4XJ">
<p>311. Gómez-Bombarelli R, Duvenaud D, Hernández-Lobato JM, Aguilera-Iparraguirre J, Hirzel TD, Adams RP, Aspuru-Guzik A. 2016 Automatic chemical design using a data-driven continuous representation of molecules. </p>
</div>
<div id="ref-13iyYvEcB">
<p>312. Cheng T, Li Q, Zhou Z, Wang Y, Bryant SH. 2012 Structure-Based Virtual Screening for Drug Discovery: a Problem-Centric Review. <em>The AAPS Journal</em> <strong>14</strong>, 133–141. (doi:<a href="https://doi.org/10.1208/s12248-012-9322-0">10.1208/s12248-012-9322-0</a>)</p>
</div>
<div id="ref-17YaKNLKk">
<p>313. Gomes J, Ramsundar B, Feinberg EN, Pande VS. 2017 Atomic convolutional networks for predicting protein-ligand binding affinity. </p>
</div>
<div id="ref-YO41GAOP">
<p>314. Wang R, Fang X, Lu Y, Yang C-Y, Wang S. 2005 The PDBbind Database:  Methodologies and Updates. <em>Journal of Medicinal Chemistry</em> <strong>48</strong>, 4111–4119. (doi:<a href="https://doi.org/10.1021/jm048957q">10.1021/jm048957q</a>)</p>
</div>
<div id="ref-Gue0c5Gb">
<p>315. Pereira JC, Caffarena ER, dos Santos CN. 2016 Boosting Docking-Based Virtual Screening with Deep Learning. <em>Journal of Chemical Information and Modeling</em> <strong>56</strong>, 2495–2506. (doi:<a href="https://doi.org/10.1021/acs.jcim.6b00355">10.1021/acs.jcim.6b00355</a>)</p>
</div>
<div id="ref-bNBiIiTt">
<p>316. Ragoza M, Hochuli J, Idrobo E, Sunseri J, Koes DR. 2016 Protein-ligand scoring with convolutional neural networks. </p>
</div>
<div id="ref-kJ4hy7E">
<p>317. Hartenfeller M, Schneider G. 2011 Enabling future drug discovery by de novo design. <em>Wiley Interdisciplinary Reviews: Computational Molecular Science</em> <strong>1</strong>, 742–759. (doi:<a href="https://doi.org/10.1002/wcms.49">10.1002/wcms.49</a>)</p>
</div>
<div id="ref-omzv9ryI">
<p>318. Schneider P, Schneider G. 2016 De Novo Design at the Edge of Chaos. <em>Journal of Medicinal Chemistry</em> <strong>59</strong>, 4077–4086. (doi:<a href="https://doi.org/10.1021/acs.jmedchem.5b01849">10.1021/acs.jmedchem.5b01849</a>)</p>
</div>
<div id="ref-15y7iq6HF">
<p>319. Graves A. 2013 Generating sequences with recurrent neural networks. </p>
</div>
<div id="ref-8LWFFeYg">
<p>320. Segler MHS, Kogej T, Tyrchan C, Waller MP. 2017 Generating focussed molecule libraries for drug discovery with recurrent neural networks. </p>
</div>
<div id="ref-AQ3N6Ayw">
<p>321. Kusner MJ, Paige B, Hernández-Lobato JM. 2017 Grammar variational autoencoder. </p>
</div>
<div id="ref-x1nE5icc">
<p>322. Gaulton A <em>et al.</em> 2011 ChEMBL: a large-scale bioactivity database for drug discovery. <em>Nucleic Acids Research</em> <strong>40</strong>, D1100–D1107. (doi:<a href="https://doi.org/10.1093/nar/gkr777">10.1093/nar/gkr777</a>)</p>
</div>
<div id="ref-1EayJRsI">
<p>323. Olivecrona M, Blaschke T, Engkvist O, Chen H. 2017 Molecular de novo design through deep reinforcement learning. </p>
</div>
<div id="ref-lERqKdZJ">
<p>324. Jaques N, Gu S, Bahdanau D, Hernández-Lobato JM, Turner RE, Eck D. 2016 Sequence tutor: Conservative fine-tuning of sequence generation models with kl-control. </p>
</div>
<div id="ref-1AhGoHZP9">
<p>325. Ba LJ, Caruana R. 2013 Do deep nets really need to be deep? </p>
</div>
<div id="ref-1AkF8Wsv7">
<p>326. Nguyen A, Yosinski J, Clune J. 2014 Deep neural networks are easily fooled: High confidence predictions for unrecognizable images. </p>
</div>
<div id="ref-QwXSJhr0">
<p>327. Ribeiro MT, Singh S, Guestrin C. 2016 ‘Why should i trust you?’: Explaining the predictions of any classifier. </p>
</div>
<div id="ref-voh0OiT2">
<p>328. Zeiler MD, Fergus R. 2013 Visualizing and understanding convolutional networks. </p>
</div>
<div id="ref-Kk20paR7">
<p>329. Zintgraf LM, Cohen TS, Adel T, Welling M. 2017 Visualizing deep neural network decisions: Prediction difference analysis. </p>
</div>
<div id="ref-zhmq9ktJ">
<p>330. Shrikumar A, Greenside P, Kundaje A. 2017 Learning important features through propagating activation differences. </p>
</div>
<div id="ref-y4t9EzPn">
<p>331. Fong R, Vedaldi A. 2017 Interpretable explanations of black boxes by meaningful perturbation. </p>
</div>
<div id="ref-1YcKYTvO">
<p>332. Simonyan K, Vedaldi A, Zisserman A. 2013 Deep inside convolutional networks: Visualising image classification models and saliency maps. </p>
</div>
<div id="ref-au5CLIOH">
<p>333. Bach S, Binder A, Montavon G, Klauschen F, Müller K-R, Samek W. 2015 On Pixel-Wise Explanations for Non-Linear Classifier Decisions by Layer-Wise Relevance Propagation. <em>PLOS ONE</em> <strong>10</strong>, e0130140. (doi:<a href="https://doi.org/10.1371/journal.pone.0130140">10.1371/journal.pone.0130140</a>)</p>
</div>
<div id="ref-b1sc0cgP">
<p>334. Kindermans P-J, Schütt K, Müller K-R, Dähne S. 2016 Investigating the influence of noise and distractors on the interpretation of neural networks. </p>
</div>
<div id="ref-f2L6isRj">
<p>335. Springenberg JT, Dosovitskiy A, Brox T, Riedmiller M. 2014 Striving for simplicity: The all convolutional net. </p>
</div>
<div id="ref-3CM9XLyL">
<p>336. In press. See <a href="https://www.robots.ox.ac.uk/~vedaldi/assets/pubs/mahendran16salient.pdf" class="uri">https://www.robots.ox.ac.uk/~vedaldi/assets/pubs/mahendran16salient.pdf</a>.</p>
</div>
<div id="ref-RZsNSRDS">
<p>337. Selvaraju RR, Cogswell M, Das A, Vedantam R, Parikh D, Batra D. 2016 Grad-cam: Visual explanations from deep networks via gradient-based localization. </p>
</div>
<div id="ref-WzFOJBiA">
<p>338. Sundararajan M, Taly A, Yan Q. 2017 Axiomatic attribution for deep networks. </p>
</div>
<div id="ref-DeOI1oGf">
<p>339. Lundberg S, Lee S-I. 2016 An unexpected unity among methods for interpreting model predictions. </p>
</div>
<div id="ref-19mGl6pfy">
<p>340. Mahendran A, Vedaldi A. 2014 Understanding deep image representations by inverting them. </p>
</div>
<div id="ref-VjsZbMSz">
<p>341. Finnegan AI, Song JS. 2017 Maximum Entropy Methods for Extracting the Learned Features of Deep Neural Networks. (doi:<a href="https://doi.org/10.1101/105957">10.1101/105957</a>)</p>
</div>
<div id="ref-1FkT6C6oa">
<p>342. Mahendran A, Vedaldi A. 2016 Visualizing Deep Convolutional Neural Networks Using Natural Pre-images. <em>International Journal of Computer Vision</em> <strong>120</strong>, 233–255. (doi:<a href="https://doi.org/10.1007/s11263-016-0911-8">10.1007/s11263-016-0911-8</a>)</p>
</div>
<div id="ref-XLHInhc1">
<p>343. In press. See <a href="http://googleresearch.blogspot.co.uk/2015/06/inceptionism-going-deeper-into-neural.html" class="uri">http://googleresearch.blogspot.co.uk/2015/06/inceptionism-going-deeper-into-neural.html</a>.</p>
</div>
<div id="ref-UAAd9Uez">
<p>344. In press. See <a href="http://www.iro.umontreal.ca/~lisa/publications2/index.php/publications/show/247" class="uri">http://www.iro.umontreal.ca/~lisa/publications2/index.php/publications/show/247</a>.</p>
</div>
<div id="ref-17i18PMkR">
<p>345. Yosinski J, Clune J, Nguyen A, Fuchs T, Lipson H. 2015 Understanding neural networks through deep visualization. </p>
</div>
<div id="ref-haHzVaaz">
<p>346. Bahdanau D, Cho K, Bengio Y. 2014 Neural machine translation by jointly learning to align and translate. </p>
</div>
<div id="ref-yHn4SDRI">
<p>347. Xu K, Ba J, Kiros R, Cho K, Courville A, Salakhutdinov R, Zemel R, Bengio Y. 2015 Show, attend and tell: Neural image caption generation with visual attention. </p>
</div>
<div id="ref-SAvEOARL">
<p>348. Deming L, Targ S, Sauder N, Almeida D, Ye CJ. 2016 Genetic architect: Discovering genomic structure with learned neural architectures. </p>
</div>
<div id="ref-UcRbawKo">
<p>349. Choi E, Bahadori MT, Kulas JA, Schuetz A, Stewart WF, Sun J. 2016 RETAIN: An interpretable predictive model for healthcare using reverse time attention mechanism. </p>
</div>
<div id="ref-10nDTiETi">
<p>350. Choi E, Bahadori MT, Song L, Stewart WF, Sun J. 2016 GRAM: Graph-based attention model for healthcare representation learning. </p>
</div>
<div id="ref-oc44yBj0">
<p>351. Ghosh J, Karamcheti V. 1992 Sequence learning with recurrent networks: analysis of internal representations. In <em>Science of Artificial Neural Networks</em> (ed DW Ruck), SPIE. (doi:<a href="https://doi.org/10.1117/12.140112">10.1117/12.140112</a>)</p>
</div>
<div id="ref-2cpYveR4">
<p>352. Karpathy A, Johnson J, Fei-Fei L. 2015 Visualizing and understanding recurrent networks. </p>
</div>
<div id="ref-1Ad3UOefc">
<p>353. Strobelt H, Gehrmann S, Huber B, Pfister H, Rush AM. 2016 Visual analysis of hidden state dynamics in recurrent neural networks. </p>
</div>
<div id="ref-10ViHstXn">
<p>354. Murdoch WJ, Szlam A. 2017 Automatic rule extraction from long short term memory networks. </p>
</div>
<div id="ref-9SnNyc8Y">
<p>355. Chryssolouris G, Lee M, Ramsey A. 1996 Confidence interval prediction for neural network models. <em>IEEE Transactions on Neural Networks</em> <strong>7</strong>, 229–232. (doi:<a href="https://doi.org/10.1109/72.478409">10.1109/72.478409</a>)</p>
</div>
<div id="ref-1FDihfnM">
<p>356. Gal Y, Ghahramani Z. 2015 Dropout as a bayesian approximation: Representing model uncertainty in deep learning. </p>
</div>
<div id="ref-69wxD9y">
<p>357. Koh PW, Liang P. 2017 Understanding black-box predictions via influence functions. </p>
</div>
<div id="ref-QphVo2P2">
<p>358. Kahng M, Andrews P, Kalro A, Chau DH. 2017 ActiVis: Visual exploration of industry-scale deep neural network models. </p>
</div>
<div id="ref-AEc66xxR">
<p>359. Liu M, Shi J, Li Z, Li C, Zhu J, Liu S. 2016 Towards better analysis of deep convolutional neural networks. </p>
</div>
<div id="ref-14DAmZTDg">
<p>360. Che Z, Purushotham S, Khemani R, Liu Y. 2015 Distilling knowledge from deep networks with applications to healthcare domain. </p>
</div>
<div id="ref-ZUCVI5eU">
<p>361. Lei T, Barzilay R, Jaakkola T. 2016 Rationalizing neural predictions. </p>
</div>
<div id="ref-5tvnB4uW">
<p>362. Park CY, Wong AK, Greene CS, Rowland J, Guan Y, Bongo LA, Burdine RD, Troyanskaya OG. 2013 Functional Knowledge Transfer for High-accuracy Prediction of Under-studied Biological Processes. <em>PLoS Computational Biology</em> <strong>9</strong>, e1002957. (doi:<a href="https://doi.org/10.1371/journal.pcbi.1002957">10.1371/journal.pcbi.1002957</a>)</p>
</div>
<div id="ref-11NHbWB1V">
<p>363. Sarraf S, DeSouza DD, Anderson J, Tofighi G,. 2016 DeepAD: Alzheimer′s Disease Classification via Deep Convolutional Neural Networks using MRI and fMRI. (doi:<a href="https://doi.org/10.1101/070441">10.1101/070441</a>)</p>
</div>
<div id="ref-15JUKBg9y">
<p>364. In press. See <a href="https://openreview.net/pdf?id=Sk-oDY9ge" class="uri">https://openreview.net/pdf?id=Sk-oDY9ge</a>.</p>
</div>
<div id="ref-BQS8ClV0">
<p>365. Schmidhuber J. 2015 Deep learning in neural networks: An overview. <em>Neural Networks</em> <strong>61</strong>, 85–117. (doi:<a href="https://doi.org/10.1016/j.neunet.2014.09.003">10.1016/j.neunet.2014.09.003</a>)</p>
</div>
<div id="ref-CKcJuj03">
<p>366. Gupta S, Agrawal A, Gopalakrishnan K, Narayanan P. 2015 Deep learning with limited numerical precision. </p>
</div>
<div id="ref-1G3owNNps">
<p>367. Courbariaux M, Bengio Y, David J-P. 2014 Training deep neural networks with low precision multiplications. </p>
</div>
<div id="ref-w6CoVmFK">
<p>368. Sa CD, Zhang C, Olukotun K, Ré C. 2015 Taming the wild: A unified analysis of hogwild!-style algorithms. </p>
</div>
<div id="ref-1GUizyE8e">
<p>369. Hubara I, Courbariaux M, Soudry D, El-Yaniv R, Bengio Y. 2016 Quantized neural networks: Training neural networks with low precision weights and activations. </p>
</div>
<div id="ref-1CRF3gAV">
<p>370. Hinton G, Vinyals O, Dean J. 2015 Distilling the knowledge in a neural network. </p>
</div>
<div id="ref-F3e4wfzQ">
<p>371. Raina R, Madhavan A, Ng AY. 2009 Large-scale deep unsupervised learning using graphics processors. In <em>Proceedings of the 26th Annual International Conference on Machine Learning - ICML ’09</em>, ACM Press. (doi:<a href="https://doi.org/10.1145/1553374.1553486">10.1145/1553374.1553486</a>)</p>
</div>
<div id="ref-NSgduYNT">
<p>372. In press. See <a href="https://research.google.com/pubs/pub37631.html" class="uri">https://research.google.com/pubs/pub37631.html</a>.</p>
</div>
<div id="ref-IULiPa6L">
<p>373. Seide F, Fu H, Droppo J, Li G, Yu D. 2014 On parallelizability of stochastic gradient descent for speech DNNS. In <em>2014 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)</em>, IEEE. (doi:<a href="https://doi.org/10.1109/icassp.2014.6853593">10.1109/icassp.2014.6853593</a>)</p>
</div>
<div id="ref-13KjSCKB2">
<p>374. Hadjis S, Abuzaid F, Zhang C, Ré C. 2015 Caffe con troll: Shallow ideas to speed up deep learning. </p>
</div>
<div id="ref-1FocAi7N0">
<p>375. Edwards C. 2015 Growing pains for deep learning. <em>Communications of the ACM</em> <strong>58</strong>, 14–16. (doi:<a href="https://doi.org/10.1145/2771283">10.1145/2771283</a>)</p>
</div>
<div id="ref-aClNvbyM">
<p>376. Su H, Chen H. 2015 Experiments on parallel training of deep neural network using model averaging. </p>
</div>
<div id="ref-fNkl8HFz">
<p>377. Li M, Zhang T, Chen Y, Smola AJ. 2014 Efficient mini-batch training for stochastic optimization. In <em>Proceedings of the 20th ACM SIGKDD international conference on Knowledge discovery and data mining - KDD ’14</em>, ACM Press. (doi:<a href="https://doi.org/10.1145/2623330.2623612">10.1145/2623330.2623612</a>)</p>
</div>
<div id="ref-x0M6vals">
<p>378. Hamanaka M, Taneishi K, Iwata H, Ye J, Pei J, Hou J, Okuno Y. 2016 CGBVS-DNN: Prediction of Compound-protein Interactions Based on Deep Learning. <em>Molecular Informatics</em> <strong>36</strong>, 1600045. (doi:<a href="https://doi.org/10.1002/minf.201600045">10.1002/minf.201600045</a>)</p>
</div>
<div id="ref-YwdqeYZi">
<p>379. Chetlur S, Woolley C, Vandermersch P, Cohen J, Tran J, Catanzaro B, Shelhamer E. 2014 CuDNN: Efficient primitives for deep learning. </p>
</div>
<div id="ref-15lYGmZpY">
<p>380. Chen W, Wilson JT, Tyree S, Weinberger KQ, Chen Y. 2015 Compressing neural networks with the hashing trick. </p>
</div>
<div id="ref-9NKsJjSw">
<p>381. Lacey G, Taylor GW, Areibi S. 2016 Deep learning on fpgas: Past, present, and future. </p>
</div>
<div id="ref-xE3EYmck">
<p>382. Dean J, Ghemawat S. 2008 MapReduce. <em>Communications of the ACM</em> <strong>51</strong>, 107. (doi:<a href="https://doi.org/10.1145/1327452.1327492">10.1145/1327452.1327492</a>)</p>
</div>
<div id="ref-1XcexUAV">
<p>383. Low Y, Bickson D, Gonzalez J, Guestrin C, Kyrola A, Hellerstein JM. 2012 Distributed GraphLab. <em>Proceedings of the VLDB Endowment</em> <strong>5</strong>, 716–727. (doi:<a href="https://doi.org/10.14778/2212351.2212354">10.14778/2212351.2212354</a>)</p>
</div>
<div id="ref-17cBimWgp">
<p>384. In press. See <a href="http://research.google.com/archive/large_deep_networks_nips2012.html" class="uri">http://research.google.com/archive/large_deep_networks_nips2012.html</a>.</p>
</div>
<div id="ref-HIiQN4bd">
<p>385. In press. See <a href="https://papers.nips.cc/paper/5717-taming-the-wild-a-unified-analysis-of-hogwild-style-algorithms.pdf" class="uri">https://papers.nips.cc/paper/5717-taming-the-wild-a-unified-analysis-of-hogwild-style-algorithms.pdf</a>.</p>
</div>
<div id="ref-rmJZ2Aui">
<p>386. Moritz P, Nishihara R, Stoica I, Jordan MI. 2015 SparkNet: Training deep networks in spark. </p>
</div>
<div id="ref-rZnxDitd">
<p>387. Meng X <em>et al.</em> 2015 MLlib: Machine learning in apache spark. </p>
</div>
<div id="ref-Gp4OR9Lf">
<p>388. In press. See <a href="http://download.tensorflow.org/paper/whitepaper2015.pdf" class="uri">http://download.tensorflow.org/paper/whitepaper2015.pdf</a>.</p>
</div>
<div id="ref-FwEK0msb">
<p>389. In press. See <a href="https://github.com/fchollet/keras" class="uri">https://github.com/fchollet/keras</a>.</p>
</div>
<div id="ref-y9IoEy4r">
<p>390. In press. See <a href="https://github.com/maxpumperla/elephas" class="uri">https://github.com/maxpumperla/elephas</a>.</p>
</div>
<div id="ref-4MZ2tmZ8">
<p>391. In press. See <a href="http://www.jmlr.org/proceedings/papers/v28/coates13.html" class="uri">http://www.jmlr.org/proceedings/papers/v28/coates13.html</a>.</p>
</div>
<div id="ref-JUF9VoRD">
<p>392. Sun S, Chen W, Liu T-Y. 2016 Ensemble-compression: A new method for parallel training of deep neural networks. </p>
</div>
<div id="ref-wz83yfHF">
<p>393. In press. See <a href="https://papers.nips.cc/paper/4443-algorithms-for-hyper-parameter-optimization.pdf" class="uri">https://papers.nips.cc/paper/4443-algorithms-for-hyper-parameter-optimization.pdf</a>.</p>
</div>
<div id="ref-Wsa952Ax">
<p>394. In press. See <a href="http://dl.acm.org/citation.cfm?id=2188395" class="uri">http://dl.acm.org/citation.cfm?id=2188395</a>.</p>
</div>
<div id="ref-B6g0qKf4">
<p>395. Schatz MC, Langmead B, Salzberg SL. 2010 Cloud computing and the DNA data race. <em>Nature Biotechnology</em> <strong>28</strong>, 691–693. (doi:<a href="https://doi.org/10.1038/nbt0710-691">10.1038/nbt0710-691</a>)</p>
</div>
<div id="ref-1E7bFCRV4">
<p>396. Muir P <em>et al.</em> 2016 The real cost of sequencing: scaling computation to keep pace with data generation. <em>Genome Biology</em> <strong>17</strong>. (doi:<a href="https://doi.org/10.1186/s13059-016-0917-0">10.1186/s13059-016-0917-0</a>)</p>
</div>
<div id="ref-q0SsFrZd">
<p>397. Stein LD. 2010 The case for cloud computing in genome informatics. <em>Genome Biology</em> <strong>11</strong>, 207. (doi:<a href="https://doi.org/10.1186/gb-2010-11-5-207">10.1186/gb-2010-11-5-207</a>)</p>
</div>
<div id="ref-ZSVsnPVO">
<p>398. Krizhevsky A. 2014 One weird trick for parallelizing convolutional neural networks. </p>
</div>
<div id="ref-ObFN78yp">
<p>399. Armbrust M <em>et al.</em> 2010 A view of cloud computing. <em>Communications of the ACM</em> <strong>53</strong>, 50. (doi:<a href="https://doi.org/10.1145/1721654.1721672">10.1145/1721654.1721672</a>)</p>
</div>
<div id="ref-o0F1MXBC">
<p>400. Longo DL, Drazen JM. 2016 Data Sharing. <em>New England Journal of Medicine</em> <strong>374</strong>, 276–277. (doi:<a href="https://doi.org/10.1056/nejme1516564">10.1056/nejme1516564</a>)</p>
</div>
<div id="ref-194IoYUs3">
<p>401. Greene CS, Garmire LX, Gilbert JA, Ritchie MD, Hunter LE. 2017 Celebrating parasites. <em>Nature Genetics</em> <strong>49</strong>, 483–484. (doi:<a href="https://doi.org/10.1038/ng.3830">10.1038/ng.3830</a>)</p>
</div>
<div id="ref-gvyja7v1">
<p>402. Stodden V, McNutt M, Bailey DH, Deelman E, Gil Y, Hanson B, Heroux MA, Ioannidis JPA, Taufer M. 2016 Enhancing reproducibility for computational methods. <em>Science</em> <strong>354</strong>, 1240–1241. (doi:<a href="https://doi.org/10.1126/science.aah6168">10.1126/science.aah6168</a>)</p>
</div>
<div id="ref-117PEpTMe">
<p>403. In press. See <a href="http://kundajelab.github.io/dragonn/" class="uri">http://kundajelab.github.io/dragonn/</a>.</p>
</div>
<div id="ref-wW6QbBXz">
<p>404. In press. See <a href="https://www.synapse.org/#!Synapse:syn6131484/wiki/402026" class="uri">https://www.synapse.org/#!Synapse:syn6131484/wiki/402026</a>.</p>
</div>
<div id="ref-enhj7VT6">
<p>405. In press. See <a href="https://papers.nips.cc/paper/5347-how-transferable-are-features-in-deep-neural-networks" class="uri">https://papers.nips.cc/paper/5347-how-transferable-are-features-in-deep-neural-networks</a>.</p>
</div>
<div id="ref-HlDY7trA">
<p>406. Zhang W, Li R, Zeng T, Sun Q, Kumar S, Ye J, Ji S. 2015 Deep Model Based Transfer and Multi-Task Learning for Biological Image Analysis. In <em>Proceedings of the 21th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining - KDD ’15</em>, ACM Press. (doi:<a href="https://doi.org/10.1145/2783258.2783304">10.1145/2783258.2783304</a>)</p>
</div>
<div id="ref-z3I2IudI">
<p>407. Zeng T, Li R, Mukkamala R, Ye J, Ji S. 2015 Deep convolutional neural networks for annotating gene expression patterns in the mouse brain. <em>BMC Bioinformatics</em> <strong>16</strong>. (doi:<a href="https://doi.org/10.1186/s12859-015-0553-9">10.1186/s12859-015-0553-9</a>)</p>
</div>
<div id="ref-2a7MHtAx">
<p>408. Pärnamaa T, Parts L. 2017 Accurate Classification of Protein Subcellular Localization from High Throughput Microscopy Images Using Deep Learning. <em>G3&amp;#58; Genes|Genomes|Genetics</em>, g3.116.033654. (doi:<a href="https://doi.org/10.1534/g3.116.033654">10.1534/g3.116.033654</a>)</p>
</div>
<div id="ref-DcnNfASG">
<p>409. Kraus OZ, Grys BT, Ba J, Chong Y, Frey BJ, Boone C, Andrews BJ. 2017 Automated analysis of high‐content microscopy data with deep learning. <em>Molecular Systems Biology</em> <strong>13</strong>, 924. (doi:<a href="https://doi.org/10.15252/msb.20177551">10.15252/msb.20177551</a>)</p>
</div>
<div id="ref-1eN66lwn">
<p>410. In press. See <a href="https://ai.stanford.edu/~ang/papers/icml11-MultimodalDeepLearning.pdf" class="uri">https://ai.stanford.edu/~ang/papers/icml11-MultimodalDeepLearning.pdf</a>.</p>
</div>
<div id="ref-obeRVckH">
<p>411. Chaudhary K, Poirion OB, Lu L, Garmire L. 2017 Deep Learning based multi-omics integration robustly predicts survival in liver cancer. (doi:<a href="https://doi.org/10.1101/114892">10.1101/114892</a>)</p>
</div>
<div id="ref-yOz8Ybj2">
<p>412. Eser U, Churchman LS. 2016 FIDDLE: An integrative deep learning framework for functional genomic data inference. (doi:<a href="https://doi.org/10.1101/081380">10.1101/081380</a>)</p>
</div>
<div id="ref-1BARarxfz">
<p>413. Hughes TB, Dang NL, Miller GP, Swamidass SJ. 2016 Modeling Reactivity to Biological Macromolecules with a Deep Multitask Network. <em>ACS Central Science</em> <strong>2</strong>, 529–537. (doi:<a href="https://doi.org/10.1021/acscentsci.6b00162">10.1021/acscentsci.6b00162</a>)</p>
</div>
<div id="ref-nyjAIan4">
<p>414. In press. See <a href="http://www.businessinsider.com/ibm-edges-closer-to-human-speech-recognition-2017-3" class="uri">http://www.businessinsider.com/ibm-edges-closer-to-human-speech-recognition-2017-3</a>.</p>
</div>
<div id="ref-M2OLWojE">
<p>415. Xiong W, Droppo J, Huang X, Seide F, Seltzer M, Stolcke A, Yu D, Zweig G. 2016 Achieving human parity in conversational speech recognition. </p>
</div>
<div id="ref-wKioubsT">
<p>416. Saon G <em>et al.</em> 2017 English conversational telephone speech recognition by humans and machines. </p>
</div>
<div id="ref-1Fel6Bdb8">
<p>417. Szegedy C, Zaremba W, Sutskever I, Bruna J, Erhan D, Goodfellow I, Fergus R. 2013 Intriguing properties of neural networks. </p>
</div>
<div id="ref-UtcyntjF">
<p>418. Goodfellow IJ, Shlens J, Szegedy C. 2014 Explaining and harnessing adversarial examples. </p>
</div>
<div id="ref-AsLAb71x">
<p>419. Papernot N, McDaniel P, Sinha A, Wellman M. 2016 Towards the science of security and privacy in machine learning. </p>
</div>
<div id="ref-18lZK7fxH">
<p>420. Xu W, Evans D, Qi Y. 2017 Feature squeezing: Detecting adversarial examples in deep neural networks. </p>
</div>
</div>
</body>
</html>
