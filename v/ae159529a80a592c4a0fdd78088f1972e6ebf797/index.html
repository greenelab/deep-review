<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml">
<head>
  <meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
  <meta http-equiv="Content-Style-Type" content="text/css" />
  <meta name="generator" content="pandoc" />
  <title></title>
  <style type="text/css">code{white-space: pre;}</style>
  <link rel="stylesheet" href="github-pandoc.css" type="text/css" />
</head>
<body>
<h1 id="deep-learning-genomics-and-precision-medicine">Deep Learning, Genomics, and Precision Medicine</h1>
<p>For preliminary authorship information, see the <a href="https://github.com/greenelab/deep-review/graphs/contributors">contributors</a> on GitHub.</p>
<h2 id="abstract">Abstract</h2>
<p>Abstract goes here.</p>
<h2 id="introduction">Introduction</h2>
<p>Biology and medicine are rapidly becoming data-intensive with respect to both research and practice. A recent comparison of genomics with social media, online videos and other data-intensive scientific disciplines suggested that the field of genomics alone would equal or surpass other fields in data generation and analysis within the next decade <span class="citation">[<a href="#ref-13bxiY1vo">1</a>]</span>. These data present new opportunities, but also new challenges. The data volume and complexity both indicate that automated algorithms will be needed to extract meaningful patterns and provide actionable knowledge allowing us to better treat, categorize, or study disease, all within data constrained and privacy critical environments.</p>
<p>Concurrent with this explosive growth in biomedical data, a new enthusiasm for a class of machine learning algorithms, known as deep learning, is revolutionizing domains from image search to the game of Go <span class="citation">[<a href="#ref-2gn6PKkv">2</a>]</span>. As recently applied to image analysis problems, these architectures readily surpass previous best-in-class results, and computer scientists are now building many-layered neural networks from collections of millions of images. In a famous and early example, scientists from Google demonstrated that a neural network could learn to identify cats simply by watching online videos <span class="citation">[<a href="#ref-IiNJE32f">3</a>]</span>.</p>
<p>What if, more generally, deep learning could solve the challenges presented by the growth of data in biomedicine? Could these algorithms identify the &quot;cats&quot; hidden in our data - the patterns unknown to the researcher - and act on them? Deep learning has transformed image analysis, but what about biomedicine more broadly? In this review, we examine whether this transformation is simply a matter of time or if there are unique challenges posed by biomedical data that render deep learning methods more challenging or less fruitful to apply.</p>
<h3 id="what-is-deep-learning">What is deep learning?</h3>
<p>Deep learning is built on a biologically-inspired approach from machine learning termed neural networks. Each neuron in a computational neural network, termed a node, has inputs, an activation function, and outputs. Each value from the inputs is usually multiplied by some weight and combined and summarized by the activation function. The value of the activation function is then multiplied by another set of weights to produce the output <strong>TODO: we probably need a figure here - I see no way that we don't include this type of description in our paper, despite the fact that it's been done tons of times before. - I'm really partial to this nature review's explanation about making non-linear problems linear - figure 1 <span class="citation">[<a href="#ref-BeijBSRE">4</a>]</span></strong> These neural networks are trained by identifying weights that produce a desired output from some specific input.</p>
<p>Neural networks can also be stacked. The outputs from one network can be used as inputs to another. This process produces a stacked, also known as a multi-layer, neural network. The multi-layer neural network techniques that underlie deep learning have a long history. Multi-layer methods have been discussed in the literature for more than five decades <span class="citation">[<a href="#ref-1G5eCiq4d">5</a>]</span>. Given this context, it's challenging to consider &quot;deep learning&quot; as a new advance, though the term has only become widespread to describe analysis methods in the last decade. Much of the early history of neural networks has been extensively covered in a recent review <span class="citation">[<a href="#ref-BQS8ClV0">6</a>]</span>. For the purposes of this review, we identify deep learning approaches as those that use multi-layer neural networks to construct complex features.</p>
<p>We also discuss a class of algorithms that we term &quot;shallow learning&quot; approaches. We do not use this as a pejorative term, but instead to denote algorithms which have all of the hallmarks of deep approaches except that they employ networks of limited depth. We found it valuable to include these as we sought to identify the current contributions of deep learning and to predict its future impact. Researchers may employ these shallow learning methods for a number of reasons including: 1) shallow networks provide a degree of interpretability that better matches their use case; 2) the available data are insufficient to support deeper architectures, however new datasets that will support deep methods are expected; 3) or as building blocks to be combined with other non-neural-network-based approaches at subsequent stages.</p>
<h3 id="will-deep-learning-transform-the-study-of-human-disease">Will deep learning transform the study of human disease?</h3>
<p>With this review, we set out to address the question: what would need to be true for deep learning to transform how we categorize, study, and treat individuals to maintain or restore health? We chose a high bar for &quot;transform.&quot; Andrew Grove, the former CEO of Intel, coined the term Strategic Inflection Point to refer to a change in technologies or environment that requires a business to be fundamentally reshaped <span class="citation">[<a href="#ref-mAXsmd43">7</a>]</span>. Here, we ought to identify whether deep learning was an innovation that would induce a strategic inflection point on the practice of biology or medicine. We considered this with an eye towards the concept of precision medicine.</p>
<p>There are numerous examples where deep learning has been applied to biological problems and produced somewhat improved results, and there are numerous reviews that have focused on general applications of deep learning in biology <span class="citation">[<a href="#ref-yXqhuueV">8</a>–<a href="#ref-G00xvi94">13</a>]</span>. We sought cases where deep learning was enabling researchers to solve challenges that were previously considered infeasible, or if it made difficult, tedious, and non-routine analyses routine.</p>
<p>Based on our guiding question, we focused on the application of deep learning to topics of biomedical importance. We divided the large range of topics into three broad classes: Disease and Patient Categorization, Fundamental Biological Study, and Patient Treatment. We briefly introduce the types of questions, approaches and data that are typical for each class in the application of deep learning.</p>
<h4 id="disease-and-patient-categorization">Disease and Patient Categorization</h4>
<p>A key challenge in biomedicine is the accurate classification of diseases and disease subtypes. In oncology, current &quot;gold standard&quot; approaches involve histology, requiring manual human expertise for quantification, or small panel of molecular markers, such as cell surface receptors or genes' expression. One example is the PAM50 approach to classifying breast cancer where the expression of 50 marker genes divides breast cancer patients into four subtypes. Significant heterogeneity still remains within these four subtypes <span class="citation">[<a href="#ref-lnK82Ey6">14</a>,<a href="#ref-pEIw87Mp">15</a>]</span>. Given the increasing wealth of molecular data available, a more comprehensive subtyping seems possible.</p>
<p>Several studies have used deep learning methods in order to better categorize breast cancer patients. For example, Tan et al. applied denoising autoencoders (DA), an unsupervised approach, in order to cluster breast cancer patients <span class="citation">[<a href="#ref-PBiRSdXv">16</a>]</span>. Ciresan et al. utilized convolutional neural networks (CNN) to count mitotic divisions in histological images; a feature that is highly correlated with disease outcome <span class="citation">[<a href="#ref-koEdZRcY">17</a>]</span>. Despite these recent advances, a number of challenges exist in this area of research, such as the integration of disparate types of data, including electronic health records (EHR), imaging and histology data, and molecular omics data.</p>
<h4 id="fundamental-biological-study">Fundamental Biological Study</h4>
<p>Deep learning can be applied to answer more fundamental biological questions, and is especially suited to leveraging large amounts of data from high throughput omics studies. One classic biological problem where machine learning has been extensively applied is the prediction of molecular targets. Recent advances using deep learning have shown higher accuracy in determining molecular targets. For example, Lee et al. used deep recurrent neural networks (RNN) to predict gene targets of micro-RNAs <span class="citation">[<a href="#ref-YUms527e">18</a>]</span>. Wang et al. used a residual CNN to predict protein-protein contact on a genome-wide scale <span class="citation">[<a href="#ref-W3grN7jy">19</a>]</span>. Other biological questions that have been investigated include the prediction of protein secondary structure based on sequence data <span class="citation">[<a href="#ref-ZzaRyGuJ">20</a>,<a href="#ref-UO8L6nd">21</a>]</span>, recognition of functional genomic elements such as enhancers and promoters <span class="citation">[<a href="#ref-s5sy4AOi">22</a>–<a href="#ref-12aqvAgz6">24</a>]</span>, predicting the deleterious effects of nucleotide polymorphisms <span class="citation">[<a href="#ref-15E5yG1Ho">25</a>]</span>, etc.</p>
<h4 id="patient-treatment">Patient Treatment</h4>
<p>Although the application of deep learning to patient treatment is just beginning, we expect a dramatic increase in methods aiming to recommend patient treatment, predict treatment outcome, and guide future development of new therapies. Specifically, effort in this area aims to identify drug targets, identify drug interactions or predict drug response. One recent approach for predicting drug response is the use of protein structure to predict drug interactions and drug bioactivity through CNN <span class="citation">[<a href="#ref-Z7fd0BYf">26</a>]</span>. Since CNNs leverage spatial relationships within the data, this particular deep learning framework is well suited to the problem. Drug discovery and drug &quot;repurposing&quot; are two other hot topics. Aliper et al. used transcriptomic data to predict which drugs might be repurposed for other diseases through deep fully connected neural networks <span class="citation">[<a href="#ref-EMDwvRGb">27</a>]</span>. In a similar vein, Wang et al. used restricted boltzman machines (RBM) to predict drug molecular targets <span class="citation">[<a href="#ref-1AU7wzPqa">28</a>]</span>.</p>
<h2 id="does-deep-learning-create-a-strategic-inflection-point-in-how-we-categorize-individuals-with-respect-to-health-and-disease">Does deep learning create a strategic inflection point in how we categorize individuals with respect to health and disease?</h2>
<p><em>Focus for the purpose of this review - within a health care context.</em></p>
<p>We currently categorize individuals using relatively <em>ad hoc</em> categories. These are divided, to an extent, by organ (e.g. cancers by tumor site), perhaps to an extent symptom, and to an extent by immediate cause. This system undergoes continual refinement (e.g. new subtypes of disease) as our understanding improves.</p>
<p><em>Would deep learning enable us to do this automatically in some principled way? Are there reasons to believe that this would be advantageous? Would it be positive to have disease categories changed by data, or would the changing definition (i.e. as more data are accumulated) actually be harmful? What impacts would this have on the training of physicians?</em></p>
<p><em>What are the major challenges in this space, and does deep learning enable us to tackle any of them? Are there example approaches whereby deep learning is already having a transformational impact? I (Casey) have added some sections below where I think we could contribute to the field with our discussion.</em></p>
<h3 id="major-areas-of-existing-contributions">Major areas of existing contributions</h3>
<p><em>There are a number of major challenges in this space. How do we get data together from multiple distinct systems? How do we find biologically meaningful patterns in that data? How do we store and compute on this data at scale? How do we share these data while respecting privacy? I've made a section for each of these. Feel free to add more. I see each section as something on the order of 1-2 paragraphs in our context.</em></p>
<h4 id="clinical-care">Clinical care</h4>
<h4 id="imaging-applications-in-health-care">Imaging applications in health care</h4>
<p>One of the general areas where deep learning methods have had substantial success has been in image analysis. Applications in areas of medicine that use imaging extensively are also emerging. Mammography has been one area with numerous contributions <span class="citation">[<a href="#ref-JK8NuXy3">29</a>–<a href="#ref-Xxb4t3zO">32</a>]</span>. In all of this work, the researchers must work around a specific challenge - the limited number of well annotated training images. To expand the number and diversity of images, the researchers have employed approaches where they employ adversarial examples <span class="citation">[<a href="#ref-Xxb4t3zO">32</a>]</span> or first train towards human-created features before subsequent fine tuning <span class="citation">[<a href="#ref-JK8NuXy3">29</a>]</span>. The presence of a large bank of well-annotated mammography images would aid in the application of deep neural networks to this area. Though this strategy has not yet been employed in this domain, large collections of unlabeled images might first be used in an unsupervised context to construct high-quality feature detectors. Then the small number of labeled examples could be used for subsequent training. Similar strategies have been employed for EHR data where high-quality labeled examples are also difficult to obtain <span class="citation">[<a href="#ref-aM2Uy2ix">33</a>]</span>.</p>
<p>In addition to radiographic images, histology slides are also being analyzed with deep learning approaches. Ciresan et al. <span class="citation">[<a href="#ref-koEdZRcY">17</a>]</span> developed one of the earliest examples, winning the 2012 International Conference on Pattern Recognition's Contest on Mitosis Detection while achieving human competitive accuracy. Their approach uses what has become a standard convolutional neural network architecture trained on public data. In more recent work, Wang et al.<span class="citation">[<a href="#ref-mbEp6jNr">34</a>]</span> analyzed stained slides to identify cancers within slides of lymph node slices. The approach provided a probability map for each slide. On this task a pathologist has about a 3% error rate. The pathologist did not produce any false positives, but did have a number of false negatives. Their algorithm had about twice the error rate of a pathologist. However, their algorithms errors were not strongly correlated with the pathologist. Theoretically, combining both could reduce the error rate to under 1%. In this area, these algorithms may be ready to incorporate into existing tools to aid pathologists. The authors' work suggests that this could reduce the false negative rate of such evaluations. This theme of an ensemble between deep learning algorithm and human expert may help overcome some of the challenges presented by data limitations.</p>
<p>One source of training examples with rich clinical annotations is the electronic health record. Recently Lee et al.<span class="citation">[<a href="#ref-SxsZyrVM">35</a>]</span> developed an approach to distinguish individuals with Age-related Macular Degeneration from control individuals. They extracted approximately 100,000 images from structured electronic health records, which they used to train and evaluate a deep neural network. Combining this data resource with standard deep learning techniques, the authors reach greater than 93% accuracy. One item that is important to note with regards to this work is that the authors used their test set for evaluating when training had concluded. In other domains, this has resulted in a minimal change in the estimated accuracy <span class="citation">[<a href="#ref-lTBZomqa">36</a>]</span>. However, there is not yet a single accepted standard within the field of biomedical research for such evaluations. We recommend the use of an independent test set wherever it is feasible. Despite this minor limitation, the work clearly illustrates the potential that can be unlocked from images stored in electronic health records.</p>
<p><code>TODO: Potential remaining topics: #122 &amp; #151 looked interesting from an early glance. - Do we want to make the point that most of the imaging examples don't really do anything different/unique from standard image processing examples (Imagenet etc.)</code></p>
<h4 id="electronic-health-records">Electronic health records</h4>
<p>EHR data include substantial amounts of free text, which remains challenging to approach <span class="citation">[<a href="#ref-uDaRUyh9">37</a>]</span>. Often, researchers developing algorithms that perform well on specific tasks must design and implement domain- specific features <span class="citation">[<a href="#ref-sG3iVOTS">38</a>]</span>. These features capture unique aspects of the literature being processed. Deep learning methods are natural feature constructors. In recent work, the authors evaluated the extent to which deep learning methods could be applied on top of generic features for domain-specific concept extraction <span class="citation">[<a href="#ref-dO844vZn">39</a>]</span>. They found that performance was in line with, but did not exceed, existing state of the art methods. The deep learning method had performance lower than the best performing domain-specific method in their evaluation <span class="citation">[<a href="#ref-dO844vZn">39</a>]</span>. This highlights the challenge of predicting the eventual impact of deep learning on the field. This provides support that deep learning may impact the field by reducing the researcher time and cost required to develop specific solutions, but it may not lead to performance increases.</p>
<p>In recent work, Yoon et al.<span class="citation">[<a href="#ref-yUgE09ve">40</a>]</span> analyzed simple features using deep neural networks and found that the patterns recognized by the algorithms could be re-used across tasks. Their aim was to analyze the free text portions of pathology reports to identify the primary site and laterality of tumors. The only features the authors supplied to the algorithms that they evaluated were unigrams and bigrams. These are the counts for single words and two-word combinations in a free text document. They subset the full set of words and word combinations to the 400 most commonly used ones. The machine learning algorithms that they employed (naive Bayes, logistic regression, and deep neural networks) all performed relatively similarly on the task of identifying the primary site. However, when the authors evaluated the more challenging task, i.e. evaluating the laterality of each tumor, the deep neural network outperformed the other methods. Of particular interest, when the authors first trained a neural network to predict primary site and then repurposed those features as a component of a secondary neural network trained to predict laterality, the performance was higher than a laterality-trained neural network. This indicates a potential strength of deep methods. It may be possible to repurpose features from task to task, improving overall predictions as the field tackles new challenges.</p>
<p>Identifying consistent subgroups of individuals and individual health trajectories from clinical tests is also an active area of research. Approaches inspired by deep learning have been used for both unsupervised feature construction and supervised prediction. Early work by Lasko et al. <span class="citation">[<a href="#ref-FLX0o7bL">41</a>]</span>, combined sparse autoencoders and Gaussian processes to distinguish gout from leukemia from uric acid sequences. Later work showed that unsupervised feature construction of many features via denoising autoencoder neural networks could dramatically reduce the number of labeled examples required for subsequent supervised analyses <span class="citation">[<a href="#ref-5x3uMSKi">42</a>]</span>. In addition, it pointed towards learned features being useful for subtyping within a single disease. A concurrent large- scale analysis of an electronic health records system found that a deep denoising autoencoder architecture applied to the number and co-occurrence of clinical test events, though not the results of those tests, constructed features that were more useful for disease prediction than other existing feature construction methods <span class="citation">[<a href="#ref-WrNCJ9sO">43</a>]</span>. Taken together, these results support the potential of unsupervised feature construction in this domain. However, numerous challenges including data integration (patient demographics, family history, laboratory tests, text-based patient records, image analysis, genomic data) and better handling of streaming temporal data with many features, will need to be overcome before we can fully assess the potential of deep learning for this application area.</p>
<p>Still, recent work has also revealed domains in which deep networks have proven superior to traditional methods. Survival analysis models the time leading to an event of interest from a shared starting point, and in the context of EHR data, often associates these events to subject covariates. Exploring this relationship is difficult, however, given that EHR data types are often heterogeneous, covariates are often missing, and conventional approaches require the covariate-event relationship be linear and aligned to a specific starting point <span class="citation">[<a href="#ref-qXdO2aMm">44</a>]</span>. Early approaches, such as the Faraggi-Simon feed-forward network, aimed to relax the linearity assumption, but performance gains were lacking <span class="citation">[<a href="#ref-1921Mctzh">45</a>]</span>. Katzman et al. in turn developed a deep implementation of the Faraggi-Simon network that, in addition to outperforming Cox regression, was capable of comparing the risk between a given pair of treatments, thus potentially acting as recommender system <span class="citation">[<a href="#ref-1FE0F2pQ">46</a>]</span>. To overcome the remaining difficulties, researchers have turned to deep exponential families, a class of latent generative models that are constructed from any type of exponential family distributions <span class="citation">[<a href="#ref-pxdeuhMS">47</a>]</span>. The result was a deep survival analysis model capable of overcoming challenges posed by missing data and heterogeneous data types, while uncovering nonlinear relationships between covariates and failure time. They showed their model more accurately stratified patients as a function of disease risk score compared the current clinical implementation.</p>
<p>There is a computational cost for these methods, however, when compared to traditional, non-network approaches. For the exponential family models, despite their scalability <span class="citation">[<a href="#ref-8RAYEOPl">48</a>]</span>, an important question for the investigator is whether he or she is interested in estimates of posterior uncertainty. Given that these models are effectively Bayesian neural networks, much of their utility simplifies to whether a Bayesian approach is warranted for a given increase in computational cost. Moreover, as with all variational methods, future work must continue to explore just how well the posterior distributions are approximated, especially as model complexity increases <span class="citation">[<a href="#ref-15lbUf0as">49</a>]</span>.</p>
<h5 id="opportunities">Opportunities</h5>
<p>However, significant work needs to be done to move these from conceptual advances to practical game-changers.</p>
<ul>
<li>Large data resources (see sample # issues that mammography researchers are working around)</li>
<li>Semi-supervised methods to take advantage of large number of unlabeled examples</li>
<li>Transfer learning.</li>
</ul>
<h5 id="unique-challenges">Unique challenges</h5>
<p>Additionally, unique barriers exist in this space that may hinder progress in this field.</p>
<h6 id="lack-of-ground-truth-labels-in-data-and-high-cost-in-post-study-validation-by-clinician-experts.">Lack of ground-truth labels in data, and high cost in post-study validation by clinician experts.</h6>
<p>Lack of true labels is perhaps among the biggest obstacles for EHR-based analyses that employ machine learning (e.g., phenotyping). Popular deep learning (and machine learning) methods are often used to tackle classification tasks and thus require ground-truth labels for training. For EHRs, unfortunately, this means that researchers need to hire multiple clinicians to manually read and annotate individual patients' records through a process called chart review. This allows researchers to assign &quot;true&quot; labels, i.e. those that match our best available knowledge. Depending on the application, sometimes the features constructed by algorithms also need to be manually validated and interpreted by clinicians. This can be time consuming and expensive <span class="citation">[<a href="#ref-1Ar4f4vfR">50</a>]</span>. Because of these costs, much of this research, including the work cited in this review, skips the process of expert review. Clinicians' skepticism for research without expert review may greatly dampen their enthusiasm for the work and consequently reduce its impact. To date, even well-resourced large national consortia have been challenged by the task of acquiring enough expert-validated labeled data. For instance, in the eMERGE consortia and PheKB database <span class="citation">[<a href="#ref-ziudr6hx">51</a>]</span>, most samples with expert validation contain only 100 to 300 patients. These datasets are quite small, even for simple machine learning algorithms. The challenge is greater for deep learning models with many parameters. While unsupervised and semi-supervised approaches can help with small sample sizes, the field would benefit greatly from large collections of anonymized records in which a substantial number of records have undergone expert review.</p>
<p>This challenge is not unique to EHR-based studies. Work on medical images, -omics data in applications for which detailed metadata are required, and other applications for which labels are costly to obtain will be hampered as long as abundant curated data are unavailable. Unsupervised and semi-supervised methods provide one path forward <span class="citation">[<a href="#ref-5x3uMSKi">42</a>]</span>, as do adversarial training examples <span class="citation">[<a href="#ref-Xxb4t3zO">32</a>]</span>. We also expect the recently described data programming strategy <span class="citation">[<a href="#ref-5Il3kN32">52</a>]</span> to play a role in addressing this challenge. In data programming, noisy automated labeling functions are integrated. Numerous writers have described data as the new oil <span class="citation">[<a href="#ref-daemz8Fm">53</a>,<a href="#ref-o8mib4CN">54</a>]</span>. The idea behind this metaphor is that data are available in large quantities, valuable once refined, and the underlying resource that will enable a data-driven revolution in how work is done. Contrasting with this perspective, Ratner, Bach, and Ré described labeled training data as &quot;The <em>New</em> New Oil&quot; <span class="citation">[<a href="#ref-hfcf5Hmi">55</a>]</span>. In this framing, data are abundant and not a scarce resource. Instead, new approaches to solve problems arise when labeled training data become sufficient to enable them. Based on our review of research on deep learning methods to categorize disease, the latter framing rings true. We expect each of these approaches to play an important role if deep learning is going to transform how we analyze data to categorize states of human health. Finally, we don't expect that these methods will replace expert review. We expect them to complement expert review by allowing more efficient use of the costly practice of manual annotation.</p>
<h6 id="discrimination-and-right-to-an-explanation-laws">Discrimination and &quot;right to an explanation&quot; laws</h6>
<p>In April 2016, the European Union adopted new rules regarding the use of personal information, the General Data Protection Regulation (GDPR) <span class="citation">[<a href="#ref-7yE9K08a">56</a>]</span>. A component of these rules can be summed up by the phrase &quot;right to an explanation&quot;. Those who use machine learning algorithms must be able to explain how a decision was reached. For example, a clinician treating a patient who is aided by a machine learning algorithm may be expected to explain decisions that use the patient's data. The new rules were designed to target categorization or recommendation systems, which inherently profile individuals. Such systems can do so in ways that are discriminatory and unlawful <code>TODO: @traversc citation needed</code>.</p>
<p>As datasets become larger and more complex, we may begin to identify relationships in data that are important for human health but difficult to understand. The algorithms described in this review and others like them may become highly accurate and useful for various purposes, including within medical practice. However, to discover and avoid discriminatory applications it will be important to consider algorithm interpretability alongside accuracy. For example, if we train an algorithm to predict which drugs would be prescribed during a patient's visit to the doctor and there's an existing pattern of racial differences in prescription behavior (<code>TODO: @traversc - you can pick a different example but I think we need one - whichever one you think is most fully supported by the literature.</code>), this pattern could become baked into the predictions made by the algorithm. Machine learning practitioners, and particularly those who use deep neural networks, which are challenging to interpret, must remain cognizant of this possibility and make every effort to prevent harm from discriminatory predictions.</p>
<h6 id="data-sharing-and-privacy">Data sharing and privacy?</h6>
<p><em>This is clearly a big issue. We should at least mention it. Deep learning likes lots of data, and sharing restrictions don't allow that. Perhaps a paragraph on current best practices and how they relate to deep learning. A lack of data (due to privacy and sharing restrictions) may hamper deep learning's utility in this area in ways that it doesn't for image analysis, etc. Perhaps this will be the Achilles heal of deep learning in this area. A couple things to think about <span class="citation">[<a href="#ref-1CuDxTLXa">57</a>,<a href="#ref-6XtEfQMC">58</a>]</span></em></p>
<h6 id="standardizationintegration">Standardization/integration</h6>
<p>EHRs are designed and optimized primarily for patient care and billing purposes, meaning research is at most a tertiary priority. This presents significant challenges to EHR based research in general, and particularly to data intensive deep learning research. EHRs are used differently even within the same health care system <span class="citation">[<a href="#ref-11sli93ov">59</a>,<a href="#ref-y9ONtSZ9">60</a>]</span>. Individual users have unique usage patterns, and different departments have different priorities which introduce missing data in a non-random fashion. Just et al. demonstrated that even the most basic task of matching patients can be challenging due to data entry issues <span class="citation">[<a href="#ref-4rTluXLs">61</a>]</span>. This is before considering challenges caused by system migrations and health care system expansions through acquisitions. Replication between hospital systems requires controlling for both these systematic biases as well as for population and demographic effects. Historically, rules-based algorithms have been popular in EHR-based research but because these are developed at a single institution and trained with a specific patient population they do not transfer easily to other populations <span class="citation">[<a href="#ref-11OyzMl87">62</a>]</span>. Wiley et al. <span class="citation">[<a href="#ref-qe90c1CL">63</a>]</span> showed that warfarin dosing algorithms often under perform in African Americans, illustrating that some of these issues are unsolved even at a treatment best practices level. This may be a promising application of deep learning, as rules-based algorithms were also the standard in most natural language processing but have been superseded by machine learning and in particular deep learning methods <span class="citation">[<a href="#ref-Qnd0SYhm">64</a>]</span>.</p>
<h6 id="temporal-patient-trajectories">Temporal Patient Trajectories</h6>
<p>Traditionally, physician training programs justified long training hours by citing increased continuity of care and learning by following the progression of a disease over time, despite the known consequences of decreased mental and quality of life <span class="citation">[<a href="#ref-XJw23xy0">65</a>–<a href="#ref-17hjNSIIc">68</a>]</span>. Yet, a common practice in EHR-based research is to take a point in time snapshot and convert patient data to a traditional vector for machine learning and statistical analysis. This results in significant signal losses as timing and order of events provide insight into a patient's disease and treatment. Efforts to account for the order of events have shown promise <span class="citation">[<a href="#ref-ogs3PPp7">69</a>]</span> but require exceedingly large patient sizes due to discrete combinatorial bucketing.</p>
<p>Lasko et al. <span class="citation">[<a href="#ref-FLX0o7bL">41</a>]</span> used autoencoders on longitudinal sequences of serum urine acid measurements to identify population subtypes. More recently, deep learning has shown promise working with both sequences (Convolutional Neural Networks) <span class="citation">[<a href="#ref-Ohd1Q9Xw">70</a>]</span> and the incorporation of past and current state (Recurrent Neural Networks, Long Short Term Memory Networks)<span class="citation">[<a href="#ref-HRXii6Ni">71</a>]</span>.</p>
<h6 id="data-sharing-and-privacy-1">Data sharing and privacy</h6>
<p>Early successes using deep learning involved very large training datasets (ImageNet 1.4 million images) <span class="citation">[<a href="#ref-HKA6hi9E">72</a>]</span>, but a responsibility to protect patient privacy limits the ability openly share large patient datasets. Limited dataset sizes may restrict the number of parameters that can be trained in a model, but the lack of sharing may also hamper reproducibility and confidence in results. Even without sharing data, algorithms trained on confidential patient data may present security risks or accidentally allow for the exposure of individual level patient data. Tramer et al. <span class="citation">[<a href="#ref-ULSPV0rh">73</a>]</span> showed the ability to steal trained models via public APIs and Dwork and Roth <span class="citation">[<a href="#ref-v8Lp4ibI">74</a>]</span> demonstrate the ability to expose individual level information from accurate answers in a machine learning model.</p>
<p>Training algorithms in a differentially private manner provides a limited guarantee that the algorithms output will be equally likely to occur regardless of the participation of any one individual. The limit is determined by a single parameter which provides a quantification of privacy. Simmons et al. <span class="citation">[<a href="#ref-6XtEfQMC">58</a>]</span> present the ability to perform GWASs in a differentially private manner and Abadi et al. <span class="citation">[<a href="#ref-ucHUOABT">75</a>]</span> show the ability to train deep learning classifiers under the differential privacy framework. Finally, Continuous Analysis <span class="citation">[<a href="#ref-7MR5St9Q">76</a>]</span> allows for the ability to automatically track and share intermediate results for the purposes of reproducibility without sharing the original data.</p>
<h6 id="biomedical-data-is-often-wide">Biomedical data is often &quot;Wide&quot;</h6>
<p><em>Biomedical studies typically deal with relatively small sample sizes but each sample may have millions of measurements (genotypes and other omics data, lab tests etc).</em></p>
<p><em>Classical machine learning recommendations were to have 10x samples per number of parameters in the model.</em></p>
<p><em>Number of parameters in an MLP. Convolutions and similar strategies help but do not solve</em></p>
<p><em>Bengio diet networks paper</em></p>
<p><em>(Wei Xie; <strong>???</strong>): I personally do not think this subsection is necessary. It does not seem a big issue for health care data. For instance, EHR is mostly textual and very small in size and easy to compute even for large medical centers. Medical images and some medical tests may be larger, but they are still way behind MNIST or ImageNet in scale and compute requirement.</em></p>
<h4 id="has-deep-learning-already-induced-a-strategic-inflection-point-for-one-or-more-aspects">Has deep learning already induced a strategic inflection point for one or more aspects?</h4>
<p><em>I have looked through the papers that we have. I don't see a case in our collection where I felt that we'd be justified to say that deep learning has transformed how we categorize individuals with respect to health and disease. There are definitely interesting applications, but I don't see anything that we couldn't do similarly with some other method.</em></p>
<h3 id="will-deep-learning-induce-a-strategic-inflection-point-for-categorization">Will deep learning induce a strategic inflection point for categorization?</h3>
<p><em>This section attempts to get at whether or not we think that deep learning will be transformational. Since we have some room to provide our perspective, I'd suggest that we take a relatively tough look at this once we review where we are in the parts above.</em></p>
<h4 id="what-unique-potential-does-deep-learning-bring-to-this">What unique potential does deep learning bring to this?</h4>
<p><em>Are there areas that we expect deep learning to transform how we categorize disease that we haven't seen yet? Let's get fun with speculation/dreaming on this one.</em></p>
<h4 id="where-would-you-point-your-deep-learning-efforts-if-you-had-the-time">Where would you point your deep learning efforts if you had the time?</h4>
<p><em>This can be fun. We might eventually merge this with the section immediately above on deep learning's unique potential here.</em></p>
<h2 id="how-is-deep-learning-used-to-study-basic-biological-processes-in-a-manner-that-may-provide-future-insights-into-human-disease">How is deep learning used to study basic biological processes in a manner that may provide future insights into human disease?</h2>
<p><em>The (awkward) placeholder section title is intended to help define the scope. We do not want this section to become a miscellaneous collection of everything that does not fit in Categorize and Treat.</em></p>
<p><em>One proposal is that we organize this roughly by what is being predicted, which will generally correspond to the types of data being used. For each sub-section we can quickly introduce the prediction problem and cite some examples of the relevance to disease. Hypothetically, if we had an algorithm that produced perfect predictions on the task, what would we learn and how could those predictions be used?</em></p>
<p><em>Existing reviews could be mentioned briefly.</em></p>
<p><em>It may not fit here, but there could be a general discussion of why different neural network architectures are particularly well-suited for different types of input data. For example, CNNs and RNNs for 1-dimensional data are used in several categories below.</em></p>
<p><em>A few suggestions for sub-sections follow. Some of these could be left out because our goal is not an exhaustive enumeration of methods. Some are important areas of biology, but there may not be much deep learning- specific content to present. Others may be important areas where we lack expertise, in which case we may acknowledge the application area but not dive into merits or weaknesses of individual methods.</em></p>
<h3 id="gene-expression">Gene expression</h3>
<p>Gene expression measurements characterize the abundance of many thousands of RNA transcripts within a given organism, tissue, or cell. This characterization can represent the underlying state of the given system and can be used to study heterogeneity across samples as well as how the system reacts to perturbation. While gene expression measurements have been traditionally made by quantitative polymerase chain reaction (qPCR), low throughput fluorescence based methods, and microarray technologies, the field has shifted in recent years to primarily performing RNA sequencing (RNA-seq) to catalog whole transcriptomes. As such next generation sequencing technologies continue to fall in price and rise in throughput, applying deep learning to study gene expression data is likely to make training deep models more feasible. With increased modeling ability, deep learning approaches are likely to grow in popularity and lead to novel biological insights.</p>
<p>Already several deep learning approaches have been applied to gene expression data with varying aims. For instance, many researchers have applied unsupervised deep learning models to extract meaningful representations of gene modules or sample clusters. Denoising autoencoders have been used to cluster yeast expression microarrays into known modules representing cell cycle processes <span class="citation">[<a href="#ref-AnenJOuU">77</a>]</span> and also to stratify yeast strains based on chemical and mutational perturbations <span class="citation">[<a href="#ref-yVBx9Qx4">78</a>]</span>. Shallow (one hidden layer) denoising autoencoders have also been fruitful in extracting biological insight from thousands of <em>Pseudomonas aeruginosa</em> experiments <span class="citation">[<a href="#ref-1CFhfCyWN">79</a>,<a href="#ref-zuLdSQx3">80</a>]</span> and in aggregating features relevant to specific breast cancer subtypes <span class="citation">[<a href="#ref-PBiRSdXv">16</a>]</span>. These unsupervised approaches applied to gene expression data are powerful methods for aggregating features and identifying gene signatures that may otherwise be overlooked by alternative methods. An additional benefit of unsupervised approaches is that ground truth labels, which are often difficult to acquire or are incorrect, are nonessential. However, careful interpretation must be performed regarding how the genes are agregated into features. Precisely attributing node activations to specific biological functions risks overinterpreting models and can lead to incorrect conclusions.</p>
<p>Alternatively, deep learning approaches are also being applied for gene expression prediction tasks. For example, a deep neural network with three hidden layers outperformed linear regression in inferring the expression of over 20,000 target genes based on a representative, well-connected set of about 1,000 landmark genes <span class="citation">[<a href="#ref-12QQw9p7v">81</a>]</span>. However, while the deep learning model outperformed already existing algorithms in nearly every scenario, the model still displayed poor performance. The paper was also limited by computational bottlenecks that required data to be split randomly into two distinct models and trained separately. It is unclear how much performance would have increased if not for computational restrictions. Furthermore, a convolutional neural network applied to histone modifications, termed DeepChrome, <span class="citation">[<a href="#ref-G10wkFHt">82</a>]</span> was shown to predict gene expression output. DeepChrome greatly improved high or low expression prediction accuracy over existing methods. Deep learning applied to epigenetic data for gene expression inference is a promising approach to study gene regulation. Deep learning approaches have also been applied to study cancer gene expression data with goals of identifying subtypes of patients with different molecular features and clinical manifestations <span class="citation">[<a href="#ref-1EtavGKI4">83</a>]</span>. In the study, the authors combine RBMs to integrate gene expression, DNA methylation, and miRNA data and use the constructed features in search of ovarian cancer subtypes. While the aforementioned approaches are promising, many convert gene expression measurements to categorical or binary variables thus ablating many complex gene expression signatures present in intermediate and relative numbers.</p>
<p>Deep learning applied to gene expression data is in its infancy but the future is bright. Many hypotheses can now be interrogated because of increasing amounts of data and new developing technologies. For example, there is a growing appreciation for the large impact of disease heterogeneity on research and treatment strategies for disease. New technologies are being developed, such as single cell RNA-seq and high throughput fluorescence based imaging that are good matches for deep learning. Concurrently, deep learning methods are being developed to address novel problems such as adjusting for batch effects in single-cell RNA-seq data <span class="citation">[<a href="#ref-T2Md9xLY">84</a>]</span>. Moreover, deep learning is already well established in the image processing community, so the marriage of fluorescence based imaging techniques and deep learning is natural. These technologies are growing in popularity and will provide increasingly novel perspectives with respect to how cellular heterogeneity impacts gene expression coordination within a sample. In general, as the flow of gene expression data increases, and techniques to integrate heterogeneous genomic measurements made on the same samples are enhanced, the quality and types of questions deep learning can address is poised to improve.</p>
<h3 id="splicing">Splicing</h3>
<p>Pre-mRNA transcripts can be spliced into different isoforms by retaining or skipping subsets of exons, or including parts of introns. This alternative splicing provides cells with enormous spatiotemporal flexibility to generate multiple distinct proteins from a single gene. Splicing is catalyzed by small nuclear RNAs (snRNAs) and spliceosomal proteins, which detect sequence motifs such as splice sites and exon sequence enhancers and silencers (ESE and ESS). Various RNA-binding proteins and noncoding RNAs can bias these reactions by altering binding affinities, blocking splice sites, or sequestering splicing factors. This remarkable complexity unfortunately lends itself to defects that underlie many diseases <span class="citation">[<a href="#ref-QFK6GapR">85</a>]</span>. For instance, in Becker muscular dystrophy, a point mutation in dystrophin creates an ESS that induces skipping of exon 31. A recent study found that quantitative trait loci (QTLs) that affect splicing in lymphoblastoid cell lines are enriched within risk loci for schizophrenia, multiple sclerosis and other immune diseases, implicating mis-splicing as a much more widespread feature of human pathologies than previously thought <span class="citation">[<a href="#ref-b6p6wxpC">86</a>]</span>.</p>
<p>Sequencing studies routinely return thousands of unannotated variants. Which cause functional changes in splicing, and if so, how? Prediction of a “splicing code” has been a holy grail over the past decade. Initial machine learning approaches used a naive Bayes model and a 2-layer Bayesian neural network with thousands of hand-derived sequence-based features to predict the probability of exon skipping <span class="citation">[<a href="#ref-11ETDdRKr">87</a>,<a href="#ref-8VPGUHcf">88</a>]</span>. With the advent of deep learning, more complex models were built that provided better predictive accuracy <span class="citation">[<a href="#ref-17sgPdcMT">89</a>,<a href="#ref-N0HBi8MH">90</a>]</span>. Importantly, these new approaches can take in not only genomic features, but also tissue identity and CLIP-seq measurements of interactions between splicing factors and RNA, which all improve predictive accuracy.</p>
<p>The massive improvement seen with deep learning seems to stem from hidden layers being able to create new higher-order “features”, whereas earlier approaches often assumed independence of features and were unable to generalize. Higher-order understanding is especially important in splicing, which depends not only on the primary sequence, but also local RNA structure, tissue identity, splicing factor binding, and other currently unknown factors — all of which interact in complex, incompletely characterized ways. With new tools to interpret these meta-features, a major focus of current deep learning research, we will soon have the ability to extract a more nuanced biological understanding of splicing — perhaps by interrogating informative hidden nodes within neural networks that take in tissue type as part of the input, or by building separate networks for each tissue type and looking for common versus distinctive nodes <span class="citation">[<a href="#ref-Qbtqlmhf">91</a>]</span>.</p>
<p>A parallel effort has been to use more data with simpler models. An exhaustive study using readouts of splicing for millions of synthetic intronic sequences was able to describe motifs that influence the strength of alternative splice sites <span class="citation">[<a href="#ref-mlqKTlZY">92</a>]</span>. Interestingly, they built a simple linear model using hexamer motif frequencies that successfully generalized to exon skipping: in a limited analysis using SNPs from three genes, it predicted exon skipping with three times the accuracy of Xiong et al.’s framework. This case is instructive in that clever sources of data, not just more powerful models, can lead to novel insights.</p>
<p>We already understand how mis-splicing of a single gene can cause diseases such as Duchenne muscular dystrophy. The challenge now is to uncover how alternative splicing genome-wide gives rise to or is involved in complex, non-Mendelian diseases such as autism, schizophrenia, Type 1 diabetes, and multiple sclerosis <span class="citation">[<a href="#ref-CNz9HwZ3">93</a>]</span>. As a proof of concept, Xiong et al. <span class="citation">[<a href="#ref-17sgPdcMT">89</a>]</span> sequenced five ASD and 12 control samples, each with an average of 42,000 rare variants, and identified 19 genes with neural functions that are mis-spliced. Deep learning will allow scientists and clinicians to rapidly profile thousands of unannotated variants for functional effects on splicing and nominate candidates for further investigation. Moreover, these nonlinear algorithms can deconvolve the effects of multiple variants on a single splice event without the need to perform combinatorial in vitro experiments.</p>
<p>Our end goal is to predict an individual’s tissue-specific, exon-specific splicing patterns from their genome sequence and other measurements. Knowing exactly which genes are mis-spliced in each tissue could enable a new branch of precision diagnostics that also stratifies patients and suggests targeted therapies to correct splicing defects. A continued focus on interpreting the “black box” of deep neural networks, along with integrating more comprehensive and diverse data sources, will likely provide the path forward to a better understanding of the basic determinants of splicing and its links to complex disease, which will lead to novel diagnostics and therapeutics.</p>
<h3 id="transcription-factors-and-rna-binding-proteins">Transcription factors and RNA-binding proteins</h3>
<p>Transcription Factor and RNA-binding proteins are key components for gene regulation, making them very important to understand for higher level biological processes. While high-throughput sequencing techniques such as chromatin immunoprecipitation and massively parallel DNA sequencing (ChIP-seq) have been able to accurately identify binding regions for DNA and RNA proteins, these experiments are both time consuming and expensive. In addition, the sequencing methods do not provide any sort of analysis on the proteins which would lead to a better understanding of the underlying process. Thus, there is a need to computationally predict and understand these binding regions de novo from sequences.</p>
<h4 id="transcription-factors">Transcription Factors</h4>
<p>Transcription Factors (TFs) are regulatory proteins that bind to certain locations on a DNA sequence and control the rate of mRNA production. ChIP-seq and related technologies are able to identify highly likely binding sites for a certain TF, and databases such as ENCODE <span class="citation">[<a href="#ref-1Bs5k1MVg">94</a>]</span> have provided ChIP-seq data for hundreds of different TFs across many laboratories. However, ChIP-seq experiments are expensive and time consuming. Since the data that scientists have discovered is available, in silico methods to predict binding sites are of great interest, thus eliminating the need to do new ChIP-seq experiments every time analysis is done on a new sequence.</p>
<p>In order to computationally predict TFBSs on a DNA sequence, researchers initially used consensus sequences and position weight matrices to match against a test sequence <span class="citation">[<a href="#ref-ywDQIvZJ">95</a>]</span>. Simple neural network classifiers were then proposed to differentiate positive and negative binding sites, but did not show significant improvements over the weight matrix matching methods <span class="citation">[<a href="#ref-uZvDdFZo">96</a>]</span>. Later, SVM techniques outperformed the generative methods by using k-mer features <span class="citation">[<a href="#ref-JxuQvvyk">97</a>,<a href="#ref-138dgb9Ca">98</a>]</span>, but string kernel based SVM systems are limited by expensive computational cost proportional to the number of training and testing sequences. More recently, <span class="citation">[<a href="#ref-2UI1BZuD">99</a>]</span> showed that convolutional neural network models could achieve state of the art results on the TFBS task and are scalable to a large number of genomic sequences. <span class="citation">[<a href="#ref-Dwi2eAvT">100</a>]</span> introduced several new convolutional and recurrent neural network models for predicting TFBSs, but it remains unclear which neural architectures work best for all samples and TFs. While neural architectures are rapidly changing and producing better results, it is clear that deep learning can be efficiently and effectively used to do functional prediction on the genome given raw data.</p>
<p>While accurately predicting transcription factors computationally is useful, it is important to understand how these computational models make their predictions. To handle this, several papers have focused on understanding machine learning models <span class="citation">[<a href="#ref-2UI1BZuD">99</a>–<a href="#ref-xAbGxia4">101</a>]</span>. <span class="citation">[<a href="#ref-2UI1BZuD">99</a>]</span> was the first to introduce a visualization method for a deep learning model on the TFBS task, and they did so by visualizing the learned convolution filters which were informative for the model’s prediction of a specific sample. However, this approach was specific to visualizing certain samples fed through their particular model. <span class="citation">[<a href="#ref-Dwi2eAvT">100</a>]</span> introduced a suite of state-of-the-art deep learning models and new visualizations techniques for a more in-depth analysis of TFBSs. Furthermore, <span class="citation">[<a href="#ref-xAbGxia4">101</a>]</span> introduced an advanced visualization method and toolbox for analyzing possible TFBS sequences. <span class="citation">[<a href="#ref-2UI1BZuD">99</a>]</span> also introduced mutation maps, where they could easily mutate, add, or delete basepairs in a sequence and see how the model changed its prediction. This is something that would be very time consuming in a lab setting, but easy to simulate using their model. Visualization techniques on deep learning models are important because they can provide new insights on regulatory mechanisms and can lead biologists to test and verify in a lab setting, leading to new biomedical knowledge. Since the “linguistics” of DNA are unclear, interpretability of models is crucial to pushing our understanding forward.</p>
<p><code>TODO: Add discussion about the large number of deep learning works in this area since the DeepBind paper. In particular, add [#43](https://github.com/greenelab/deep-review/issues/43), [#215](https://github.com/greenelab/deep-review/issues/215), and [#258](https://github.com/greenelab/deep-review/issues/258).</code></p>
<h3 id="promoters-enhancers-and-related-epigenomic-tasks">Promoters, enhancers, and related epigenomic tasks</h3>
<p><em>We may want to be selective about what we discuss and not list every application in this area.</em></p>
<h3 id="micro-rna-binding">Micro-RNA binding</h3>
<p><em>miRNAs are important biologically, but have neural networks produced anything particularly notable in this area?</em></p>
<h3 id="protein-secondary-and-tertiary-structure">Protein secondary and tertiary structure</h3>
<p>Proteins play fundamental roles in all biological processes including the maintenance of cellular integrity, metabolism, transcription/translation, and cell-cell communication. Complete description of protein structures and functions is a fundamental step towards understanding biological life and also highly relevant in the development of therapeutics and drugs. UnitProt currently has about 94 millions of protein sequences. Even if we remove redundancy at 50% sequence identity level, UnitProt still has about 20 millions of protein sequences. However, fewer than 100,000 proteins have experimentally-solved structures in Protein Data Bank (PDB). As a result, computational structure prediction is essential for a majority number of protein sequences. However, predicting protein 3D structures from sequence alone is very challenging, especially when similar solved structures (called templates) are not available in PDB. In the past decades, various computational methods have been developed to predict protein structure from different aspects, including prediction of secondary structure, torsion angles, solvent accessibility, inter-residue contact map, disorder regions and side-chain packing.</p>
<p>Machine learning is extensively applied to predict protein structures and some success has been achieved. For example, secondary structure can be predicted with about 80% of 3-state (i.e., Q3) accuracy by a neural network method PSIPRED <span class="citation">[<a href="#ref-cRuWK1eG">102</a>]</span>. Starting from 2012, deep learning has been gradually introduced to protein structure prediction. The adopted deep learning models include deep belief network, LSTM(long short-term memory), deep convolutional neural networks (DCNN) and deep convolutional neural fields<span class="citation">[<a href="#ref-UO8L6nd">21</a>,<a href="#ref-pNoAbBEu">103</a>]</span>. Here we focus on deep learning methods for two representative subproblems: secondary structure prediction and contact map prediction. Secondary structure refers to local conformation of a sequence segment while a contact map contains information of global conformation. Secondary structure prediction is a basic problem and almost an essential module of any protein structure prediction package. It has also been used as sequence labeling benchmark in the machine learning community. Contact prediction is much more challenging than secondary structure prediction, but it has a much larger impact on tertiary structure prediction. In recent years, contact prediction has made good progress and its accuracy has been significantly improved <span class="citation">[<a href="#ref-BhfjKSY3">104</a>–<a href="#ref-10dNuD89l">107</a>]</span>.</p>
<p>Protein secondary structure can exhibit three different states (alpha helix, beta strand and loop regions) or eight finer-grained states. More methods are developed to predict 3-state secondary structure than 8-state. A predictor is typically evaluated by 3-state (i.e., Q3) and 8-state (i.e., Q8) accuracy, respectively. Qi et al. developed a multi-task deep learning method to simultaneously predict several local structure properties including secondary structures <span class="citation">[<a href="#ref-1AlhRKQbe">108</a>]</span>. Spencer, Eickholt and Cheng predicted secondary structure using deep belief networks <span class="citation">[<a href="#ref-ZzaRyGuJ">20</a>]</span>. Heffernan and Zhou et al. developed an iterative deep learning framework to simultaneously predict secondary structure, backbone torsion angles and solvent accessibility <span class="citation">[<a href="#ref-UpFrhdJf">109</a>]</span>. However, none of these deep learning methods achieved significant improvement over PSIPRED <span class="citation">[<a href="#ref-Aic7UyXM">110</a>]</span> in terms of Q3 accuracy. In 2014, Zhou and Troyanskaya demonstrated that they could improve Q8 accuracy over a shallow learning architecture conditional neural fields <span class="citation">[<a href="#ref-NnpYUsi">111</a>]</span> by using a deep supervised and convolutional generative stochastic network<span class="citation">[<a href="#ref-8t43CQ9m">112</a>]</span>, but did not report any results in terms of Q3 accuracy. In 2016 Wang and Xu et al. developed a deep convolutional neural fields (DeepCNF) model that can significantly improve secondary structure prediction in terms of both Q3 and Q8 accuracy<span class="citation">[<a href="#ref-UO8L6nd">21</a>]</span>. DeepCNF possibly is the first that reports Q3 accuracy of 84-85%, much higher than the 80% accuracy maintained by PSIPRED for more than 10 years. It is also reported that DeepCNF can improve prediction of solvent accessibility and disorder regions <span class="citation">[<a href="#ref-pNoAbBEu">103</a>]</span>. This improvement may be mainly due to the introduction of convolutional neural fields to capture long-range sequential information, which is important for beta strand prediction. Nevertheless, improving secondary structure prediction from 80% to 84-85% is unlikely to result in a similar amount of improvement in tertiary structure prediction since secondary structure mainly reflects coarse-grained local conformation of a protein structure.</p>
<p>Protein contact prediction and contact-assisted folding (i.e., folding proteins using predicted contacts as restraints) represents a promising new direction for ab initio folding of proteins without good templates in PDB. Evolutionary coupling analysis (ECA) is an effective contact prediction method for some proteins with a very large number (&gt;1000) of sequence homologs <span class="citation">[<a href="#ref-10dNuD89l">107</a>]</span>, but ECA fares poorly for proteins without many sequence homologs. Since (soluble) proteins with many sequence homologs are likely to have a good template in PDB, to make contact-assisted folding practically useful for ab initio folding, it is essential to predict accurate contacts for proteins without many sequence homologs. By combining ECA with a few other protein features, shallow neural network-based methods such as MetaPSICOV <span class="citation">[<a href="#ref-7atXz0r">105</a>]</span> and CoinDCA-NN <span class="citation">[<a href="#ref-kqjqFesT">113</a>]</span> have shown some advantage over ECA for proteins with a small number of sequence homologs, but their accuracy is still not very good. In recent years, deep learning methods have been explored for contact prediction. For example, Di Lena et al. introduced a deep spatio-temporal neural network (up to 100 layers) that utilizes both spatial and temporal features to predict protein contacts<span class="citation">[<a href="#ref-xdoT1yUx">114</a>]</span>. Eickholt and Cheng combined deep belief networks and boosting techniques to predict protein contacts <span class="citation">[<a href="#ref-18bNbDNlc">115</a>]</span> and trained deep networks by layer-wise unsupervised learning followed by fine-tuning of the entire network. Skwark and Elofsson et al. developed an iterative deep learning technique for contact prediction by stacking a series of Random Forests <span class="citation">[<a href="#ref-F13xtRbV">116</a>]</span>. However, blindly tested in the well-known CASP competitions, these methods did not show any advantage over MetaPSICOV <span class="citation">[<a href="#ref-7atXz0r">105</a>]</span>, a method using two cascaded neural networks. Very recently, Wang and Xu et al. proposed a novel deep learning method RaptorX-Contact <span class="citation">[<a href="#ref-BhfjKSY3">104</a>]</span> that can significantly improve contact prediction over MetaPSICOV especially for proteins without many sequence homologs. RaptorX-Contact employs a network architecture formed by one 1D residual neural network and one 2D residual neural network. Blindly tested in the latest CASP competition (i.e., CASP12 <span class="citation">[<a href="#ref-zScWGveU">117</a>]</span>), RaptorX-Contact is ranked first in terms of the total F1 score (a widely-used performance metric) on free-modeling targets as well as the whole set of targets. In the CASP12 test, the group ranked second also employed a deep learning method. Even MetaPSICOV, which ranked third in CASP12, employed more and wider hidden layers than its old version. Wang and Xu et al. have also demonstrated in another blind test CAMEO (which can be interpreted as a fully-automated CASP) <span class="citation">[<a href="#ref-u9uApoaB">118</a>]</span> that their predicted contacts can help fold quite a few proteins with a novel fold and only 65-330 sequence homologs and that their method also works well on membrane protein contact prediction even if trained mostly by non-membrane proteins. In fact, most of the top 10 contact prediction groups in CASP12 employed some kind of deep learning techniques. The RaptorX-Contact method performed better mainly due to introduction of residual neural networks and exploiting contact occurrence patterns by simultaneous prediction of all the contacts in a single protein. It is still possible to further improve contact prediction by studying new deep network architectures. However, current methods fail when proteins in question have almost no sequence homologs. It is unclear if there is an effective way to deal with this type of proteins or not except waiting for more sequence homologs. Finally, the deep learning methods summarized above also apply to interfacial contact prediction of a protein complex, but may be less effective since on average protein complexes have fewer sequence homologs.</p>
<h3 id="signaling">Signaling</h3>
<p><em>There is not much content here. Can <span class="citation">[<a href="#ref-rmjDc5rm">119</a>]</span> be covered elsewhere?</em></p>
<h3 id="morphological-phenotypes">Morphological phenotypes</h3>
<p>A field poised for dramatic revolution by deep learning is bioimage analysis. Thus far, the primary use of deep learning for biological images has been for segmentation - that is, for the identification of biologically relevant structures in images such as nuclei, infected cells, or vasculature, in fluorescence or even brightfield channels <span class="citation">[<a href="#ref-40EG4ZEU">120</a>]</span>. Once so-called regions of interest have been identified, it is often straightforward to measure biological properties of interest, such as fluorescence intensities, textures, and sizes. Given the dramatic successes of deep learning in biological imaging, we simply refer to articles that review recent advancements <span class="citation">[<a href="#ref-MmRGFVUu">10</a>,<a href="#ref-40EG4ZEU">120</a>,<a href="#ref-TutLhFSz">121</a>]</span>. We believe deep learning will become a commonplace tool for biological image segmentation once user-friendly tools exist.</p>
<p>We anticipate an additional kind of paradigm shift in bioimaging that will be brought about by deep learning: what if images of biological samples, from simple cell cultures to three-dimensional organoids and tissue samples, could be mined for much more extensive biologically meaningful information than is currently standard? For example, a recent study demonstrated the ability to predict lineage fate in hematopoietic cells up to three generations in advance of differentiation <span class="citation">[<a href="#ref-On4vW5aU">122</a>]</span>. In biomedical research, by far the most common paradigm is for biologists to decide in advance what feature to measure in images from their assay system. But images of cells contain a wide variety of quantitative information, and deep learning may just be the tool to extract it. Although classical methods of segmentation and feature extraction can produce hundreds of metrics per cell in an image, deep learning is unconstrained by human intuition and can in theory extract more subtle features. Already, there is evidence deep learning can surpass the efficacy of classical methods <span class="citation">[<a href="#ref-gllSeTW">123</a>]</span>, even using generic deep convolutional networks trained on natural images <span class="citation">[<a href="#ref-BMg062hc">124</a>]</span>, known as transfer learning.</p>
<p>The impact of further improvements on biomedicine could be enormous. Comparing cell population morphologies using conventional methods of segmentation and feature extraction has already proven useful for functionally annotating genes and alleles, identifying the cellular target of small molecules, and identifying disease-specific phenotypes suitable for drug screening <span class="citation">[<a href="#ref-hkKO4QYl">125</a>–<a href="#ref-McjXFLLq">127</a>]</span>. Deep learning would bring to these new kinds of experiments - known as image-based profiling or morphological profiling - a higher degree of accuracy, stemming from the freedom from human-tuned feature extraction strategies.</p>
<p><code>TODO: Make sure that at the end we clearly emphasize our excitement around unsupervised uses.</code></p>
<h3 id="single-cell">Single-cell</h3>
<p>Single-cell methods are generating extreme excitement as biologists recognize the vast heterogeneity within unicellular species and between cells of the same tissue type in the same organism <span class="citation">[<a href="#ref-1AWC7HsO0">128</a>]</span>. For instance, tumor cells and neurons can both harbor extensive somatic variation <span class="citation">[<a href="#ref-1GvfSy48x">129</a>]</span>. Understanding single-cell diversity in all its dimensions — genetic, epigenetic, transcriptomic, proteomic, morphologic, and metabolic — is key if precision medicine is to be targeted not only to a specific individual, but also to specific pathological subsets of cells. Single-cell methods also promise to uncover a wealth of new biological knowledge. A sufficiently large population of single cells will have enough representative “snapshots” to recreate timelines of rapid biological processes. If tracking processes over time is not the limiting factor, single cell techniques can provide maximal resolution compared to averaging across all cells in bulk tissue, enabling the study of transcriptional bursting with single-cell FISH or the heterogeneity of epigenetic patterns with single-cell Hi-C or ATAC-seq <span class="citation">[<a href="#ref-QafUwNKn">130</a>,<a href="#ref-v97iPXDw">131</a>]</span>.</p>
<p>However, large challenges exist in studying single cells. Relatively few cells can be assayed at once using current droplet, imaging, or microwell technologies, and low-abundance molecules or modifications may not be detected by chance in a phenomenon known as dropout. To solve this problem, Angermueller et al. <span class="citation">[<a href="#ref-19EJTHByG">132</a>]</span> trained a neural network to predict the presence or absence of methylation of a specific CpG site in single cells based on surrounding methylation signal and underlying DNA sequence, achieving several percentage points of improvement compared to random forests or deep networks trained only on CpG or sequence information. Similar deep learning methods have been applied to impute low-resolution ChIP-seq signal from bulk tissue with great success, and they could easily be adapted to single cell data <span class="citation">[<a href="#ref-Qbtqlmhf">91</a>,<a href="#ref-XimuXZlz">133</a>]</span>.</p>
<p>Examining populations of single cells can reveal biologically meaningful subsets of cells as well as their underlying gene regulatory networks <span class="citation">[<a href="#ref-1HPu3R2B4">134</a>]</span>. Unfortunately, machine learning generally struggles with unbalanced data — when there are many more inputs of class 1 than class 2 — because prediction accuracy is usually evaluated over the entire dataset. To tackle this challenge, Arvaniti et al. <span class="citation">[<a href="#ref-r3Gbjksq">135</a>]</span> classified healthy and cancer cells expressing 25 markers by using the most discriminative filters from a CNN trained on the data as a linear classifier. They achieved an impressive precision of 50% to 90% with 80% recall on cells where the subset percentage ranged from 0.1 to 1%, which significantly outperformed logistic regression and distance-based outlier detection methods. However, they did not benchmark against random forests, which tend to be better with unbalanced data, or against the neural network itself, and their data was fairly low dimensional. Future work will be needed to establish the utility of deep learning in cell subset identification, but the stunning improvements in image classification over the past 5 years <span class="citation">[<a href="#ref-j7KrVyi8">136</a>]</span> suggest that this goal will be achievable.</p>
<p>The sheer quantity of “omic” information that can be obtained from each cell, as well as the number of cells in each dataset, uniquely position single-cell data to benefit from deep learning. In the future, lineage tracing could be revolutionized by using autoencoders to reduce the feature space of transcriptomic or variant data followed by algorithms to learn optimal cell differentiation trajectories <span class="citation">[<a href="#ref-Oljj2W96">137</a>]</span>, or by feeding cell morphology and movement into neural networks <span class="citation">[<a href="#ref-On4vW5aU">122</a>]</span>. Reinforcement learning algorithms <span class="citation">[<a href="#ref-2gn6PKkv">2</a>]</span> could be trained on the evolutionary dynamics of cancer cells or bacterial cells undergoing selection pressure and reveal whether patterns of adaptation are random or deterministic, allowing us to develop therapeutic strategies that forestall resistance. It will be exciting to see the creative applications of deep learning to single-cell biology that emerge over the next few years.</p>
<p><code>TODO: https://github.com/greenelab/deep-review/issues/153</code></p>
<h3 id="metagenomics">Metagenomics</h3>
<p><code>TODO: Add reference tags to this section</code> Metagenomics (which refers to the study of genetic material, 16S rRNA and/or whole-genome shotgun DNA, from microbial communities) has revolutionized the study of micro-scale ecosystems within us and around us. There is increasing literature of applying machine learning in general to metagenomic analysis. In the late 2000’s, a plethora of machine learning methods were applied to classifying DNA sequencing reads to the thousands of species within a sample. An important problem is genome assembly from these mixed-organism samples. And to do that, the organisms should be “binned” before assembling. Binning methods began with many k-mer techniques <span class="citation">[<a href="#ref-N9NzkOjA">138</a>]</span> and then delved into other clustering algorithms, such as self-organizing maps (SOM) <span class="citation">[<a href="#ref-1HhqhBwrM">139</a>]</span>. Then came the taxonomic classification problem, with researchers naturally using BLAST <span class="citation">[<a href="#ref-s9ycaHcq">140</a>]</span>, followed by other machine learning techniques such as SVMs <span class="citation">[<a href="#ref-QV551Nlx">141</a>]</span>, naive Bayesian classifiers <span class="citation">[<a href="#ref-1HtJuEkb2">142</a>]</span>, etc. to classify each read. Then, researchers began to use techniques that could be used to estimate relative abundances of an entire sample, instead of the precise but painstakingly slow read-by-read classification. Relative abundance estimators (a.k.a diversity profilers) are MetaPhlan <span class="citation">[<a href="#ref-56wEWVIl">143</a>]</span>, (WGS)Quikr <span class="citation">[<a href="#ref-RqhGD9c7">144</a>]</span>, and some configurations of tools like OneCodex <span class="citation">[<a href="#ref-EbkFuLrS">145</a>]</span> and LMAT <span class="citation">[<a href="#ref-189TQrQA9">146</a>]</span>. While one cannot identify which reads were mapped back to an organism using relative abundance estimators, they can be useful for faster comparative and other downstream analyses. Newer methods hope to classify reads and estimate relative abundances at faster rates <span class="citation">[<a href="#ref-8DLzxOEt">147</a>]</span> and as of this writing, there are more than 70 metagenomic taxonomic classifiers in existence. Besides binning and classification of species, there is functional identification and annotation of sequence reads <span class="citation">[<a href="#ref-qUGH5CX8">148</a>,<a href="#ref-yFOAeemA">149</a>]</span>. However, the focus on taxonomic/functional annotation is just the first step. Once organisms are identified, there is the interest in understanding the interrelationship between these organisms and host/environment phenotypes <span class="citation">[<a href="#ref-W0cYSf89">150</a>]</span>. One of the first attempts was a survey of supervised classification methods for microbes-&gt;phenotype classification <span class="citation">[<a href="#ref-aI9g2UOc">151</a>]</span>, followed by similar studies that are more massive in scale <span class="citation">[<a href="#ref-c5P9jHCg">152</a>,<a href="#ref-y9s5irW">153</a>]</span>. There have been techniques that bypass the taxonomic classification step altogether <span class="citation">[<a href="#ref-5W4KMSdT">154</a>]</span>, (sequence composition to phenotype classification). Also, researchers have looked into how feature selection can improve classification <span class="citation">[<a href="#ref-y9s5irW">153</a>,<a href="#ref-Kt9NojjR">155</a>]</span>, and techniques have been proposed that are classifier-independent <span class="citation">[<a href="#ref-1AN5UPfb1">156</a>,<a href="#ref-O9D66oYa">157</a>]</span>.</p>
<p>So, how have neural networks (NNs) been of use? Most neural networks are being used for short sequence-&gt;taxa/function classification, where there is a lot of data for training (and thus suitable for NNs). Neural networks have been applied successfully to gene annotation (e.g. Orphelia <span class="citation">[<a href="#ref-q1A2AEtO">158</a>]</span> and FragGeneScan <span class="citation">[<a href="#ref-QlbXLqH">159</a>]</span>), which usually has plenty of training examples. Representations (similar to Word2Vec <span class="citation">[<a href="#ref-1GhHIDxuW">160</a>]</span> in natural language processing) for protein family classification has been introduced and classified with a skip-gram neural network <span class="citation">[<a href="#ref-1E1PWjqTm">161</a>]</span>. Recurrent neural networks show good performance for homology and protein family identification <span class="citation">[<a href="#ref-G8RKF6sz">162</a>,<a href="#ref-81Cl5QSM">163</a>]</span>. Interestingly, Hochreiter, who invented Long Short Term Memory, delved into homology/protein family classification in 2007, and therefore, deep learning is deeply rooted in functional classification methods.</p>
<p>One of the first techniques of “de novo” genome binning used self-organizing maps, a type of NN <span class="citation">[<a href="#ref-1HhqhBwrM">139</a>]</span>. Essinger et al. use ART, a neural network algorithm called Adaptive Resonance Theory, to cluster similar genomic fragments and showed that it has better performance than K-means. However, other methods based on interpolated Markov models <span class="citation">[<a href="#ref-c4rnN1wo">164</a>]</span> have performed better than these early genome binners. Also, neural networks can be slow, and therefore, have had limited use for reference-based taxonomic classification, with TAC-ELM <span class="citation">[<a href="#ref-Wz7VUS03">165</a>]</span> being the only NN-based algorithm to taxonomically classify massive amounts of metagenomic data. Also, neural networks can fail to perform if there are not enough training examples, which is the case with taxonomic classification (since only ~10% of estimated species have been sequenced). An initial study shows that deep neural networks have been successfully applied to taxonomic classification of 16S rRNA genes, with convolutional networks provide about 10% accuracy genus-level improvement over RNNs and even random forests <span class="citation">[<a href="#ref-iPIJrVVs">166</a>]</span>. However, this study performed 10-fold cross-validation on 3000 sequences in total.</p>
<p>Due to the traditionally small numbers of metagenomic samples in studies, neural network uses for classifying phenotype from microbial composition are just beginning. A standard MLP was able to classify wound severity from microbial species present in the wound <span class="citation">[<a href="#ref-oas5tbC7">167</a>]</span>. Recently, multi-layer, recurrent networks (and convolutional networks) have been applied to microbiome genotype-phenotype, with Ditzler et al. being the first to associate soil samples with pH level using multi-layer perceptrons, deep-belief networks, and recursive neural networks (RNNs) <span class="citation">[<a href="#ref-i38A0beL">168</a>]</span>. Besides classifying the samples appropriately, Ditzler shows that internal phylogenetic tree nodes inferred by the networks are appropriate features representing low/high pH, which can provide additional useful information and new features for future metagenomic sample comparison. Also, an initial study has show promise of these networks for diagnosing disease <span class="citation">[<a href="#ref-NQ5jiN7B">169</a>]</span>.</p>
<p>There are still a lot of challenges with applying deep neural networks to metagenomics problems. They are not ideal for microbial/functional composition-&gt;phenotype classification because most studies contain tens of samples (~20-&gt;40) and hundreds/thousands of features (aka species). Such underdetermined/ill-conditioned problems are still a challenge for deep neural networks that require many more training examples than features to sufficiently converge the weights on the hidden layers. Also, due to convergence issues (slowness and instability due to large neural networks modeling very large datasets <span class="citation">[<a href="#ref-g2vvbB91">170</a>]</span>), taxonomic classification of reads from whole genome sequencing seems out of reach at the moment for deep neural networks -- due to only thousands of full-sequenced genomes as compared to hundreds of thousands of 16S rRNA sequences available for training.</p>
<p>However, because recurrent neural networks are showing success for base-calling (and thus removing the large error in the measurement of a pore's current signal) for the relatively new Oxford Nanopore sequencer <span class="citation">[<a href="#ref-1BTJ1KqRa">171</a>]</span>, there is hope that the process of denoising-&gt;organism/function classification can be combined into one step in using powerful LSTM's. LSTM's are working miracles in raw speech signal-&gt;meaning translation <span class="citation">[<a href="#ref-2cMhMv5A">172</a>]</span>, and combining steps in metagenomics are not out of the question. For example, metagenomic assembly usually requires binning then assembly, but could deep neural nets accomplish both tasks in one network? Does functional/taxonomic classification need to be separate processes? The largest potential in deep learning is to learn &quot;everything&quot; in one complex network, with a plethora of labeled (reference) data and unlabeled (microbiome experiments) examples.</p>
<h3 id="sequencing-and-variant-calling">Sequencing and variant calling</h3>
<p><em>We have one nanopore paper in the issues and very recent work on variant calling that looks worthy of inclusion.</em></p>
<h2 id="the-impact-of-deep-learning-in-treating-disease-and-developing-new-treatments">The impact of deep learning in treating disease and developing new treatments</h2>
<p><em>There will be some overlap with the Categorize section, and we may have to determine which methods categorize individuals and which more directly match patients with treatments. The sub-section titles are merely placeholders.</em></p>
<h3 id="categorizing-patients-for-clinical-decision-making">Categorizing patients for clinical decision making</h3>
<p>There has been sustained interest in applying deep learning to clinical decision making for over two decades. In 1996, Tu <span class="citation">[<a href="#ref-kL0B4m9d">173</a>]</span> compared the effectiveness of artificial neural networks and logistic regression, questioning whether deep learning would replace traditional statistical methods for predicting medical outcomes such as myocardial infarction <span class="citation">[<a href="#ref-jdg2u7bX">174</a>]</span> or mortality <span class="citation">[<a href="#ref-xX68eyvs">175</a>]</span>. He posited that while neural networks have several advantages in representational power, the difficulties in interpretation may limit clinical applications. In 2007, Lisboa and Taktak <span class="citation">[<a href="#ref-qxxwkSAT">176</a>]</span> examined the use of artificial neural networks in medical journals, concluding that neural networks provided an increase in benefit to healthcare relative to traditional screening methods in 21 of 27 studies.</p>
<p>While significant progress has been made in developing deep learning methods for diagnosis, it is not clear that these methods have yet transformed clinical decision making. The difficulty in applying deep learning to clinical decision making represents a challenge common to many deep learning applications: it is much easier to predict an outcome than to suggest an action to change the outcome. Several attempts at recasting the clinical decision making problem into a prediction problem (i.e. prediction of which treatment will most improve the patient's health) have accurately predicted prescription habits, but technical and medical challenges remain for clinical adoption. In particular, remaining challenges include actionable interpretability of deep learning models, fitting deep models to limited and heterogeneous data, and integrating complex predictive models into a dynamic clinical environment.</p>
<h4 id="applications">Applications</h4>
<h5 id="trajectory-prediction-for-treatment">Trajectory Prediction for Treatment</h5>
<p>A common application for deep learning techniques in this domain is to leverage the temporal structure of healthcare records. As previously discussed, many studies <span class="citation">[<a href="#ref-4zpZxjHR">177</a>–<a href="#ref-glyI7H6F">180</a>]</span> have used deep recurrent networks to categorize patients but most stop short of suggesting clinical decisions. Nemati et al <span class="citation">[<a href="#ref-16OQvsRqJ">181</a>]</span> used deep reinforcement learning to optimize a heparin dosing policy for intensive care patients. However, because the ideal dosing policy is unknown, the model's predictions must be evaluated on counter-factual data. This represents a common challenge when bridging the gap between research and clinical practice: because the ground-truth is unknown, researchers struggle to evaluate model predictions in the absence of interventional data, but clinical application is unlikely until the model has been shown to be effective . The impressive applications of deep reinforcement learning to other domains <span class="citation">[<a href="#ref-2gn6PKkv">2</a>]</span> have relied on knowledge of the underlying processes (e..g the rules of the game). Some models have been developed for targeted medical problems <span class="citation">[<a href="#ref-eCrLGgiX">182</a>]</span>, but a generalized engine is beyond current capabilities. Further development of the rules underlying biological processes could unleash deep learning methods that are currently hampered by the difficulties of counter-factual inference.</p>
<h5 id="efficient-clinical-trials">Efficient Clinical trials</h5>
<p>A clinical task to deep learning which has been more successfully applied is the assignment of patients to clinical trials. Ithapu et al <span class="citation">[<a href="#ref-eehGXQlY">183</a>]</span> used a randomized denoising autoenconder to learn a multimodal imaging marker that predicts future cognitive and neural decline from positron emission tomography (PET), amyloid florbetapir PET, and structural magnetic resonance imaging. By accurately predicting which cases will progress to dementia, they were able to efficiently assign patients to a clinical trial and reduced the required sample sizes by a factor of five. Similarly, Artemov et al <span class="citation">[<a href="#ref-mo3GQwJj">184</a>]</span> applied deep learning to predict which clinical trials were likely to fail and which were likely to succeed. By predicting the side effects and pathway activations of each drug, and then translating these activations to a success proability, their deep learning-based approach was able to significantly outperform a random forest classifier trained on gene expression changes. These approaches suggest promising directions to improve the efficiency of clinical trials and accelerate drug development.</p>
<h4 id="challenges">Challenges</h4>
<h5 id="actionable-interpretability">Actionable Interpretability</h5>
<p>A common challenge in many applied deep learning problems is the consideration of deep learning models as uninterpretable &quot;black boxes&quot;. Without human- intelligible reasoning for the model's predictions, it is difficult to trust the model. This presents a major challenge for the risk-averse task of clinical decision making. As described above, there has been some work to directly assign treatment plans without interpretability; however, the removal of human experts from the decision-making loop make the models difficult to integrate with clinical practice. To alleviate this challenge, several studies have attempted to create more interpretable deep models, either specifically for healthcare or as a general procedure for deep learning. Further work in interpreting predictions and understanding the knowledge learned by deep neural networks seem necessary for transformative impact in clinical practice. Interpretability in deep learning is reviewed more extensively in the Discussion.</p>
<h5 id="integrating-deep-learning-with-clinical-practice">Integrating Deep Learning with Clinical Practice</h5>
<p>As deep learning models are difficult to interpret, many current models have been designed to replace aspects of clinical practice rather than to assist trained clinicians. This makes it difficult to integrate deep learning with clinical decision making. In addition, the challenges that physicians face are largely similar to those faced by machine learning models. For a given patient, the number of possible diseases is very large, with a long tail of rare diseases. Furthermore, patients are highly heterogeneous and may present with very different signs and symptoms for the same disease. Physicians are experienced in treating patients with common diseases, but rare diseases are extremely challenging. Unfortunately, machine learning methods also struggle for rare diseases. Because deep learning models are data-intensive, directly applying current deep learning models to diagnose patients with rare diseases would require prohibitively large datasets. Focused effort in reducing the data requirements of deep learning by integrating pre-existing knowledge or compiling large datasets of patient records may unlock the power of deep learning for clinical practice.</p>
<h3 id="effects-of-drugs-on-transcriptomic-responses">Effects of drugs on transcriptomic responses</h3>
<p><em>We discussed a few papers that operate on Library of Network-Based Cellular Signatures (LINCS) gene expression data. We could briefly introduce the goals of that resource and comment on the deep learning applications. In the Issues, we had reservations about whether the improvements in expression prediction are good enough to make a practical difference in the domain and feature selection and construction.</em></p>
<h3 id="ligand-based-prediction-of-bioactivity">Ligand-Based Prediction of Bioactivity</h3>
<p><strong>TODO: expand outline</strong></p>
<ul>
<li>Short introduction to problem, related reviews, use vHTS definition from <span class="citation">[<a href="#ref-cjj5vT3H">185</a>]</span> (vHTS doesn't fit neatly into classic classification, regression, or ranking)</li>
<li>Introduce ligand-based approaches, hype and excitement surrounding performance of a &quot;high-parameter&quot; network on the Merck Kaggle challenge, cover other neural networks trained on fingerprints or descriptors as features that followed, Tox21 Data Challenge</li>
<li>Multitask networks related to the above point</li>
<li>Realistic view of where things stand today, high-parameter networks struggle with overfitting, cross validation needs to be done carefully because of temporal structure <span class="citation">[<a href="#ref-uP7SgBVd">186</a>]</span>, low parameter networks based on chemical similarity (IRV) work very well, especially well-suited for the domain in which training data can be limited and contains few positive instances, may touch on BACE example here and other discussions of training data limitations (e.g. <span class="citation">[<a href="#ref-HRoooKGh">187</a>]</span>)</li>
<li>&quot;Creative experimentation&quot; phase of the field, new ideas for representation learning and novel approaches including graph convolutions, autoencoders, one shot learning, and generative models</li>
<li>These &quot;creative&quot; approaches are definitely interesting but aren't necessarily outperforming existing methods, improvements on the software and reusability side could be important to help establish more rigorous benchmarking, DeepChem as example of this</li>
<li>Future outlook, what would need to happen for the &quot;creative&quot; approaches to overtake the current state of the art, can representation learning be improved by incorporating more information about chemical properties or even more &quot;tasks&quot; during training, how much will future growth depend on data versus algorithms</li>
<li>Future outlook part 2, how the above approaches relate to traditional methods like docking (note neural networks that include docking scores as features), deep learning efforts in this direction that use structure (e.g. <span class="citation">[<a href="#ref-Z7fd0BYf">26</a>,<a href="#ref-bNBiIiTt">188</a>]</span>), &quot;zero-shot learning&quot;, analogies to other domains where deep learning can capture the behavior of complex physics (e.g. quantum physics example), maybe briefly mention other compound-protein interaction-based networks although that doesn't seem to fit here and is somewhat out of scope</li>
<li>Future output part 3 (most speculative), what would successful generative networks mean for the HTS field?</li>
</ul>
<h3 id="modeling-metabolism-and-chemical-reactivity">Modeling Metabolism and Chemical Reactivity</h3>
<p><em>Add a review here of metabolism and chemical reactivity.</em></p>
<h2 id="discussion">Discussion</h2>
<p><em>This section provides meta-commentary that spans the Categorize, Study, and Treat subject areas. The candidate sub-sections below are initial ideas that can be further pruned.</em></p>
<h3 id="evaluation">Evaluation</h3>
<p><em>What are the challenges in evaluating deep learning models that are specific to this domain? This can include a discussion of ROC versus precision-recall curves for the imbalanced classes often encountered in biomedical datasets. It could also mention alternative metrics that are used in specific sub-areas such as enrichment factors in virtual screening. A lack of true gold standard data for some problems complicates both training and evaluation. Confidence- weighted labels are valuable when available.</em></p>
<p><em>Is progress in some biomedical areas slowed when new predictions (e.g. from generative models) cannot be assessed by any human expert and require experimental testing? For example, contrast a painting or song generated by a GAN versus a novel chemical compound. Related is the idea that on some tasks (e.g. the recent wave of deep learning versus MD image classification papers) it is easy to tell when deep learning has produced a breakthrough because human-level performance is an impressive baseline. In many tasks we reviewed, human-level performance is irrelevant.</em></p>
<h3 id="interpretation">Interpretation</h3>
<p>As the challenge of interpretability is common across many domains, there is significant interest in developing generic procedures for knowledge extraction from deep models. Ribeiro et al <span class="citation">[<a href="#ref-QwXSJhr0">189</a>]</span> focus on interpreting individual predictions rather than interpreting the model. By fitting simple linear models to mimic the predictions of the deep learning model in a small neighborhood of a data sample, they generated an interpretable model for each prediction. While this procedure can provide interpretable models for each sample, it is unclear whether these interpretable models are reliable. Theoretical guarantees on the curvature of the predictions of deep learning models are not known, and it is unclear whether predictions from deep learning models are robust to sample noise. Toward quantifying the uncertainty of predictions, there has been a renewed interest in confidence intervals for deep neural networks. Early work from Chryssolouris et al <span class="citation">[<a href="#ref-9SnNyc8Y">190</a>]</span> provided confidence intervals under the assumption of normally distributed error. However, Nguyen et al <span class="citation">[<a href="#ref-1AkF8Wsv7">191</a>]</span> showed that the confidence of convolutional neural networks is not reliable; they can output confidence scores over 99.99% even for samples that are purely noise. Recently, Fong and Vedaldi <span class="citation">[<a href="#ref-y4t9EzPn">192</a>]</span> provided a framework for understanding black box algorithms by perturbing input data.</p>
<p>For domain-specific models, we previously described approaches for the interpretation and visualization of neural networks that prediction transcription factor binding <span class="citation">[<a href="#ref-2UI1BZuD">99</a>–<a href="#ref-xAbGxia4">101</a>]</span>. Other studies have primarily focused on integrating attention mechanisms with the neural networks. Attention mechanisms dynamically weight the importance the neural network gives to each feature. By inspecting the attention weights for a particular sample, a practitioner can identify the important features for a particular prediction. Choi et al <span class="citation">[<a href="#ref-UcRbawKo">193</a>]</span> inverted the typical architecture of recurrent neural networks to improve interpretability. In particular, they only used recurrent connections in the attention generating procedure, leaving the hidden state directly connected to the input variables. In the clinical domain, this model was able to produce accurate diagnoses in which the contribution of previous hospital visits could be directly interpreted. Choi et al <span class="citation">[<a href="#ref-10nDTiETi">194</a>]</span> later extended this work to take into account the structure of disease ontologies and found that the concepts represented by the model were aligned with medical knowledge. Che et al <span class="citation">[<a href="#ref-14DAmZTDg">195</a>]</span> introduced a knowledge-distillation approach which used gradient boosted trees to learn interpretable healthcare features from trained deep models.</p>
<h3 id="data-limitations">Data limitations</h3>
<p><em>Related to evaluation, are there data quality issues in genomic, clinical, and other data that make this domain particularly challenging? Are these worse than what is faced in other non-biomedical domains?</em></p>
<p><em>Many applications have used relatively small training datasets. We might discuss workarounds (e.g. semi-synthetic data, splitting instances, etc.) and how this could impact future progress. Might this be why some studies have resorted to feature engineering instead of learning representations from low- level features? Is there still work to be done in finding the right low-level features in some problems?</em></p>
<h3 id="hardware-limitations-and-scaling">Hardware limitations and scaling</h3>
<p><em>Several papers have stated that memory or other hardware limitations artificially restricted the number of training instances, model inputs/outputs, hidden layers, etc. Is this a general problem worth discussing or will it be solved naturally as hardware improves and/or groups move to distributed deep learning frameworks? Does hardware limit what types of problems are accessible to the average computational group, and if so, will that limit future progress? For instance, some hyperparameter search strategies are not feasible for a lab with only a couple GPUs.</em></p>
<p><em>Some of this is also outlined in the Categorize section. We can decide where it best fits.</em></p>
<p>Efficiently scaling deep learning is challenging, and there is a high computational cost (e.g., time, memory, energy) associated with training neural networks and using them for classification. As such, neural networks have only recently found widespread use <span class="citation">[<a href="#ref-BQS8ClV0">6</a>]</span>.</p>
<p>Many have sought to curb the costs of deep learning, with methods ranging from the very applied (e.g., reduced numerical precision <span class="citation">[<a href="#ref-CKcJuj03">196</a>–<a href="#ref-1GUizyE8e">199</a>]</span>) to the exotic and theoretic (e.g., training small networks to mimic large networks and ensembles <span class="citation">[<a href="#ref-1AhGoHZP9">200</a>,<a href="#ref-1CRF3gAV">201</a>]</span>). The largest gains in efficiency have come from computation with graphics processing units (GPUs) <span class="citation">[<a href="#ref-BQS8ClV0">6</a>,<a href="#ref-F3e4wfzQ">202</a>–<a href="#ref-1FocAi7N0">206</a>]</span>, which excel at the matrix and vector operations so central to deep learning. The massively parallel nature of GPUs allows additional optimizations, such as accelerated mini-batch gradient descent <span class="citation">[<a href="#ref-NSgduYNT">203</a>,<a href="#ref-IULiPa6L">204</a>,<a href="#ref-aClNvbyM">207</a>,<a href="#ref-fNkl8HFz">208</a>]</span>. However, GPUs also have a limited quantity of memory, making it difficult to implement networks of significant size and complexity on a single GPU or machine <span class="citation">[<a href="#ref-F3e4wfzQ">202</a>,<a href="#ref-CCS5KSIM">209</a>]</span>. This restriction has sometimes forced computational biologists to use workarounds or limit the size of an analysis. For example, Chen et al. <span class="citation">[<a href="#ref-12QQw9p7v">81</a>]</span> aimed to infer the expression level of all genes with a single neural network, but due to memory restrictions they randomly partitioned genes into two halves and analyzed each separately. In other cases, researchers limited the size of their neural network <span class="citation">[<a href="#ref-W3grN7jy">19</a>,<a href="#ref-2dU8f4XJ">210</a>]</span>. Some have also chosen to use slower CPU implementations rather than sacrifice network size or performance <span class="citation">[<a href="#ref-x0M6vals">211</a>]</span>.</p>
<p>Steady improvements in GPU hardware may alleviate this issue somewhat, but it is not clear whether they can occur quickly enough to keep up with the growing amount of available biological data or increasing network sizes. Much has been done to minimize the memory requirements of neural networks <span class="citation">[<a href="#ref-CKcJuj03">196</a>–<a href="#ref-1AhGoHZP9">200</a>,<a href="#ref-YwdqeYZi">212</a>,<a href="#ref-15lYGmZpY">213</a>]</span>, but there is also growing interest in specialized hardware, such as field-programmable gate arrays (FPGAs) <span class="citation">[<a href="#ref-1FocAi7N0">206</a>,<a href="#ref-9NKsJjSw">214</a>]</span> and application-specific integrated circuits (ASICs). Specialized hardware promises improvements in deep learning at reduced time, energy, and memory <span class="citation">[<a href="#ref-1FocAi7N0">206</a>]</span>. Logically, there is less software for highly specialized hardware <span class="citation">[<a href="#ref-9NKsJjSw">214</a>]</span>, and it could be a difficult investment for those not solely interested in deep learning. However, it is likely that such options will find increased support as they become a more popular platform for deep learning and general computation.</p>
<p>Distributed computing is a general solution to intense computational requirements, and has enabled many large-scale deep learning efforts. Early approaches to distributed computation <span class="citation">[<a href="#ref-xE3EYmck">215</a>,<a href="#ref-1XcexUAV">216</a>]</span> were not suitable for deep learning <span class="citation">[<a href="#ref-17cBimWgp">217</a>]</span>, but significant progress has been made. There now exist a number of algorithms <span class="citation">[<a href="#ref-w6CoVmFK">198</a>,<a href="#ref-17cBimWgp">217</a>,<a href="#ref-HIiQN4bd">218</a>]</span>, tools <span class="citation">[<a href="#ref-rmJZ2Aui">219</a>–<a href="#ref-Gp4OR9Lf">221</a>]</span>, and high-level libraries <span class="citation">[<a href="#ref-FwEK0msb">222</a>,<a href="#ref-y9IoEy4r">223</a>]</span> for deep learning in a distributed environment, and it is possible to train very complex networks with limited infrastructure <span class="citation">[<a href="#ref-4MZ2tmZ8">224</a>]</span>. Besides handling very large networks, distributed or parallelized approaches offer other advantages, such as improved ensembling <span class="citation">[<a href="#ref-JUF9VoRD">225</a>]</span> or accelerated hyperparameter optimization <span class="citation">[<a href="#ref-wz83yfHF">226</a>,<a href="#ref-Wsa952Ax">227</a>]</span>.</p>
<p>Cloud computing, which has already seen adoption in genomics <span class="citation">[<a href="#ref-B6g0qKf4">228</a>]</span>, could facilitate easier sharing of the large datasets common to biology <span class="citation">[<a href="#ref-1E7bFCRV4">229</a>,<a href="#ref-q0SsFrZd">230</a>]</span>, and may be key to scaling deep learning. Cloud computing affords researchers significant flexibility, and enables the use of specialized hardware (e.g., FPGAs, ASICs, GPUs) without significant investment. With such flexibility, it could be easier to address the different challenges associated with the multitudinous layers and architectures available <span class="citation">[<a href="#ref-ZSVsnPVO">231</a>]</span>. Though many are reluctant to store sensitive data (e.g., patient electronic health records) in the cloud, secure/regulation-compliant cloud services do exist <span class="citation">[<a href="#ref-ObFN78yp">232</a>]</span>.</p>
<p><em>TODO: Write the transition once more of the Discussion section has been fleshed out.</em></p>
<h3 id="code-data-and-model-sharing">Code, data, and model sharing</h3>
<p><em>Reproducibiliy is important for science to progress. In the context of deep learning applied to advance human healthcare, does reproducibility have different requirements or alternative connotations? With vast hyperparameter spaces, massively heterogeneous and noisy biological data sets, and black box interpretability problems, how can we best ensure reproducible models? What might a clinician, or policy maker, need to see in a deep model in order to influence healthcare decisions? Or, is deep learning a hypothesis generation machine that requires manual validation? DeepChem and DragoNN are worth discussing here.</em></p>
<h3 id="transfer-learningtransferability-of-features">Transfer learning/transferability of features</h3>
<ul>
<li>https://github.com/greenelab/deep-review/issues/139#issuecomment-268901804</li>
</ul>
<h2 id="conclusions">Conclusions</h2>
<p>Final thoughts and future outlook here. The Discussion will give an overview and the Conclusion will provide a short, punchy take home message.</p>
<p>Points to mention based on discussion thus far that may make the bar for conclusions:</p>
<ul>
<li>Limitations of data &amp; workarounds (availability impacts on amount, etc)</li>
<li>Transferability of features</li>
<li>Strong enthusiasm for unsupervised approaches.</li>
<li>Right to an explanation (possibly, depends if raised in multiple areas)</li>
</ul>
<h3 id="author-contributions">Author contributions</h3>
<p><code>TODO: not sure if it should go here, but somewhere we should talk about how we wrote this thing, since it is still somewhat unconventional to have a review written in this manner.</code> We recognized that writing a review on a rapidly developing area in a manner that allowed us to provide a forward-looking perspective on diverse approaches and biological problems would require expertise from across computational biology and medicine. We created an open repository on the GitHub version control system and engaged with numerous authors from papers within and outside of the area. Paper review was conducted in the open by <code>#</code> individuals, and the manuscript was drafted in a series of commits from <code>#</code> authors. Individuals who met the ICJME standards of authorship are included as authors. These were individuals who contributed to the review of the literature; drafted the manuscript or provided substantial critical revisions; approved the final manuscript draft; and agreed to be accountable in all aspects of the work. Individuals who did not contribute in one or more of these ways, but who did participate, are acknowledged at the end of the manuscript.</p>
<div id="refs" class="references">
<div id="ref-13bxiY1vo">
<p>1. Stephens ZD <em>et al.</em> 2015 Big Data: Astronomical or Genomical? <em>PLOS Biology</em> <strong>13</strong>, e1002195. (doi:<a href="https://doi.org/10.1371/journal.pbio.1002195">10.1371/journal.pbio.1002195</a>)</p>
</div>
<div id="ref-2gn6PKkv">
<p>2. Silver D <em>et al.</em> 2016 Mastering the game of Go with deep neural networks and tree search. <em>Nature</em> <strong>529</strong>, 484–489. (doi:<a href="https://doi.org/10.1038/nature16961">10.1038/nature16961</a>)</p>
</div>
<div id="ref-IiNJE32f">
<p>3. In press. See <a href="http://research.google.com/archive/unsupervised_icml2012.html" class="uri">http://research.google.com/archive/unsupervised_icml2012.html</a>.</p>
</div>
<div id="ref-BeijBSRE">
<p>4. LeCun Y, Bengio Y, Hinton G. 2015 Deep learning. <em>Nature</em> <strong>521</strong>, 436–444. (doi:<a href="https://doi.org/10.1038/nature14539">10.1038/nature14539</a>)</p>
</div>
<div id="ref-1G5eCiq4d">
<p>5. Block HD, Knight BW, Rosenblatt F. 1962 Analysis of a Four-Layer Series-Coupled Perceptron. II. <em>Reviews of Modern Physics</em> <strong>34</strong>, 135–142. (doi:<a href="https://doi.org/10.1103/revmodphys.34.135">10.1103/revmodphys.34.135</a>)</p>
</div>
<div id="ref-BQS8ClV0">
<p>6. Schmidhuber J. 2015 Deep learning in neural networks: An overview. <em>Neural Networks</em> <strong>61</strong>, 85–117. (doi:<a href="https://doi.org/10.1016/j.neunet.2014.09.003">10.1016/j.neunet.2014.09.003</a>)</p>
</div>
<div id="ref-mAXsmd43">
<p>7. In press. See <a href="http://www.intel.com/pressroom/archive/speeches/ag080998.htm" class="uri">http://www.intel.com/pressroom/archive/speeches/ag080998.htm</a>.</p>
</div>
<div id="ref-yXqhuueV">
<p>8. Park Y, Kellis M. 2015 Deep learning for regulatory genomics. <em>Nature Biotechnology</em> <strong>33</strong>, 825–826. (doi:<a href="https://doi.org/10.1038/nbt.3313">10.1038/nbt.3313</a>)</p>
</div>
<div id="ref-gJE0ExFr">
<p>9. Gawehn E, Hiss JA, Schneider G. 2015 Deep Learning in Drug Discovery. <em>Molecular Informatics</em> <strong>35</strong>, 3–14. (doi:<a href="https://doi.org/10.1002/minf.201501008">10.1002/minf.201501008</a>)</p>
</div>
<div id="ref-MmRGFVUu">
<p>10. Kraus OZ, Frey BJ. 2016 Computer vision for high content screening. <em>Critical Reviews in Biochemistry and Molecular Biology</em> <strong>51</strong>, 102–109. (doi:<a href="https://doi.org/10.3109/10409238.2015.1135868">10.3109/10409238.2015.1135868</a>)</p>
</div>
<div id="ref-1VZjheOA">
<p>11. Mamoshina P, Vieira A, Putin E, Zhavoronkov A. 2016 Applications of Deep Learning in Biomedicine. <em>Molecular Pharmaceutics</em> <strong>13</strong>, 1445–1454. (doi:<a href="https://doi.org/10.1021/acs.molpharmaceut.5b00982">10.1021/acs.molpharmaceut.5b00982</a>)</p>
</div>
<div id="ref-irSe12Sm">
<p>12. Angermueller C, Pärnamaa T, Parts L, Stegle O. 2016 Deep learning for computational biology. <em>Molecular Systems Biology</em> <strong>12</strong>, 878. (doi:<a href="https://doi.org/10.15252/msb.20156651">10.15252/msb.20156651</a>)</p>
</div>
<div id="ref-G00xvi94">
<p>13. Min S, Lee B, Yoon S. 2016 Deep learning in bioinformatics. <em>Briefings in Bioinformatics</em>, bbw068. (doi:<a href="https://doi.org/10.1093/bib/bbw068">10.1093/bib/bbw068</a>)</p>
</div>
<div id="ref-lnK82Ey6">
<p>14. Parker JS <em>et al.</em> 2009 Supervised Risk Predictor of Breast Cancer Based on Intrinsic Subtypes. <em>Journal of Clinical Oncology</em> <strong>27</strong>, 1160–1167. (doi:<a href="https://doi.org/10.1200/jco.2008.18.1370">10.1200/jco.2008.18.1370</a>)</p>
</div>
<div id="ref-pEIw87Mp">
<p>15. Mayer IA, Abramson VG, Lehmann BD, Pietenpol JA. 2014 New Strategies for Triple-Negative Breast Cancer–Deciphering the Heterogeneity. <em>Clinical Cancer Research</em> <strong>20</strong>, 782–790. (doi:<a href="https://doi.org/10.1158/1078-0432.ccr-13-0583">10.1158/1078-0432.ccr-13-0583</a>)</p>
</div>
<div id="ref-PBiRSdXv">
<p>16. TAN J, UNG M, CHENG C, GREENE CS. 2014 UNSUPERVISED FEATURE CONSTRUCTION AND KNOWLEDGE EXTRACTION FROM GENOME-WIDE ASSAYS OF BREAST CANCER WITH DENOISING AUTOENCODERS. In <em>Biocomputing 2015</em>, WORLD SCIENTIFIC. (doi:<a href="https://doi.org/10.1142/9789814644730_0014">10.1142/9789814644730_0014</a>)</p>
</div>
<div id="ref-koEdZRcY">
<p>17. Cireşan DC, Giusti A, Gambardella LM, Schmidhuber J. 2013 Mitosis Detection in Breast Cancer Histology Images with Deep Neural Networks. In <em>Medical Image Computing and Computer-Assisted Intervention – MICCAI 2013</em>, pp. 411–418. Springer Berlin Heidelberg. (doi:<a href="https://doi.org/10.1007/978-3-642-40763-5_51">10.1007/978-3-642-40763-5_51</a>)</p>
</div>
<div id="ref-YUms527e">
<p>18. Zurada J. In press. End effector target position learning using feedforward with error back-propagation and recurrent neural networks. In <em>Proceedings of 1994 IEEE International Conference on Neural Networks (ICNN’94)</em>, IEEE. (doi:<a href="https://doi.org/10.1109/icnn.1994.374637">10.1109/icnn.1994.374637</a>)</p>
</div>
<div id="ref-W3grN7jy">
<p>19. Wang S, Sun S, Li Z, Zhang R, Xu J. 2016 Accurate De Novo Prediction of Protein Contact Map by Ultra-Deep Learning Model. (doi:<a href="https://doi.org/10.1101/073239">10.1101/073239</a>)</p>
</div>
<div id="ref-ZzaRyGuJ">
<p>20. Spencer M, Eickholt J, Cheng J. 2015 A Deep Learning Network Approach to <italic>ab initio</italic> Protein Secondary Structure Prediction. <em>IEEE/ACM Transactions on Computational Biology and Bioinformatics</em> <strong>12</strong>, 103–112. (doi:<a href="https://doi.org/10.1109/tcbb.2014.2343960">10.1109/tcbb.2014.2343960</a>)</p>
</div>
<div id="ref-UO8L6nd">
<p>21. Wang S, Peng J, Ma J, Xu J. 2016 Protein Secondary Structure Prediction Using Deep Convolutional Neural Fields. <em>Scientific Reports</em> <strong>6</strong>. (doi:<a href="https://doi.org/10.1038/srep18962">10.1038/srep18962</a>)</p>
</div>
<div id="ref-s5sy4AOi">
<p>22. Liu F, Li H, Ren C, Bo X, Shu W. 2016 PEDLA: predicting enhancers with a deep learning-based algorithmic framework. (doi:<a href="https://doi.org/10.1101/036129">10.1101/036129</a>)</p>
</div>
<div id="ref-17B2QAA1k">
<p>23. Li Y, Chen C-Y, Wasserman WW. 2015 Deep Feature Selection: Theory and Application to Identify Enhancers and Promoters. In <em>Lecture Notes in Computer Science</em>, pp. 205–217. Springer International Publishing. (doi:<a href="https://doi.org/10.1007/978-3-319-16706-0_20">10.1007/978-3-319-16706-0_20</a>)</p>
</div>
<div id="ref-12aqvAgz6">
<p>24. Kleftogiannis D, Kalnis P, Bajic VB. 2014 DEEP: a general computational framework for predicting enhancers. <em>Nucleic Acids Research</em> <strong>43</strong>, e6–e6. (doi:<a href="https://doi.org/10.1093/nar/gku1058">10.1093/nar/gku1058</a>)</p>
</div>
<div id="ref-15E5yG1Ho">
<p>25. Quang D, Chen Y, Xie X. 2014 DANN: a deep learning approach for annotating the pathogenicity of genetic variants. <em>Bioinformatics</em> <strong>31</strong>, 761–763. (doi:<a href="https://doi.org/10.1093/bioinformatics/btu703">10.1093/bioinformatics/btu703</a>)</p>
</div>
<div id="ref-Z7fd0BYf">
<p>26. Wallach I, Dzamba M, Heifets A. 2015 AtomNet: A deep convolutional neural network for bioactivity prediction in structure-based drug discovery. </p>
</div>
<div id="ref-EMDwvRGb">
<p>27. Aliper A, Plis S, Artemov A, Ulloa A, Mamoshina P, Zhavoronkov A. 2016 Deep Learning Applications for Predicting Pharmacological Properties of Drugs and Drug Repurposing Using Transcriptomic Data. <em>Molecular Pharmaceutics</em> <strong>13</strong>, 2524–2530. (doi:<a href="https://doi.org/10.1021/acs.molpharmaceut.6b00248">10.1021/acs.molpharmaceut.6b00248</a>)</p>
</div>
<div id="ref-1AU7wzPqa">
<p>28. Wang Y, Zeng J. 2013 Predicting drug-target interactions using restricted Boltzmann machines. <em>Bioinformatics</em> <strong>29</strong>, i126–i134. (doi:<a href="https://doi.org/10.1093/bioinformatics/btt234">10.1093/bioinformatics/btt234</a>)</p>
</div>
<div id="ref-JK8NuXy3">
<p>29. Dhungel N, Carneiro G, Bradley AP. 2016 The Automated Learning of Deep Features for Breast Mass Classification from Mammograms. In <em>Medical Image Computing and Computer-Assisted Intervention – MICCAI 2016</em>, pp. 106–114. Springer International Publishing. (doi:<a href="https://doi.org/10.1007/978-3-319-46723-8_13">10.1007/978-3-319-46723-8_13</a>)</p>
</div>
<div id="ref-VFw1VXDP">
<p>30. Dhungel N, Carneiro G, Bradley AP. 2015 Deep Learning and Structured Prediction for the Segmentation of Mass in Mammograms. In <em>Lecture Notes in Computer Science</em>, pp. 605–612. Springer International Publishing. (doi:<a href="https://doi.org/10.1007/978-3-319-24553-9_74">10.1007/978-3-319-24553-9_74</a>)</p>
</div>
<div id="ref-9G9Hv1Pp">
<p>31. Zhu W, Lou Q, Vang YS, Xie X. 2016 Deep Multi-instance Networks with Sparse Label Assignment for Whole Mammogram Classification. (doi:<a href="https://doi.org/10.1101/095794">10.1101/095794</a>)</p>
</div>
<div id="ref-Xxb4t3zO">
<p>32. Zhu W, Xie X. 2016 Adversarial Deep Structural Networks for Mammographic Mass Segmentation. (doi:<a href="https://doi.org/10.1101/095786">10.1101/095786</a>)</p>
</div>
<div id="ref-aM2Uy2ix">
<p>33. Beaulieu-Jones BK, Greene CS. 2016 Semi-Supervised Learning of the Electronic Health Record for Phenotype Stratification. (doi:<a href="https://doi.org/10.1101/039800">10.1101/039800</a>)</p>
</div>
<div id="ref-mbEp6jNr">
<p>34. Wang D, Khosla A, Gargeya R, Irshad H, Beck AH. 2016 Deep learning for identifying metastatic breast cancer. </p>
</div>
<div id="ref-SxsZyrVM">
<p>35. Lee CS, Baughman DM, Lee AY. 2016 Deep learning is effective for the classification of OCT images of normal versus Age-related Macular Degeneration. (doi:<a href="https://doi.org/10.1101/094276">10.1101/094276</a>)</p>
</div>
<div id="ref-lTBZomqa">
<p>36. In press. See <a href="http://papers.nips.cc/paper/4824-imagenet-classification-with-deep-convolutional-neural-networks.pdf" class="uri">http://papers.nips.cc/paper/4824-imagenet-classification-with-deep-convolutional-neural-networks.pdf</a>.</p>
</div>
<div id="ref-uDaRUyh9">
<p>37. Ohno-Machado L. 2011 Realizing the full potential of electronic health records: the role of natural language processing. <em>Journal of the American Medical Informatics Association</em> <strong>18</strong>, 539–539. (doi:<a href="https://doi.org/10.1136/amiajnl-2011-000501">10.1136/amiajnl-2011-000501</a>)</p>
</div>
<div id="ref-sG3iVOTS">
<p>38. de Bruijn B, Cherry C, Kiritchenko S, Martin J, Zhu X. 2011 Machine-learned solutions for three stages of clinical information extraction: the state of the art at i2b2 2010. <em>Journal of the American Medical Informatics Association</em> <strong>18</strong>, 557–562. (doi:<a href="https://doi.org/10.1136/amiajnl-2011-000150">10.1136/amiajnl-2011-000150</a>)</p>
</div>
<div id="ref-dO844vZn">
<p>39. Chalapathy R, Borzeshi EZ, Piccardi M. 2016 Bidirectional lstm-crf for clinical concept extraction. </p>
</div>
<div id="ref-yUgE09ve">
<p>40. Yoon H-J, Ramanathan A, Tourassi G. 2016 Multi-task Deep Neural Networks for Automated Extraction of Primary Site and Laterality Information from Cancer Pathology Reports. In <em>Advances in Big Data</em>, pp. 195–204. Springer International Publishing. (doi:<a href="https://doi.org/10.1007/978-3-319-47898-2_21">10.1007/978-3-319-47898-2_21</a>)</p>
</div>
<div id="ref-FLX0o7bL">
<p>41. Lasko TA, Denny JC, Levy MA. 2013 Computational Phenotype Discovery Using Unsupervised Feature Learning over Noisy, Sparse, and Irregular Clinical Data. <em>PLoS ONE</em> <strong>8</strong>, e66341. (doi:<a href="https://doi.org/10.1371/journal.pone.0066341">10.1371/journal.pone.0066341</a>)</p>
</div>
<div id="ref-5x3uMSKi">
<p>42. Beaulieu-Jones BK, Greene CS. 2016 Semi-supervised learning of the electronic health record for phenotype stratification. <em>Journal of Biomedical Informatics</em> <strong>64</strong>, 168–178. (doi:<a href="https://doi.org/10.1016/j.jbi.2016.10.007">10.1016/j.jbi.2016.10.007</a>)</p>
</div>
<div id="ref-WrNCJ9sO">
<p>43. Miotto R, Li L, Kidd BA, Dudley JT. 2016 Deep Patient: An Unsupervised Representation to Predict the Future of Patients from the Electronic Health Records. <em>Scientific Reports</em> <strong>6</strong>. (doi:<a href="https://doi.org/10.1038/srep26094">10.1038/srep26094</a>)</p>
</div>
<div id="ref-qXdO2aMm">
<p>44. Ranganath R, Perotte A, Elhadad N, Blei D. 2016 Deep survival analysis. </p>
</div>
<div id="ref-1921Mctzh">
<p>45. Xiang A, Lapuerta P, Ryutov A, Buckley J, Azen S. 2000 Comparison of the performance of neural network methods and Cox regression for censored survival data. <em>Computational Statistics &amp; Data Analysis</em> <strong>34</strong>, 243–257. (doi:<a href="https://doi.org/10.1016/s0167-9473(99)00098-5">10.1016/s0167-9473(99)00098-5</a>)</p>
</div>
<div id="ref-1FE0F2pQ">
<p>46. Katzman J, Shaham U, Bates J, Cloninger A, Jiang T, Kluger Y. 2016 Deep survival: A deep cox proportional hazards network. </p>
</div>
<div id="ref-pxdeuhMS">
<p>47. Ranganath R, Tang L, Charlin L, Blei DM. 2014 Deep exponential families. </p>
</div>
<div id="ref-8RAYEOPl">
<p>48. Hoffman M, Blei DM, Wang C, Paisley J. 2012 Stochastic variational inference. </p>
</div>
<div id="ref-15lbUf0as">
<p>49. Ranganath R, Tran D, Blei DM. 2015 Hierarchical variational models. </p>
</div>
<div id="ref-1Ar4f4vfR">
<p>50. Zheng T, Xie W, Xu L, He X, Zhang Y, You M, Yang G, Chen Y. 2017 A machine learning-based framework to identify type 2 diabetes through electronic health records. <em>International Journal of Medical Informatics</em> <strong>97</strong>, 120–127. (doi:<a href="https://doi.org/10.1016/j.ijmedinf.2016.09.014">10.1016/j.ijmedinf.2016.09.014</a>)</p>
</div>
<div id="ref-ziudr6hx">
<p>51. In press. See <a href="https://phekb.org/implementations" class="uri">https://phekb.org/implementations</a>.</p>
</div>
<div id="ref-5Il3kN32">
<p>52. Ratner A, Sa CD, Wu S, Selsam D, Ré C. 2016 Data programming: Creating large training sets, quickly. </p>
</div>
<div id="ref-daemz8Fm">
<p>53. In press. See <a href="http://ana.blogs.com/maestros/2006/11/data_is_the_new.html," class="uri">http://ana.blogs.com/maestros/2006/11/data_is_the_new.html,</a></p>
</div>
<div id="ref-o8mib4CN">
<p>54. In press. See <a href="https://medium.com/twenty-one-hundred/data-is-the-new-oil-a-ludicrous-proposition-1d91bba4f294" class="uri">https://medium.com/twenty-one-hundred/data-is-the-new-oil-a-ludicrous-proposition-1d91bba4f294</a>.</p>
</div>
<div id="ref-hfcf5Hmi">
<p>55. In press. See <a href="http://hazyresearch.github.io/snorkel/blog/weak_supervision.html" class="uri">http://hazyresearch.github.io/snorkel/blog/weak_supervision.html</a>.</p>
</div>
<div id="ref-7yE9K08a">
<p>56. Goodman B, Flaxman S. 2016 European union regulations on algorithmic decision-making and a ‘right to explanation’. </p>
</div>
<div id="ref-1CuDxTLXa">
<p>57. Gymrek M, McGuire AL, Golan D, Halperin E, Erlich Y. 2013 Identifying Personal Genomes by Surname Inference. <em>Science</em> <strong>339</strong>, 321–324. (doi:<a href="https://doi.org/10.1126/science.1229566">10.1126/science.1229566</a>)</p>
</div>
<div id="ref-6XtEfQMC">
<p>58. Simmons S, Sahinalp C, Berger B. 2016 Enabling Privacy-Preserving GWASs in Heterogeneous Human Populations. <em>Cell Systems</em> <strong>3</strong>, 54–61. (doi:<a href="https://doi.org/10.1016/j.cels.2016.04.013">10.1016/j.cels.2016.04.013</a>)</p>
</div>
<div id="ref-11sli93ov">
<p>59. Bowman S. 2013 Impact of Electronic Health Record Systems on Information Integrity: Quality and Safety Implications. <em>Perspect Health Inf Manag</em> <strong>10</strong>, 1c. </p>
</div>
<div id="ref-y9ONtSZ9">
<p>60. Botsis T, Hartvigsen G, Chen F, Weng C. 2010 Secondary Use of EHR: Data Quality Issues and Informatics Opportunities. <em>Summit on Translat Bioinforma</em> <strong>2010</strong>, 1–5. </p>
</div>
<div id="ref-4rTluXLs">
<p>61. Just BH, Marc D, Munns M, Sandefer R. 2016 Why Patient Matching Is a Challenge: Research on Master Patient Index (MPI) Data Discrepancies in Key Identifying Fields. <em>Perspect Health Inf Manag</em> <strong>13</strong>, 1e. </p>
</div>
<div id="ref-11OyzMl87">
<p>62. Shivade C, Raghavan P, Fosler-Lussier E, Embi PJ, Elhadad N, Johnson SB, Lai AM. 2014 A review of approaches to identifying patient phenotype cohorts using electronic health records. <em>Journal of the American Medical Informatics Association</em> <strong>21</strong>, 221–230. (doi:<a href="https://doi.org/10.1136/amiajnl-2013-001935">10.1136/amiajnl-2013-001935</a>)</p>
</div>
<div id="ref-qe90c1CL">
<p>63. WILEY LK, VANHOUTEN JP, SAMUELS DC, ALDRICH MC, RODEN DM, PETERSON JF, DENNY JC. 2016 STRATEGIES FOR EQUITABLE PHARMACOGENOMIC-GUIDED WARFARIN DOSING AMONG EUROPEAN AND AFRICAN AMERICAN INDIVIDUALS IN A CLINICAL POPULATION. In <em>Biocomputing 2017</em>, WORLD SCIENTIFIC. (doi:<a href="https://doi.org/10.1142/9789813207813_0050">10.1142/9789813207813_0050</a>)</p>
</div>
<div id="ref-Qnd0SYhm">
<p>64. In press. See <a href="https://aclweb.org/anthology/D/D13/D13-1079.pdf" class="uri">https://aclweb.org/anthology/D/D13/D13-1079.pdf</a>.</p>
</div>
<div id="ref-XJw23xy0">
<p>65. Jagsi R, Surender R. 2004 Regulation of junior doctors’ work hours: an analysis of British and American doctors’ experiences and attitudes. <em>Social Science &amp; Medicine</em> <strong>58</strong>, 2181–2191. (doi:<a href="https://doi.org/10.1016/j.socscimed.2003.08.016">10.1016/j.socscimed.2003.08.016</a>)</p>
</div>
<div id="ref-wzfGJdXI">
<p>66. Liapis CD. 2003 Effects of limited work hours on surgical training. <em>Journal of the American College of Surgeons</em> <strong>196</strong>, 662–663. (doi:<a href="https://doi.org/10.1016/s1072-7515(03)00097-8">10.1016/s1072-7515(03)00097-8</a>)</p>
</div>
<div id="ref-nPRpl05n">
<p>67. Gravenstein JS, Cooper JB, Orkin FK. 1990 Work and Rest Cycles in Anesthesia Practice. <em>Anesthesiology</em> <strong>72</strong>, 737–742. (doi:<a href="https://doi.org/10.1097/00000542-199004000-00024">10.1097/00000542-199004000-00024</a>)</p>
</div>
<div id="ref-17hjNSIIc">
<p>68. Firth-Cozens J, Greenhalgh J. 1997 Doctors’ perceptions of the links between stress and lowered clinical care. <em>Social Science &amp; Medicine</em> <strong>44</strong>, 1017–1022. (doi:<a href="https://doi.org/10.1016/s0277-9536(96)00227-4">10.1016/s0277-9536(96)00227-4</a>)</p>
</div>
<div id="ref-ogs3PPp7">
<p>69. Jensen AB, Moseley PL, Oprea TI, Ellesøe SG, Eriksson R, Schmock H, Jensen PB, Jensen LJ, Brunak S. 2014 Temporal disease trajectories condensed from population-wide registry data covering 6.2 million patients. <em>Nature Communications</em> <strong>5</strong>. (doi:<a href="https://doi.org/10.1038/ncomms5022">10.1038/ncomms5022</a>)</p>
</div>
<div id="ref-Ohd1Q9Xw">
<p>70. Nguyen P, Tran T, Wickramasinghe N, Venkatesh S. 2016 Deepr: A convolutional net for medical records. </p>
</div>
<div id="ref-HRXii6Ni">
<p>71. Pham T, Tran T, Phung D, Venkatesh S. 2016 DeepCare: A deep dynamic memory model for predictive medicine. </p>
</div>
<div id="ref-HKA6hi9E">
<p>72. Russakovsky O <em>et al.</em> 2014 ImageNet large scale visual recognition challenge. </p>
</div>
<div id="ref-ULSPV0rh">
<p>73. Tramèr F, Zhang F, Juels A, Reiter MK, Ristenpart T. 2016 Stealing machine learning models via prediction apis. </p>
</div>
<div id="ref-v8Lp4ibI">
<p>74. Dwork C, Roth A. 2013 The Algorithmic Foundations of Differential Privacy. <em>Foundations and Trends® in Theoretical Computer Science</em> <strong>9</strong>, 211–407. (doi:<a href="https://doi.org/10.1561/0400000042">10.1561/0400000042</a>)</p>
</div>
<div id="ref-ucHUOABT">
<p>75. Abadi M, Chu A, Goodfellow I, McMahan HB, Mironov I, Talwar K, Zhang L. 2016 Deep learning with differential privacy. (doi:<a href="https://doi.org/10.1145/2976749.2978318">10.1145/2976749.2978318</a>)</p>
</div>
<div id="ref-7MR5St9Q">
<p>76. Beaulieu-Jones BK, Greene CS. 2016 Reproducible Computational Workflows with Continuous Analysis. (doi:<a href="https://doi.org/10.1101/056473">10.1101/056473</a>)</p>
</div>
<div id="ref-AnenJOuU">
<p>77. Gupta A, Wang H, Ganapathiraju M. 2015 Learning structure in gene expression data using deep architectures, with an application to gene clustering. (doi:<a href="https://doi.org/10.1101/031906">10.1101/031906</a>)</p>
</div>
<div id="ref-yVBx9Qx4">
<p>78. Chen L, Cai C, Chen V, Lu X. 2016 Learning a hierarchical representation of the yeast transcriptomic machinery using an autoencoder model. <em>BMC Bioinformatics</em> <strong>17</strong>. (doi:<a href="https://doi.org/10.1186/s12859-015-0852-1">10.1186/s12859-015-0852-1</a>)</p>
</div>
<div id="ref-1CFhfCyWN">
<p>79. Tan J, Hammond JH, Hogan DA, Greene CS. 2016 ADAGE-Based Integration of Publicly AvailablePseudomonas aeruginosaGene Expression Data with Denoising Autoencoders Illuminates Microbe-Host Interactions. <em>mSystems</em> <strong>1</strong>, e00025–15. (doi:<a href="https://doi.org/10.1128/msystems.00025-15">10.1128/msystems.00025-15</a>)</p>
</div>
<div id="ref-zuLdSQx3">
<p>80. Tan J <em>et al.</em> 2016 Unsupervised extraction of stable expression signatures from public compendia with eADAGE. (doi:<a href="https://doi.org/10.1101/078659">10.1101/078659</a>)</p>
</div>
<div id="ref-12QQw9p7v">
<p>81. Chen Y, Li Y, Narayan R, Subramanian A, Xie X. 2016 Gene expression inference with deep learning. <em>Bioinformatics</em> <strong>32</strong>, 1832–1839. (doi:<a href="https://doi.org/10.1093/bioinformatics/btw074">10.1093/bioinformatics/btw074</a>)</p>
</div>
<div id="ref-G10wkFHt">
<p>82. Singh R, Lanchantin J, Robins G, Qi Y. 2016 DeepChrome: Deep-learning for predicting gene expression from histone modifications. </p>
</div>
<div id="ref-1EtavGKI4">
<p>83. Liang M, Li Z, Chen T, Zeng J. 2015 Integrative Data Analysis of Multi-Platform Cancer Data with a Multimodal Deep Learning Approach. <em>IEEE/ACM Transactions on Computational Biology and Bioinformatics</em> <strong>12</strong>, 928–937. (doi:<a href="https://doi.org/10.1109/tcbb.2014.2377729">10.1109/tcbb.2014.2377729</a>)</p>
</div>
<div id="ref-T2Md9xLY">
<p>84. Shaham U, Stanton KP, Zhao J, Li H, Raddassi K, Montgomery R, Kluger Y. 2016 Removal of batch effects using distribution-matching residual networks. </p>
</div>
<div id="ref-QFK6GapR">
<p>85. Scotti MM, Swanson MS. 2015 RNA mis-splicing in disease. <em>Nature Reviews Genetics</em> <strong>17</strong>, 19–32. (doi:<a href="https://doi.org/10.1038/nrg.2015.3">10.1038/nrg.2015.3</a>)</p>
</div>
<div id="ref-b6p6wxpC">
<p>86. Li YI, van de Geijn B, Raj A, Knowles DA, Petti AA, Golan D, Gilad Y, Pritchard JK. 2016 RNA splicing is a primary link between genetic variation and disease. <em>Science</em> <strong>352</strong>, 600–604. (doi:<a href="https://doi.org/10.1126/science.aad9417">10.1126/science.aad9417</a>)</p>
</div>
<div id="ref-11ETDdRKr">
<p>87. Barash Y, Calarco JA, Gao W, Pan Q, Wang X, Shai O, Blencowe BJ, Frey BJ. 2010 Deciphering the splicing code. <em>Nature</em> <strong>465</strong>, 53–59. (doi:<a href="https://doi.org/10.1038/nature09000">10.1038/nature09000</a>)</p>
</div>
<div id="ref-8VPGUHcf">
<p>88. Xiong HY, Barash Y, Frey BJ. 2011 Bayesian prediction of tissue-regulated splicing using RNA sequence and cellular context. <em>Bioinformatics</em> (doi:<a href="https://doi.org/10.1093/bioinformatics/btr444">10.1093/bioinformatics/btr444</a>)</p>
</div>
<div id="ref-17sgPdcMT">
<p>89. Xiong HY <em>et al.</em> 2014 The human splicing code reveals new insights into the genetic determinants of disease. <em>Science</em> <strong>347</strong>, 1254806–1254806. (doi:<a href="https://doi.org/10.1126/science.1254806">10.1126/science.1254806</a>)</p>
</div>
<div id="ref-N0HBi8MH">
<p>90. Jha A, Gazzara MR, Barash Y. 2017 Integrative Deep Models for Alternative Splicing. (doi:<a href="https://doi.org/10.1101/104869">10.1101/104869</a>)</p>
</div>
<div id="ref-Qbtqlmhf">
<p>91. Qin Q, Feng J. 2017 Imputation for transcription factor binding predictions based on deep learning. <em>PLOS Computational Biology</em> <strong>13</strong>, e1005403. (doi:<a href="https://doi.org/10.1371/journal.pcbi.1005403">10.1371/journal.pcbi.1005403</a>)</p>
</div>
<div id="ref-mlqKTlZY">
<p>92. Rosenberg A, Patwardhan R, Shendure J, Seelig G. 2015 Learning the Sequence Determinants of Alternative Splicing from Millions of Random Sequences. <em>Cell</em> <strong>163</strong>, 698–711. (doi:<a href="https://doi.org/10.1016/j.cell.2015.09.054">10.1016/j.cell.2015.09.054</a>)</p>
</div>
<div id="ref-CNz9HwZ3">
<p>93. Juan-Mateu J, Villate O, Eizirik DL. 2015 MECHANISMS IN ENDOCRINOLOGY: Alternative splicing: the new frontier in diabetes research. <em>European Journal of Endocrinology</em> <strong>174</strong>, R225–R238. (doi:<a href="https://doi.org/10.1530/eje-15-0916">10.1530/eje-15-0916</a>)</p>
</div>
<div id="ref-1Bs5k1MVg">
<p>94. 2004 The ENCODE (ENCyclopedia Of DNA Elements) Project. <em>Science</em> <strong>306</strong>, 636–640. (doi:<a href="https://doi.org/10.1126/science.1105136">10.1126/science.1105136</a>)</p>
</div>
<div id="ref-ywDQIvZJ">
<p>95. Stormo GD. 2000 DNA binding sites: representation and discovery. <em>Bioinformatics</em> <strong>16</strong>, 16–23. (doi:<a href="https://doi.org/10.1093/bioinformatics/16.1.16">10.1093/bioinformatics/16.1.16</a>)</p>
</div>
<div id="ref-uZvDdFZo">
<p>96. Horton PB, Kanehisa M. 1992 An assessment of neural network and statistical approaches for prediction of E.coli Promoter sites. <em>Nucleic Acids Research</em> <strong>20</strong>, 4331–4338. (doi:<a href="https://doi.org/10.1093/nar/20.16.4331">10.1093/nar/20.16.4331</a>)</p>
</div>
<div id="ref-JxuQvvyk">
<p>97. Ghandi M, Lee D, Mohammad-Noori M, Beer MA. 2014 Enhanced Regulatory Sequence Prediction Using Gapped k-mer Features. <em>PLoS Computational Biology</em> <strong>10</strong>, e1003711. (doi:<a href="https://doi.org/10.1371/journal.pcbi.1003711">10.1371/journal.pcbi.1003711</a>)</p>
</div>
<div id="ref-138dgb9Ca">
<p>98. Setty M, Leslie CS. 2015 SeqGL Identifies Context-Dependent Binding Signals in Genome-Wide Regulatory Element Maps. <em>PLOS Computational Biology</em> <strong>11</strong>, e1004271. (doi:<a href="https://doi.org/10.1371/journal.pcbi.1004271">10.1371/journal.pcbi.1004271</a>)</p>
</div>
<div id="ref-2UI1BZuD">
<p>99. Zhou J, Troyanskaya OG. 2015 Predicting effects of noncoding variants with deep learning–based sequence model. <em>Nature Methods</em> <strong>12</strong>, 931–934. (doi:<a href="https://doi.org/10.1038/nmeth.3547">10.1038/nmeth.3547</a>)</p>
</div>
<div id="ref-Dwi2eAvT">
<p>100. Lanchantin J, Singh R, Wang B, Qi Y. 2016 Deep motif dashboard: Visualizing and understanding genomic sequences using deep neural networks. </p>
</div>
<div id="ref-xAbGxia4">
<p>101. Shrikumar A, Greenside P, Shcherbina A, Kundaje A. 2016 Not just a black box: Learning important features through propagating activation differences. </p>
</div>
<div id="ref-cRuWK1eG">
<p>102. McGuffin LJ, Bryson K, Jones DT. 2000 The PSIPRED protein structure prediction server. <em>Bioinformatics</em> <strong>16</strong>, 404–405. (doi:<a href="https://doi.org/10.1093/bioinformatics/16.4.404">10.1093/bioinformatics/16.4.404</a>)</p>
</div>
<div id="ref-pNoAbBEu">
<p>103. Wang S, Sun S, Xu J. 2016 AUC-Maximized Deep Convolutional Neural Fields for Protein Sequence Labeling. In <em>Machine Learning and Knowledge Discovery in Databases</em>, pp. 1–16. Springer International Publishing. (doi:<a href="https://doi.org/10.1007/978-3-319-46227-1_1">10.1007/978-3-319-46227-1_1</a>)</p>
</div>
<div id="ref-BhfjKSY3">
<p>104. Wang S, Sun S, Li Z, Zhang R, Xu J. 2017 Accurate De Novo Prediction of Protein Contact Map by Ultra-Deep Learning Model. <em>PLOS Computational Biology</em> <strong>13</strong>, e1005324. (doi:<a href="https://doi.org/10.1371/journal.pcbi.1005324">10.1371/journal.pcbi.1005324</a>)</p>
</div>
<div id="ref-7atXz0r">
<p>105. Jones DT, Singh T, Kosciolek T, Tetchner S. 2014 MetaPSICOV: combining coevolution methods for accurate prediction of contacts and long range hydrogen bonding in proteins. <em>Bioinformatics</em> <strong>31</strong>, 999–1006. (doi:<a href="https://doi.org/10.1093/bioinformatics/btu791">10.1093/bioinformatics/btu791</a>)</p>
</div>
<div id="ref-kboAopkh">
<p>106. Weigt M, White RA, Szurmant H, Hoch JA, Hwa T. 2008 Identification of direct residue contacts in protein-protein interaction by message passing. <em>Proceedings of the National Academy of Sciences</em> <strong>106</strong>, 67–72. (doi:<a href="https://doi.org/10.1073/pnas.0805923106">10.1073/pnas.0805923106</a>)</p>
</div>
<div id="ref-10dNuD89l">
<p>107. Marks DS, Colwell LJ, Sheridan R, Hopf TA, Pagnani A, Zecchina R, Sander C. 2011 Protein 3D Structure Computed from Evolutionary Sequence Variation. <em>PLoS ONE</em> <strong>6</strong>, e28766. (doi:<a href="https://doi.org/10.1371/journal.pone.0028766">10.1371/journal.pone.0028766</a>)</p>
</div>
<div id="ref-1AlhRKQbe">
<p>108. Qi Y, Oja M, Weston J, Noble WS. 2012 A Unified Multitask Architecture for Predicting Local Protein Properties. <em>PLoS ONE</em> <strong>7</strong>, e32235. (doi:<a href="https://doi.org/10.1371/journal.pone.0032235">10.1371/journal.pone.0032235</a>)</p>
</div>
<div id="ref-UpFrhdJf">
<p>109. Heffernan R, Paliwal K, Lyons J, Dehzangi A, Sharma A, Wang J, Sattar A, Yang Y, Zhou Y. 2015 Improving prediction of secondary structure, local backbone angles, and solvent accessible surface area of proteins by iterative deep learning. <em>Scientific Reports</em> <strong>5</strong>, 11476. (doi:<a href="https://doi.org/10.1038/srep11476">10.1038/srep11476</a>)</p>
</div>
<div id="ref-Aic7UyXM">
<p>110. Jones DT. 1999 Protein secondary structure prediction based on position-specific scoring matrices. <em>Journal of Molecular Biology</em> <strong>292</strong>, 195–202. (doi:<a href="https://doi.org/10.1006/jmbi.1999.3091">10.1006/jmbi.1999.3091</a>)</p>
</div>
<div id="ref-NnpYUsi">
<p>111. Wang Z, Zhao F, Peng J, Xu J. 2011 Protein 8-class secondary structure prediction using conditional neural fields. <em>PROTEOMICS</em> <strong>11</strong>, 3786–3792. (doi:<a href="https://doi.org/10.1002/pmic.201100196">10.1002/pmic.201100196</a>)</p>
</div>
<div id="ref-8t43CQ9m">
<p>112. Zhou J, Troyanskaya OG. 2014 Deep supervised and convolutional generative stochastic network for protein secondary structure prediction. </p>
</div>
<div id="ref-kqjqFesT">
<p>113. Ma J, Wang S, Wang Z, Xu J. 2015 Protein contact prediction by integrating joint evolutionary coupling analysis and supervised learning. <em>Bioinformatics</em> <strong>31</strong>, 3506–3513. (doi:<a href="https://doi.org/10.1093/bioinformatics/btv472">10.1093/bioinformatics/btv472</a>)</p>
</div>
<div id="ref-xdoT1yUx">
<p>114. Di Lena P, Nagata K, Baldi P. 2012 Deep architectures for protein contact map prediction. <em>Bioinformatics</em> <strong>28</strong>, 2449–2457. (doi:<a href="https://doi.org/10.1093/bioinformatics/bts475">10.1093/bioinformatics/bts475</a>)</p>
</div>
<div id="ref-18bNbDNlc">
<p>115. Eickholt J, Cheng J. 2012 Predicting protein residue-residue contacts using deep networks and boosting. <em>Bioinformatics</em> <strong>28</strong>, 3066–3072. (doi:<a href="https://doi.org/10.1093/bioinformatics/bts598">10.1093/bioinformatics/bts598</a>)</p>
</div>
<div id="ref-F13xtRbV">
<p>116. Skwark MJ, Raimondi D, Michel M, Elofsson A. 2014 Improved Contact Predictions Using the Recognition of Protein Like Contact Patterns. <em>PLoS Computational Biology</em> <strong>10</strong>, e1003889. (doi:<a href="https://doi.org/10.1371/journal.pcbi.1003889">10.1371/journal.pcbi.1003889</a>)</p>
</div>
<div id="ref-zScWGveU">
<p>117. In press. See <a href="http://www.predictioncenter.org/casp12/rrc_avrg_results.cgi" class="uri">http://www.predictioncenter.org/casp12/rrc_avrg_results.cgi</a>.</p>
</div>
<div id="ref-u9uApoaB">
<p>118. In press. See <a href="http://www.cameo3d.org/" class="uri">http://www.cameo3d.org/</a>.</p>
</div>
<div id="ref-rmjDc5rm">
<p>119. Chen L, Cai C, Chen V, Lu X. 2015 Trans-species learning of cellular signaling systems with bimodal deep belief networks. <em>Bioinformatics</em> <strong>31</strong>, 3008–3015. (doi:<a href="https://doi.org/10.1093/bioinformatics/btv315">10.1093/bioinformatics/btv315</a>)</p>
</div>
<div id="ref-40EG4ZEU">
<p>120. Van Valen DA <em>et al.</em> 2016 Deep Learning Automates the Quantitative Analysis of Individual Cells in Live-Cell Imaging Experiments. <em>PLOS Computational Biology</em> <strong>12</strong>, e1005177. (doi:<a href="https://doi.org/10.1371/journal.pcbi.1005177">10.1371/journal.pcbi.1005177</a>)</p>
</div>
<div id="ref-TutLhFSz">
<p>121. Ronneberger O, Fischer P, Brox T. 2015 U-Net: Convolutional Networks for Biomedical Image Segmentation. In <em>Lecture Notes in Computer Science</em>, pp. 234–241. Springer International Publishing. (doi:<a href="https://doi.org/10.1007/978-3-319-24574-4_28">10.1007/978-3-319-24574-4_28</a>)</p>
</div>
<div id="ref-On4vW5aU">
<p>122. Buggenthin F <em>et al.</em> 2017 Prospective identification of hematopoietic lineage choice by deep learning. <em>Nature Methods</em> <strong>14</strong>, 403–406. (doi:<a href="https://doi.org/10.1038/nmeth.4182">10.1038/nmeth.4182</a>)</p>
</div>
<div id="ref-gllSeTW">
<p>123. Eulenberg P, Koehler N, Blasi T, Filby A, Carpenter AE, Rees P, Theis FJ, Wolf FA. 2016 Deep Learning for Imaging Flow Cytometry: Cell Cycle Analysis of Jurkat Cells. (doi:<a href="https://doi.org/10.1101/081364">10.1101/081364</a>)</p>
</div>
<div id="ref-BMg062hc">
<p>124. Pawlowski N, Caicedo JC, Singh S, Carpenter AE, Storkey A. 2016 Automating Morphological Profiling with Generic Deep Convolutional Networks. (doi:<a href="https://doi.org/10.1101/085118">10.1101/085118</a>)</p>
</div>
<div id="ref-hkKO4QYl">
<p>125. Caicedo JC, Singh S, Carpenter AE. 2016 Applications in image-based profiling of perturbations. <em>Current Opinion in Biotechnology</em> <strong>39</strong>, 134–142. (doi:<a href="https://doi.org/10.1016/j.copbio.2016.04.003">10.1016/j.copbio.2016.04.003</a>)</p>
</div>
<div id="ref-m3Ij21U8">
<p>126. Bougen-Zhukov N, Loh SY, Lee HK, Loo L-H. 2016 Large-scale image-based screening and profiling of cellular phenotypes. <em>Cytometry Part A</em> <strong>91</strong>, 115–125. (doi:<a href="https://doi.org/10.1002/cyto.a.22909">10.1002/cyto.a.22909</a>)</p>
</div>
<div id="ref-McjXFLLq">
<p>127. Grys BT, Lo DS, Sahin N, Kraus OZ, Morris Q, Boone C, Andrews BJ. 2016 Machine learning and computer vision approaches for phenotypic profiling. <em>The Journal of Cell Biology</em> <strong>216</strong>, 65–71. (doi:<a href="https://doi.org/10.1083/jcb.201610026">10.1083/jcb.201610026</a>)</p>
</div>
<div id="ref-1AWC7HsO0">
<p>128. Gawad C, Koh W, Quake SR. 2016 Single-cell genome sequencing: current state of the science. <em>Nature Reviews Genetics</em> <strong>17</strong>, 175–188. (doi:<a href="https://doi.org/10.1038/nrg.2015.16">10.1038/nrg.2015.16</a>)</p>
</div>
<div id="ref-1GvfSy48x">
<p>129. Lodato MA <em>et al.</em> 2015 Somatic mutation in single human neurons tracks developmental and transcriptional history. <em>Science</em> <strong>350</strong>, 94–98. (doi:<a href="https://doi.org/10.1126/science.aab1785">10.1126/science.aab1785</a>)</p>
</div>
<div id="ref-QafUwNKn">
<p>130. Liu S, Trapnell C. 2016 Single-cell transcriptome sequencing: recent advances and remaining challenges. <em>F1000Research</em> (doi:<a href="https://doi.org/10.12688/f1000research.7223.1">10.12688/f1000research.7223.1</a>)</p>
</div>
<div id="ref-v97iPXDw">
<p>131. Vera M, Biswas J, Senecal A, Singer RH, Park HY. 2016 Single-Cell and Single-Molecule Analysis of Gene Expression Regulation. <em>Annual Review of Genetics</em> <strong>50</strong>, 267–291. (doi:<a href="https://doi.org/10.1146/annurev-genet-120215-034854">10.1146/annurev-genet-120215-034854</a>)</p>
</div>
<div id="ref-19EJTHByG">
<p>132. Angermueller C, Lee HJ, Reik W, Stegle O. 2017 DeepCpG: accurate prediction of single-cell DNA methylation states using deep learning. <em>Genome Biology</em> <strong>18</strong>. (doi:<a href="https://doi.org/10.1186/s13059-017-1189-z">10.1186/s13059-017-1189-z</a>)</p>
</div>
<div id="ref-XimuXZlz">
<p>133. Koh PW, Pierson E, Kundaje A. 2016 Denoising genome-wide histone ChIP-seq with convolutional neural networks. (doi:<a href="https://doi.org/10.1101/052118">10.1101/052118</a>)</p>
</div>
<div id="ref-1HPu3R2B4">
<p>134. Gaublomme J <em>et al.</em> 2015 Single-Cell Genomics Unveils Critical Regulators of Th17 Cell Pathogenicity. <em>Cell</em> <strong>163</strong>, 1400–1412. (doi:<a href="https://doi.org/10.1016/j.cell.2015.11.009">10.1016/j.cell.2015.11.009</a>)</p>
</div>
<div id="ref-r3Gbjksq">
<p>135. Arvaniti E, Claassen M. 2016 Sensitive detection of rare disease-associated cell subsets via representation learning. (doi:<a href="https://doi.org/10.1101/046508">10.1101/046508</a>)</p>
</div>
<div id="ref-j7KrVyi8">
<p>136. He K, Zhang X, Ren S, Sun J. 2015 Deep residual learning for image recognition. </p>
</div>
<div id="ref-Oljj2W96">
<p>137. Qiu X, Mao Q, Tang Y, Wang L, Chawla R, Pliner H, Trapnell C. 2017 Reversed graph embedding resolves complex single-cell developmental trajectories. (doi:<a href="https://doi.org/10.1101/110668">10.1101/110668</a>)</p>
</div>
<div id="ref-N9NzkOjA">
<p>138. Karlin S, Mrázek J, Campbell AM. 1997 Compositional biases of bacterial genomes and evolutionary implications. <em>Journal of Bacteriology</em> <strong>179</strong>, 3899–3913. (doi:<a href="https://doi.org/10.1128/jb.179.12.3899-3913.1997">10.1128/jb.179.12.3899-3913.1997</a>)</p>
</div>
<div id="ref-1HhqhBwrM">
<p>139. Abe T. 2003 Informatics for Unveiling Hidden Genome Signatures. <em>Genome Research</em> <strong>13</strong>, 693–702. (doi:<a href="https://doi.org/10.1101/gr.634603">10.1101/gr.634603</a>)</p>
</div>
<div id="ref-s9ycaHcq">
<p>140. Altschul SF, Gish W, Miller W, Myers EW, Lipman DJ. 1990 Basic local alignment search tool. <em>Journal of Molecular Biology</em> <strong>215</strong>, 403–410. (doi:<a href="https://doi.org/10.1016/s0022-2836(05)80360-2">10.1016/s0022-2836(05)80360-2</a>)</p>
</div>
<div id="ref-QV551Nlx">
<p>141. McHardy AC, Martín HG, Tsirigos A, Hugenholtz P, Rigoutsos I. 2006 Accurate phylogenetic classification of variable-length DNA fragments. <em>Nature Methods</em> <strong>4</strong>, 63–72. (doi:<a href="https://doi.org/10.1038/nmeth976">10.1038/nmeth976</a>)</p>
</div>
<div id="ref-1HtJuEkb2">
<p>142. Rosen GL, Reichenberger ER, Rosenfeld AM. 2010 NBC: the Naive Bayes Classification tool webserver for taxonomic classification of metagenomic reads. <em>Bioinformatics</em> <strong>27</strong>, 127–129. (doi:<a href="https://doi.org/10.1093/bioinformatics/btq619">10.1093/bioinformatics/btq619</a>)</p>
</div>
<div id="ref-56wEWVIl">
<p>143. Segata N, Waldron L, Ballarini A, Narasimhan V, Jousson O, Huttenhower C. 2012 Metagenomic microbial community profiling using unique clade-specific marker genes. <em>Nature Methods</em> <strong>9</strong>, 811–814. (doi:<a href="https://doi.org/10.1038/nmeth.2066">10.1038/nmeth.2066</a>)</p>
</div>
<div id="ref-RqhGD9c7">
<p>144. Koslicki D, Foucart S, Rosen G. 2014 WGSQuikr: Fast Whole-Genome Shotgun Metagenomic Classification. <em>PLoS ONE</em> <strong>9</strong>, e91784. (doi:<a href="https://doi.org/10.1371/journal.pone.0091784">10.1371/journal.pone.0091784</a>)</p>
</div>
<div id="ref-EbkFuLrS">
<p>145. In press. See <a href="https://www.onecodex.com/" class="uri">https://www.onecodex.com/</a>.</p>
</div>
<div id="ref-189TQrQA9">
<p>146. Ames SK, Hysom DA, Gardner SN, Lloyd GS, Gokhale MB, Allen JE. 2013 Scalable metagenomic taxonomy classification using a reference genome database. <em>Bioinformatics</em> <strong>29</strong>, 2253–2260. (doi:<a href="https://doi.org/10.1093/bioinformatics/btt389">10.1093/bioinformatics/btt389</a>)</p>
</div>
<div id="ref-8DLzxOEt">
<p>147. Vervier K, Mahé P, Tournoud M, Veyrieras J-B, Vert J-P. 2015 Large-scale machine learning for metagenomics sequence classification. <em>Bioinformatics</em> <strong>32</strong>, 1023–1032. (doi:<a href="https://doi.org/10.1093/bioinformatics/btv683">10.1093/bioinformatics/btv683</a>)</p>
</div>
<div id="ref-qUGH5CX8">
<p>148. Yok NG, Rosen GL. 2011 Combining gene prediction methods to improve metagenomic gene annotation. <em>BMC Bioinformatics</em> <strong>12</strong>, 20. (doi:<a href="https://doi.org/10.1186/1471-2105-12-20">10.1186/1471-2105-12-20</a>)</p>
</div>
<div id="ref-yFOAeemA">
<p>149. Soueidan H, Nikolski M. 2017 Machine learning for metagenomics: methods and tools. <em>Metagenomics</em> <strong>1</strong>. (doi:<a href="https://doi.org/10.1515/metgen-2016-0001">10.1515/metgen-2016-0001</a>)</p>
</div>
<div id="ref-W0cYSf89">
<p>150. In press. See <a href="http://www.fasebj.org/content/30/1_Supplement/406.3" class="uri">http://www.fasebj.org/content/30/1_Supplement/406.3</a>.</p>
</div>
<div id="ref-aI9g2UOc">
<p>151. Knights D, Costello EK, Knight R. 2011 Supervised classification of human microbiota. <em>FEMS Microbiology Reviews</em> <strong>35</strong>, 343–359. (doi:<a href="https://doi.org/10.1111/j.1574-6976.2010.00251.x">10.1111/j.1574-6976.2010.00251.x</a>)</p>
</div>
<div id="ref-c5P9jHCg">
<p>152. Statnikov A <em>et al.</em> 2013 A comprehensive evaluation of multicategory classification methods for microbiomic data. <em>Microbiome</em> <strong>1</strong>, 11. (doi:<a href="https://doi.org/10.1186/2049-2618-1-11">10.1186/2049-2618-1-11</a>)</p>
</div>
<div id="ref-y9s5irW">
<p>153. Pasolli E, Truong DT, Malik F, Waldron L, Segata N. 2016 Machine Learning Meta-analysis of Large Metagenomic Datasets: Tools and Biological Insights. <em>PLOS Computational Biology</em> <strong>12</strong>, e1004977. (doi:<a href="https://doi.org/10.1371/journal.pcbi.1004977">10.1371/journal.pcbi.1004977</a>)</p>
</div>
<div id="ref-5W4KMSdT">
<p>154. Ding X, Cheng F, Cao C, Sun X. 2015 DectICO: an alignment-free supervised metagenomic classification method based on feature extraction and dynamic selection. <em>BMC Bioinformatics</em> <strong>16</strong>. (doi:<a href="https://doi.org/10.1186/s12859-015-0753-3">10.1186/s12859-015-0753-3</a>)</p>
</div>
<div id="ref-Kt9NojjR">
<p>155. Liu Z, Chen D, Sheng L, Liu AY. 2014 Correction: Class Prediction and Feature Selection with Linear Optimization for Metagenomic Count Data. <em>PLoS ONE</em> <strong>9</strong>, e97958. (doi:<a href="https://doi.org/10.1371/journal.pone.0097958">10.1371/journal.pone.0097958</a>)</p>
</div>
<div id="ref-1AN5UPfb1">
<p>156. Ditzler G, Morrison JC, Lan Y, Rosen GL. 2015 Fizzy: feature subset selection for metagenomics. <em>BMC Bioinformatics</em> <strong>16</strong>. (doi:<a href="https://doi.org/10.1186/s12859-015-0793-8">10.1186/s12859-015-0793-8</a>)</p>
</div>
<div id="ref-O9D66oYa">
<p>157. Ditzler G, Polikar R, Rosen G. 2015 A Bootstrap Based Neyman-Pearson Test for Identifying Variable Importance. <em>IEEE Transactions on Neural Networks and Learning Systems</em> <strong>26</strong>, 880–886. (doi:<a href="https://doi.org/10.1109/tnnls.2014.2320415">10.1109/tnnls.2014.2320415</a>)</p>
</div>
<div id="ref-q1A2AEtO">
<p>158. Hoff KJ, Lingner T, Meinicke P, Tech M. 2009 Orphelia: predicting genes in metagenomic sequencing reads. <em>Nucleic Acids Research</em> <strong>37</strong>, W101–W105. (doi:<a href="https://doi.org/10.1093/nar/gkp327">10.1093/nar/gkp327</a>)</p>
</div>
<div id="ref-QlbXLqH">
<p>159. Rho M, Tang H, Ye Y. 2010 FragGeneScan: predicting genes in short and error-prone reads. <em>Nucleic Acids Research</em> <strong>38</strong>, e191–e191. (doi:<a href="https://doi.org/10.1093/nar/gkq747">10.1093/nar/gkq747</a>)</p>
</div>
<div id="ref-1GhHIDxuW">
<p>160. Mikolov T, Chen K, Corrado G, Dean J. 2013 Efficient estimation of word representations in vector space. </p>
</div>
<div id="ref-1E1PWjqTm">
<p>161. Asgari E, Mofrad MRK. 2015 Continuous Distributed Representation of Biological Sequences for Deep Proteomics and Genomics. <em>PLOS ONE</em> <strong>10</strong>, e0141287. (doi:<a href="https://doi.org/10.1371/journal.pone.0141287">10.1371/journal.pone.0141287</a>)</p>
</div>
<div id="ref-G8RKF6sz">
<p>162. Hochreiter S, Heusel M, Obermayer K. 2007 Fast model-based protein homology detection without alignment. <em>Bioinformatics</em> <strong>23</strong>, 1728–1736. (doi:<a href="https://doi.org/10.1093/bioinformatics/btm247">10.1093/bioinformatics/btm247</a>)</p>
</div>
<div id="ref-81Cl5QSM">
<p>163. Sønderby SK, Sønderby CK, Nielsen H, Winther O. 2015 Convolutional lstm networks for subcellular localization of proteins. (doi:<a href="https://doi.org/10.1007/978-3-319-21233-3_6">10.1007/978-3-319-21233-3_6</a>)</p>
</div>
<div id="ref-c4rnN1wo">
<p>164. Kelley DR, Salzberg SL. 2010 Clustering metagenomic sequences with interpolated Markov models. <em>BMC Bioinformatics</em> <strong>11</strong>, 544. (doi:<a href="https://doi.org/10.1186/1471-2105-11-544">10.1186/1471-2105-11-544</a>)</p>
</div>
<div id="ref-Wz7VUS03">
<p>165. RASHEED Z, RANGWALA H. 2012 METAGENOMIC TAXONOMIC CLASSIFICATION USING EXTREME LEARNING MACHINES. <em>Journal of Bioinformatics and Computational Biology</em> <strong>10</strong>, 1250015. (doi:<a href="https://doi.org/10.1142/s0219720012500151">10.1142/s0219720012500151</a>)</p>
</div>
<div id="ref-iPIJrVVs">
<p>166. In press. See <a href="https://repozitorij.uni-lj.si/IzpisGradiva.php?id=85515" class="uri">https://repozitorij.uni-lj.si/IzpisGradiva.php?id=85515</a>.</p>
</div>
<div id="ref-oas5tbC7">
<p>167. Chudobova D <em>et al.</em> 2015 Influence of microbiome species in hard-to-heal wounds on disease severity and treatment duration. <em>The Brazilian Journal of Infectious Diseases</em> <strong>19</strong>, 604–613. (doi:<a href="https://doi.org/10.1016/j.bjid.2015.08.013">10.1016/j.bjid.2015.08.013</a>)</p>
</div>
<div id="ref-i38A0beL">
<p>168. Ditzler G, Polikar R, Rosen G. 2015 Multi-Layer and Recursive Neural Networks for Metagenomic Classification. <em>IEEE Transactions on NanoBioscience</em> <strong>14</strong>, 608–616. (doi:<a href="https://doi.org/10.1109/tnb.2015.2461219">10.1109/tnb.2015.2461219</a>)</p>
</div>
<div id="ref-NQ5jiN7B">
<p>169. In press. See <a href="http://alifar76.github.io/sklearn-metrics/" class="uri">http://alifar76.github.io/sklearn-metrics/</a>.</p>
</div>
<div id="ref-g2vvbB91">
<p>170. Bengio Y, Boulanger-Lewandowski N, Pascanu R. 2012 Advances in optimizing recurrent networks. </p>
</div>
<div id="ref-1BTJ1KqRa">
<p>171. Boža V, Brejová B, Vinař T. 2016 DeepNano: Deep recurrent neural networks for base calling in minion nanopore reads. </p>
</div>
<div id="ref-2cMhMv5A">
<p>172. Sutskever I, Vinyals O, Le QV. 2014 Sequence to sequence learning with neural networks. </p>
</div>
<div id="ref-kL0B4m9d">
<p>173. Tu JV. 1996 Advantages and disadvantages of using artificial neural networks versus logistic regression for predicting medical outcomes. <em>Journal of Clinical Epidemiology</em> <strong>49</strong>, 1225–1231. (doi:<a href="https://doi.org/10.1016/s0895-4356(96)00002-9">10.1016/s0895-4356(96)00002-9</a>)</p>
</div>
<div id="ref-jdg2u7bX">
<p>174. Baxt WG. 1991 Use of an Artificial Neural Network for the Diagnosis of Myocardial Infarction. <em>Annals of Internal Medicine</em> <strong>115</strong>, 843. (doi:<a href="https://doi.org/10.7326/0003-4819-115-11-843">10.7326/0003-4819-115-11-843</a>)</p>
</div>
<div id="ref-xX68eyvs">
<p>175. Wasson JH, Sox HC, Neff RK, Goldman L. 1985 Clinical Prediction Rules. <em>New England Journal of Medicine</em> <strong>313</strong>, 793–799. (doi:<a href="https://doi.org/10.1056/nejm198509263131306">10.1056/nejm198509263131306</a>)</p>
</div>
<div id="ref-qxxwkSAT">
<p>176. Lisboa PJ, Taktak AF. 2006 The use of artificial neural networks in decision support in cancer: A systematic review. <em>Neural Networks</em> <strong>19</strong>, 408–415. (doi:<a href="https://doi.org/10.1016/j.neunet.2005.10.007">10.1016/j.neunet.2005.10.007</a>)</p>
</div>
<div id="ref-4zpZxjHR">
<p>177. Lipton ZC, Kale DC, Wetzel R. 2016 Modeling missing data in clinical time series with rnns. </p>
</div>
<div id="ref-O7Vbecm2">
<p>178. Che Z, Purushotham S, Cho K, Sontag D, Liu Y. 2016 Recurrent neural networks for multivariate time series with missing values. </p>
</div>
<div id="ref-fOaBA9Vc">
<p>179. Huddar V, Desiraju BK, Rajan V, Bhattacharya S, Roy S, Reddy CK. 2016 Predicting Complications in Critical Care Using Heterogeneous Clinical Data. <em>IEEE Access</em> <strong>4</strong>, 7988–8001. (doi:<a href="https://doi.org/10.1109/access.2016.2618775">10.1109/access.2016.2618775</a>)</p>
</div>
<div id="ref-glyI7H6F">
<p>180. Lipton ZC, Kale DC, Wetzel RC. 2015 Phenotyping of clinical time series with lstm recurrent neural networks. </p>
</div>
<div id="ref-16OQvsRqJ">
<p>181. Nemati S, Ghassemi MM, Clifford GD. 2016 Optimal medication dosing from suboptimal clinical examples: A deep reinforcement learning approach. In <em>2016 38th Annual International Conference of the IEEE Engineering in Medicine and Biology Society (EMBC)</em>, IEEE. (doi:<a href="https://doi.org/10.1109/embc.2016.7591355">10.1109/embc.2016.7591355</a>)</p>
</div>
<div id="ref-eCrLGgiX">
<p>182. Gultepe E, Green JP, Nguyen H, Adams J, Albertson T, Tagkopoulos I. 2014 From vital signs to clinical outcomes for patients with sepsis: a machine learning basis for a clinical decision support system. <em>Journal of the American Medical Informatics Association</em> <strong>21</strong>, 315–325. (doi:<a href="https://doi.org/10.1136/amiajnl-2013-001815">10.1136/amiajnl-2013-001815</a>)</p>
</div>
<div id="ref-eehGXQlY">
<p>183. Ithapu VK, Singh V, Okonkwo OC, Chappell RJ, Dowling NM, Johnson SC. 2015 Imaging-based enrichment criteria using deep learning algorithms for efficient clinical trials in mild cognitive impairment. <em>Alzheimer’s &amp; Dementia</em> <strong>11</strong>, 1489–1499. (doi:<a href="https://doi.org/10.1016/j.jalz.2015.01.010">10.1016/j.jalz.2015.01.010</a>)</p>
</div>
<div id="ref-mo3GQwJj">
<p>184. Artemov AV, Putin E, Vanhaelen Q, Aliper A, Ozerov IV, Zhavoronkov A. 2016 Integrated deep learned transcriptomic and structure-based predictor of clinical trials outcomes. (doi:<a href="https://doi.org/10.1101/095653">10.1101/095653</a>)</p>
</div>
<div id="ref-cjj5vT3H">
<p>185. Swamidass SJ, Azencott C-A, Lin T-W, Gramajo H, Tsai S-C, Baldi P. 2009 Influence Relevance Voting: An Accurate And Interpretable Virtual High Throughput Screening Method. <em>Journal of Chemical Information and Modeling</em> <strong>49</strong>, 756–766. (doi:<a href="https://doi.org/10.1021/ci8004379">10.1021/ci8004379</a>)</p>
</div>
<div id="ref-uP7SgBVd">
<p>186. Kearnes S, Goldman B, Pande V. 2016 Modeling industrial admet data with multitask networks. </p>
</div>
<div id="ref-HRoooKGh">
<p>187. Altae-Tran H, Ramsundar B, Pappu AS, Pande V. 2016 Low data drug discovery with one-shot learning. </p>
</div>
<div id="ref-bNBiIiTt">
<p>188. Ragoza M, Hochuli J, Idrobo E, Sunseri J, Koes DR. 2016 Protein-ligand scoring with convolutional neural networks. </p>
</div>
<div id="ref-QwXSJhr0">
<p>189. Ribeiro MT, Singh S, Guestrin C. 2016 ‘Why should i trust you?’: Explaining the predictions of any classifier. </p>
</div>
<div id="ref-9SnNyc8Y">
<p>190. Chryssolouris G, Lee M, Ramsey A. 1996 Confidence interval prediction for neural network models. <em>IEEE Transactions on Neural Networks</em> <strong>7</strong>, 229–232. (doi:<a href="https://doi.org/10.1109/72.478409">10.1109/72.478409</a>)</p>
</div>
<div id="ref-1AkF8Wsv7">
<p>191. Nguyen A, Yosinski J, Clune J. 2014 Deep neural networks are easily fooled: High confidence predictions for unrecognizable images. </p>
</div>
<div id="ref-y4t9EzPn">
<p>192. Fong R, Vedaldi A. 2017 Interpretable explanations of black boxes by meaningful perturbation. </p>
</div>
<div id="ref-UcRbawKo">
<p>193. Choi E, Bahadori MT, Kulas JA, Schuetz A, Stewart WF, Sun J. 2016 RETAIN: An interpretable predictive model for healthcare using reverse time attention mechanism. </p>
</div>
<div id="ref-10nDTiETi">
<p>194. Choi E, Bahadori MT, Song L, Stewart WF, Sun J. 2016 GRAM: Graph-based attention model for healthcare representation learning. </p>
</div>
<div id="ref-14DAmZTDg">
<p>195. Che Z, Purushotham S, Khemani R, Liu Y. 2015 Distilling knowledge from deep networks with applications to healthcare domain. </p>
</div>
<div id="ref-CKcJuj03">
<p>196. Gupta S, Agrawal A, Gopalakrishnan K, Narayanan P. 2015 Deep learning with limited numerical precision. </p>
</div>
<div id="ref-1G3owNNps">
<p>197. Courbariaux M, Bengio Y, David J-P. 2014 Training deep neural networks with low precision multiplications. </p>
</div>
<div id="ref-w6CoVmFK">
<p>198. Sa CD, Zhang C, Olukotun K, Ré C. 2015 Taming the wild: A unified analysis of hogwild!-style algorithms. </p>
</div>
<div id="ref-1GUizyE8e">
<p>199. Hubara I, Courbariaux M, Soudry D, El-Yaniv R, Bengio Y. 2016 Quantized neural networks: Training neural networks with low precision weights and activations. </p>
</div>
<div id="ref-1AhGoHZP9">
<p>200. Ba LJ, Caruana R. 2013 Do deep nets really need to be deep? </p>
</div>
<div id="ref-1CRF3gAV">
<p>201. Hinton G, Vinyals O, Dean J. 2015 Distilling the knowledge in a neural network. </p>
</div>
<div id="ref-F3e4wfzQ">
<p>202. Raina R, Madhavan A, Ng AY. 2009 Large-scale deep unsupervised learning using graphics processors. In <em>Proceedings of the 26th Annual International Conference on Machine Learning - ICML ’09</em>, ACM Press. (doi:<a href="https://doi.org/10.1145/1553374.1553486">10.1145/1553374.1553486</a>)</p>
</div>
<div id="ref-NSgduYNT">
<p>203. In press. See <a href="https://research.google.com/pubs/pub37631.html" class="uri">https://research.google.com/pubs/pub37631.html</a>.</p>
</div>
<div id="ref-IULiPa6L">
<p>204. Seide F, Fu H, Droppo J, Li G, Yu D. 2014 On parallelizability of stochastic gradient descent for speech DNNS. In <em>2014 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)</em>, IEEE. (doi:<a href="https://doi.org/10.1109/icassp.2014.6853593">10.1109/icassp.2014.6853593</a>)</p>
</div>
<div id="ref-13KjSCKB2">
<p>205. Hadjis S, Abuzaid F, Zhang C, Ré C. 2015 Caffe con troll: Shallow ideas to speed up deep learning. </p>
</div>
<div id="ref-1FocAi7N0">
<p>206. Edwards C. 2015 Growing pains for deep learning. <em>Communications of the ACM</em> <strong>58</strong>, 14–16. (doi:<a href="https://doi.org/10.1145/2771283">10.1145/2771283</a>)</p>
</div>
<div id="ref-aClNvbyM">
<p>207. Su H, Chen H. 2015 Experiments on parallel training of deep neural network using model averaging. </p>
</div>
<div id="ref-fNkl8HFz">
<p>208. Li M, Zhang T, Chen Y, Smola AJ. 2014 Efficient mini-batch training for stochastic optimization. In <em>Proceedings of the 20th ACM SIGKDD international conference on Knowledge discovery and data mining - KDD ’14</em>, ACM Press. (doi:<a href="https://doi.org/10.1145/2623330.2623612">10.1145/2623330.2623612</a>)</p>
</div>
<div id="ref-CCS5KSIM">
<p>209. In press. See <a href="https://papers.nips.cc/paper/4824-imagenet-classification-with-deep-convolutional-neural-networks.pdf" class="uri">https://papers.nips.cc/paper/4824-imagenet-classification-with-deep-convolutional-neural-networks.pdf</a>.</p>
</div>
<div id="ref-2dU8f4XJ">
<p>210. Gómez-Bombarelli R, Duvenaud D, Hernández-Lobato JM, Aguilera-Iparraguirre J, Hirzel TD, Adams RP, Aspuru-Guzik A. 2016 Automatic chemical design using a data-driven continuous representation of molecules. </p>
</div>
<div id="ref-x0M6vals">
<p>211. Hamanaka M, Taneishi K, Iwata H, Ye J, Pei J, Hou J, Okuno Y. 2016 CGBVS-DNN: Prediction of Compound-protein Interactions Based on Deep Learning. <em>Molecular Informatics</em> <strong>36</strong>, 1600045. (doi:<a href="https://doi.org/10.1002/minf.201600045">10.1002/minf.201600045</a>)</p>
</div>
<div id="ref-YwdqeYZi">
<p>212. Chetlur S, Woolley C, Vandermersch P, Cohen J, Tran J, Catanzaro B, Shelhamer E. 2014 CuDNN: Efficient primitives for deep learning. </p>
</div>
<div id="ref-15lYGmZpY">
<p>213. Chen W, Wilson JT, Tyree S, Weinberger KQ, Chen Y. 2015 Compressing neural networks with the hashing trick. </p>
</div>
<div id="ref-9NKsJjSw">
<p>214. Lacey G, Taylor GW, Areibi S. 2016 Deep learning on fpgas: Past, present, and future. </p>
</div>
<div id="ref-xE3EYmck">
<p>215. Dean J, Ghemawat S. 2008 MapReduce. <em>Communications of the ACM</em> <strong>51</strong>, 107. (doi:<a href="https://doi.org/10.1145/1327452.1327492">10.1145/1327452.1327492</a>)</p>
</div>
<div id="ref-1XcexUAV">
<p>216. Low Y, Bickson D, Gonzalez J, Guestrin C, Kyrola A, Hellerstein JM. 2012 Distributed GraphLab. <em>Proceedings of the VLDB Endowment</em> <strong>5</strong>, 716–727. (doi:<a href="https://doi.org/10.14778/2212351.2212354">10.14778/2212351.2212354</a>)</p>
</div>
<div id="ref-17cBimWgp">
<p>217. In press. See <a href="http://research.google.com/archive/large_deep_networks_nips2012.html" class="uri">http://research.google.com/archive/large_deep_networks_nips2012.html</a>.</p>
</div>
<div id="ref-HIiQN4bd">
<p>218. In press. See <a href="https://papers.nips.cc/paper/5717-taming-the-wild-a-unified-analysis-of-hogwild-style-algorithms.pdf" class="uri">https://papers.nips.cc/paper/5717-taming-the-wild-a-unified-analysis-of-hogwild-style-algorithms.pdf</a>.</p>
</div>
<div id="ref-rmJZ2Aui">
<p>219. Moritz P, Nishihara R, Stoica I, Jordan MI. 2015 SparkNet: Training deep networks in spark. </p>
</div>
<div id="ref-rZnxDitd">
<p>220. Meng X <em>et al.</em> 2015 MLlib: Machine learning in apache spark. </p>
</div>
<div id="ref-Gp4OR9Lf">
<p>221. In press. See <a href="http://download.tensorflow.org/paper/whitepaper2015.pdf" class="uri">http://download.tensorflow.org/paper/whitepaper2015.pdf</a>.</p>
</div>
<div id="ref-FwEK0msb">
<p>222. In press. See <a href="https://github.com/fchollet/keras" class="uri">https://github.com/fchollet/keras</a>.</p>
</div>
<div id="ref-y9IoEy4r">
<p>223. In press. See <a href="https://github.com/maxpumperla/elephas" class="uri">https://github.com/maxpumperla/elephas</a>.</p>
</div>
<div id="ref-4MZ2tmZ8">
<p>224. In press. See <a href="http://www.jmlr.org/proceedings/papers/v28/coates13.html" class="uri">http://www.jmlr.org/proceedings/papers/v28/coates13.html</a>.</p>
</div>
<div id="ref-JUF9VoRD">
<p>225. Sun S, Chen W, Liu T-Y. 2016 Ensemble-compression: A new method for parallel training of deep neural networks. </p>
</div>
<div id="ref-wz83yfHF">
<p>226. In press. See <a href="https://papers.nips.cc/paper/4443-algorithms-for-hyper-parameter-optimization.pdf" class="uri">https://papers.nips.cc/paper/4443-algorithms-for-hyper-parameter-optimization.pdf</a>.</p>
</div>
<div id="ref-Wsa952Ax">
<p>227. In press. See <a href="http://dl.acm.org/citation.cfm?id=2188395" class="uri">http://dl.acm.org/citation.cfm?id=2188395</a>.</p>
</div>
<div id="ref-B6g0qKf4">
<p>228. Schatz MC, Langmead B, Salzberg SL. 2010 Cloud computing and the DNA data race. <em>Nature Biotechnology</em> <strong>28</strong>, 691–693. (doi:<a href="https://doi.org/10.1038/nbt0710-691">10.1038/nbt0710-691</a>)</p>
</div>
<div id="ref-1E7bFCRV4">
<p>229. Muir P <em>et al.</em> 2016 The real cost of sequencing: scaling computation to keep pace with data generation. <em>Genome Biology</em> <strong>17</strong>. (doi:<a href="https://doi.org/10.1186/s13059-016-0917-0">10.1186/s13059-016-0917-0</a>)</p>
</div>
<div id="ref-q0SsFrZd">
<p>230. Stein LD. 2010 The case for cloud computing in genome informatics. <em>Genome Biology</em> <strong>11</strong>, 207. (doi:<a href="https://doi.org/10.1186/gb-2010-11-5-207">10.1186/gb-2010-11-5-207</a>)</p>
</div>
<div id="ref-ZSVsnPVO">
<p>231. Krizhevsky A. 2014 One weird trick for parallelizing convolutional neural networks. </p>
</div>
<div id="ref-ObFN78yp">
<p>232. Armbrust M <em>et al.</em> 2010 A view of cloud computing. <em>Communications of the ACM</em> <strong>53</strong>, 50. (doi:<a href="https://doi.org/10.1145/1721654.1721672">10.1145/1721654.1721672</a>)</p>
</div>
</div>
</body>
</html>
